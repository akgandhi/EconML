[
  {
<<<<<<< HEAD
    "path": "posts/2021-02-28-elements-of-distill-and-rmarkdown/",
    "title": "Elements of Rmarkdown and R",
    "description": "A look at some of the elements of style for your blog posts.",
=======
    "path": "posts/zhongtian-yihao-progress/",
    "title": "Pricing Strategies of Retailers",
    "description": "Description of a subsample",
    "author": [
      {
        "name": "Zhongtian Chen",
        "url": {}
      },
      {
        "name": "Yihao Yuan",
        "url": "https://github.com/yihao-yuan"
      }
    ],
    "date": "2021-03-16",
    "categories": [
      "Zhongtian and Yihao's project"
    ],
    "contents": "\nDescriptive Analyses\nWe start with assortment data on six categories of products: coconut water, corn, cups and straws, deo men roll-on and stick, greek yogurt, and soda and tonic water. We focus on these six categories because the detailed product information of other products are encrypted by the stores. This reduces the number of product-package-days to 19,750,749. We exclude observations where prices or costs are zero (1,014,003, 5.13%), as well as those whose regular price equal to (1,923,812, 9.74%) or less than (738,321, 3.74%) cost. It further reduces the number of observations to 16,812,934 (85.13%).\nWe define discount as a product-package-day-level dummy variable, which equals to 1 if the daily sales price of a product-package lower than its regular price in a day. Both daily sales price and regular price are provided in the assortment data. 1.76% of the product-packages-days (6.87% of the sales) were at a discount, suggesting consumers are price sensitive.\nWe compute margins of each product-package-day as \\(Margin = \\frac{P-C}{P}\\). Strikingly, 44.63% of the discounted product-packages (56.79% of the sales at a discount) were sold with negative margins. Another 12.46% of the discounted product-packages (8.96% of the sales at a discount) were sold exactly at the cost level. The histograms of margins for all and discounted product-packages are presented below.\n\n\n\nThe heat plots on discounted product-packages below show some patterns in stores’ discounting strategies. The y-axes in both graphs are the discount rates. The x-axis in the left graph is the margin rates of the discounted prices, and that in the right graph is the margin rates of the regular prices. We find it common for stores to discount the products to their costs. In addition, stores tend to give discount rates around 10% and 20%, even for product-packages with small margins, which drives the margin rates negative.\n\n\n\nPossible Explanations\nIntertemporal price discrimination\nThe theory of intertemporal price discrimination suggests that retailers charge low prices to attract searchers, who are more price sensitive; meanwhile, they charge high prices to non-searchers, who are less price sensitive (Hendel and Nevo (2013)). This theory implies that retailers should always charge prices greater than costs because they have the market power for price discrimination. This contradicts the findings above, which suggest that almost 2/3 of the discounted sales have negative margins.\nInventory Management\nBecause some products are perishable, and stores may want to sell before they perish. To investigate whether this is an explanation for negative margins, we firstly regress the binary variable discount and the continuous variable discount rate on the logged mean of stock quantities in the past 8 to 28 days. The nearest 7 days are excluded when constructing the variable because it is likely that stores make preparations for the promotions, and start stockpiling days before promotions. In order to prevent the outliers with extremely large amount of stocks to affect the regressions overwhelmingly, we take the logarithm of the stock quantities in analyses. Store and product fixed effects are controlled in all specifications.\nColumn (1) and (2) of the table below shows that the moving average is positively associated with both the probability and rate of the discount. However, as column (3) shows, among the discounted product-packages, higher stock quantity is not significantly correlated with higher likelihood of negative margins. The results suggest inventory management may not be the main reason of negative margins, though it can be correlated with the probability of discount.\n\n\n\nRegression Results: Inventory Management\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\nDiscount\n\n\nDiscount rate\n\n\nNegative margin\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n\n\nLog(stock quantity)\n\n\n0.006***\n\n0.002***\n\n0.003\n\n\n\n\n(0.001)\n\n\n(0.0003)\n\n\n(0.008)\n\n\n\n\nObservations\n\n\n8,750,021\n\n\n8,750,021\n\n\n146,170\n\n\nR2\n\n0.131\n\n\n0.054\n\n\n0.417\n\n\nAdjusted R2\n\n0.131\n\n\n0.054\n\n\n0.415\n\n\n\n\nNote:\n\n\n+p<0.1; ⋆p<0.05; ⋆⋆p<0.01; ⋆⋆⋆p<0.001\n\n\n\nLoss Leader\nStores may want to offer deep promotions on some products to attract consumers to the store to shop for other products, and maximize the overall profit. For example, Li, Gu, and Liu (2013) built up a Hotelling model and empirically showed that book sellers are more likely to promote best sellers, and book sellers that have wider ranges of books are more likely to adopt loss leader strategy. Applying their conclusions, we investigate if more popular products are more likely to be discounted and have negative margins. We use the moving average of the sales quantity in past 28 days to measure popularity. Days with discounted prices are excluded from the computation of moving average to avoid spurious positive correlation between popularity and discount probability. For example, some products may have been discounted for days, such that they have large moving averages of sales quantities. Though these numbers cannot reflect the popularity of the products without price promotions, falsefully using them in analyses may result misleading finding that product-packages with higher sales quantities are more likely to be promoted.\nThe table below shows that popularity is negatively correlated with the likelihood and the rate of discount, though no significance is found in column (2). In addition, popularity is not significantly correlated with the likelihood of negative margins for discounted product-packages. Without using logarithm of sales quantities as the dependent variable will turn all coefficients positive, though no significance will be found (results are not presented). In sum, loss leader may not be the main reason for either price promotion or negative margins.\n\n\nRegression Results: Loss Leader\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\nDiscount\n\n\nDiscount rate\n\n\nNegative margin\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n\n\nLog(sales quantity)\n\n\n-0.005*\n\n-0.0004\n\n\n-0.009\n\n\n\n\n(0.002)\n\n\n(0.0005)\n\n\n(0.017)\n\n\n\n\nObservations\n\n\n8,839,999\n\n\n8,839,999\n\n\n140,025\n\n\nR2\n\n0.139\n\n\n0.054\n\n\n0.422\n\n\nAdjusted R2\n\n0.139\n\n\n0.054\n\n\n0.421\n\n\n\n\nNote:\n\n\n+p<0.1; ⋆p<0.05; ⋆⋆p<0.01; ⋆⋆⋆p<0.001\n\n\nNext Steps\nFull data are being merged and compressed into one single csv.gz file. Future work will be conducted on Amazon cloud.\nLook for other explanations of discounts and negative margins, and use linear models to investigate their explanatory powers.\nUse unsupervised machine learning methods to explore the factors to explain the remaining variations of dependent variables.\n\n\n\nHendel, Igal, and Aviv Nevo. 2013. “Intertemporal Price Discrimination in Storable Goods Markets.” American Economic Review 103 (7): 2722–51.\n\n\nLi, Xinxin, Bin Gu, and Hongju Liu. 2013. “Price Dispersion and Loss-Leader Pricing: Evidence from the Online Book Industry.” Management Science 59 (6). INFORMS: 1290–1308.\n\n\n\n\n",
    "preview": "posts/zhongtian-yihao-progress/distill-preview.png",
    "last_modified": "2021-03-16T14:23:46+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-15-kristen-jordan-data-work-and-exploration/",
    "title": "Data Work and Exploration",
    "description": "Unpacking the student, parent, teacher, administrator, and counselor surveys.",
    "author": [
      {
        "name": "Kristen Beamer",
        "url": {}
      },
      {
        "name": "Jordan Peeples",
        "url": {}
      }
    ],
    "date": "2021-03-15",
    "categories": [
      "Jordan and Kristen's project"
    ],
    "contents": "\nIn this post we will dive deep into the data for our project, HSLS:09, in an attempt to better understand the wealth of information within the 6,000+ different variables. In addition to the 6,608 variables, we are dealing with more than 23,000 observations. With such large data, we must divide the data into smaller sections to better understand the contents and to perform machine learning analysis, as the many categorical variables are computationally taxing.\nThis post will be split into five sections pertaining to the surveys aggregated in HSLS:09 – the parent survey, student survey, teacher survey, administrator survey, and counselor survey. Through these different surveys, we will be able to discover which variables are most important in determining a student’s outcome after graduation. This post will expose our data cleaning exercise and document the challenges and important features we uncover along the way.\nFor now we will just study the raw survey responses rather than the composite and imputation variables within the data.\nStudent Survey\nThe student survey is composed of three sections: base year, first year follow-up, and 2013 update. The base year questions are asked during the student’s freshman year, the first year follow-up is in 2012, and the 2013 update occurs after a student has graduated high school (assuming the student graduated after four years). Variables that begin with “S1”, “S2”, and “S3” correspond to the base year, the first year follow-up, and the 2013 update respectively.\n\n\nstudentDataStudents <- studentData %>%\n  select(X3TCREDENG:S2PUBASSIST, S3FOCUS) %>%\n  mutate_all(na_if, -5) %>%\n  mutate_all(na_if, -4) %>%\n  mutate_all(na_if, -7) %>%\n  mutate_all(na_if, -8) %>%\n  mutate_all(na_if, -9) %>%\n  mutate(S1EDUEXPECT = recode(S1EDUEXPECT, \"(01) Less than high school\" = \"Less than HS\",\n                              \"(02) High school diploma or GED\" = \"HS Diploma/GED\",\n                              \"(03) Start an Associate's degree\" = \"Start Assoc.\",\n                              \"(04) Complete an Associate's degree\" = \"Complete Assoc.\",\n                              \"(05) Start a Bachelor's degree\" = \"Start Bachelor's\",\n                              \"(06) Complete a Bachelor's degree\" = \"Complete Bachelor's\",\n                              \"(07) Start a Master's degree\" = \"Start Master's\",\n                              \"(08) Complete a Master's degree\" = \"Complete Master's\",\n                              \"(09) Start Ph.D/M.D/Law/other prof degree\" = \"Start PhD\",\n                              \"(10) Complete Ph.D/M.D/Law/other prof degree\" = \"Complete PhD\",\n                              \"(11) Don't know\" = \"Don't know\")) %>%\n  mutate(S3FOCUS = recode(S3FOCUS, \"(1) Taking classes from postsecondary institution\" = \"Postsecondary\",\n                          \"(2) Participating in an apprenticeship program\" = \"Apprenticeship\",\n                          \"(3) Working for pay\" = \"Work\",\n                          \"(4) Serving in the military\" = \"Military\",\n                          \"(5) Starting family or taking care of your/his/her children\" = \"Childcare\",\n                          \"(6) Attending high school or homeschool\" = \"Continued school\",\n                          \"(7) Taking course to prepare for the GED/other high school equivalency exam\" = \"GED Prep\",\n                          \"(8) Equally focused on more than one of these\" = \"Multiple\"))\n\nstudentDataStudents <- studentDataStudents[ , colSums(is.na(studentDataStudents)) < 12000]\n\n\n\nAbove, we have selected only the student survey questions and have dropped variables that contain an excessive amount of NA’s. We also did not keep variables from the 2013 update because they are variations of outcomes after high school; our only interest is S3FOCUS for now, which is the general post-high school graduation outcome. After dropping these variables, this subset contains 649 variables.\nThe variables being recoded for easier interpretability in the code excerpt above are the outcome variable of interest (S3FOCUS) and a potential predictor we are interested in (S1EDUEXPECT). The latter asks “As things stand now, how far in school do you think you will get?” We hypothesize that the variable will play a role in the machine learning analysis. Below, we plot the expectations over the outcome.\n\n\nggplot(studentDataStudents, aes(x = S1EDUEXPECT, fill = S3FOCUS)) + \n  geom_bar(position = \"fill\") +\n  labs(title = \"Student Outcomes as Proportions of Expectations\",\n       y = \"Proportion\",\n       x = \"Student Expectation\") +\n  guides(fill=guide_legend(title=\"Student Outcomes\")) +\n  theme(axis.text.x=element_text(size=8))\n\n\n\n\nExpectations are somewhat consistent with the actual student outcomes. Students who expect to complete Master’s degrees and Ph.D.’s have the largest proportion of students who attend postsecondary schools. Those who expected to complete less than high school, receive a HS diploma or GED, or start an associates degree contain the largest proportion of students who worked after graduation. We expect this variable to play some role in predicting the outcome, but we will learn which variables have the most important in our machine learning analysis.\nThere are other pertinent questions in this survey, such as grade-related questions, demographics, course-specific questions, and even reflective questions such as, “9th grader sees himself/herself as a math person.” Overall, the variables are mostly categorical. We can see this below:\n\n\nskim(studentDataStudents%>%select(where(is.numeric)))\n\n\nTable 1: Data summary\nName\nstudentDataStudents %>% s…\nNumber of rows\n23503\nNumber of columns\n74\n_______________________\n\nColumn type frequency:\n\nnumeric\n74\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nX3TCREDENG\n1575\n0.93\n3.88\n1.33\n0.00\n3.5\n4.0\n4.5e+00\n9.00e+00\n▁▂▇▁▁\nX3TCREDAPENG\n1575\n0.93\n0.26\n0.60\n0.00\n0.0\n0.0\n0.0e+00\n3.00e+00\n▇▁▁▁▁\nX3TGPAENG\n1739\n0.93\n2.60\n0.95\n0.25\n2.0\n2.5\n3.5e+00\n4.00e+00\n▂▂▇▅▇\nX3TCREDAPMTH\n1575\n0.93\n0.19\n0.50\n0.00\n0.0\n0.0\n0.0e+00\n3.00e+00\n▇▁▁▁▁\nX3TCREDMAT\n1575\n0.93\n3.58\n1.28\n0.00\n3.0\n4.0\n4.0e+00\n8.00e+00\n▂▃▇▂▁\nX3TGPAMAT\n1742\n0.93\n2.37\n0.98\n0.25\n1.5\n2.5\n3.0e+00\n4.00e+00\n▃▃▇▃▅\nX3TGPAHIMTH\n2280\n0.90\n2.29\n1.03\n0.25\n1.5\n2.0\n3.0e+00\n4.00e+00\n▆▃▇▅▆\nX3TCREDAPSCI\n1575\n0.93\n0.22\n0.60\n0.00\n0.0\n0.0\n0.0e+00\n4.00e+00\n▇▁▁▁▁\nX3TCREDSCI\n1575\n0.93\n3.25\n1.32\n0.00\n3.0\n3.0\n4.0e+00\n8.00e+00\n▂▇▇▂▁\nX3TGPASCI\n1825\n0.92\n2.44\n0.98\n0.25\n2.0\n2.5\n3.0e+00\n4.00e+00\n▃▃▇▅▆\nX3TGPAHISCI\n2299\n0.90\n2.52\n0.98\n0.25\n2.0\n2.5\n3.5e+00\n4.00e+00\n▃▃▇▅▇\nX3TCREDSOCST\n1575\n0.93\n3.49\n1.39\n0.00\n3.0\n3.5\n4.0e+00\n8.00e+00\n▂▆▇▂▁\nX3TCREDAPSS\n1575\n0.93\n0.43\n0.92\n0.00\n0.0\n0.0\n0.0e+00\n5.00e+00\n▇▁▁▁▁\nX3TGPASOCST\n1929\n0.92\n2.64\n0.96\n0.25\n2.0\n3.0\n3.5e+00\n4.00e+00\n▂▂▇▅▇\nX3TCREDART\n1575\n0.93\n1.84\n1.81\n0.00\n0.5\n1.0\n2.5e+00\n9.00e+00\n▇▃▁▁▁\nX3TCREDAPART\n1575\n0.93\n0.52\n0.12\n0.50\n0.5\n0.5\n5.0e-01\n2.00e+00\n▇▁▁▁▁\nX3TGPAART\n5303\n0.77\n3.23\n0.95\n0.25\n3.0\n3.5\n4.0e+00\n4.00e+00\n▁▁▂▂▇\nX3TCREDLANG\n1575\n0.93\n1.85\n1.32\n0.00\n1.0\n2.0\n3.0e+00\n7.00e+00\n▇▇▆▁▁\nX3TCREDAPLNG\n1575\n0.93\n0.54\n0.20\n0.50\n0.5\n0.5\n5.0e-01\n3.00e+00\n▇▁▁▁▁\nX3TGPALANG\n5403\n0.77\n2.69\n1.07\n0.25\n2.0\n3.0\n3.5e+00\n4.00e+00\n▂▂▆▃▇\nX3TCREDREL\n1575\n0.93\n0.48\n1.22\n0.00\n0.0\n0.0\n0.0e+00\n5.00e+00\n▇▁▁▁▁\nX3TCREDHELPE\n1575\n0.93\n1.99\n1.24\n0.00\n1.0\n2.0\n2.5e+00\n8.00e+00\n▇▆▂▁▁\nX3TGPAHELPE\n2598\n0.89\n3.25\n0.91\n0.25\n3.0\n3.5\n4.0e+00\n4.00e+00\n▁▁▂▂▇\nX3TCREDMILSCI\n1575\n0.93\n0.09\n0.51\n0.00\n0.0\n0.0\n0.0e+00\n5.00e+00\n▇▁▁▁▁\nX3TCREDCOMPSCI\n1575\n0.93\n0.48\n0.69\n0.00\n0.0\n0.0\n1.0e+00\n5.00e+00\n▇▁▁▁▁\nX3TCREDCOM\n1575\n0.93\n0.27\n0.63\n0.00\n0.0\n0.0\n0.0e+00\n5.00e+00\n▇▁▁▁▁\nX3TCREDBUS\n1575\n0.93\n0.36\n0.74\n0.00\n0.0\n0.0\n5.0e-01\n6.00e+00\n▇▁▁▁▁\nX3TCREDMANU\n1575\n0.93\n0.08\n0.41\n0.00\n0.0\n0.0\n0.0e+00\n5.00e+00\n▇▁▁▁▁\nX3TCREDHELSCI\n1575\n0.93\n0.19\n0.73\n0.00\n0.0\n0.0\n0.0e+00\n7.00e+00\n▇▁▁▁▁\nX3TCREDPUBSER\n1575\n0.93\n0.08\n0.34\n0.00\n0.0\n0.0\n0.0e+00\n4.00e+00\n▇▁▁▁▁\nX3TCREDTOUR\n1575\n0.93\n0.12\n0.46\n0.00\n0.0\n0.0\n0.0e+00\n5.00e+00\n▇▁▁▁▁\nX3TCREDARCH\n1575\n0.93\n0.14\n0.55\n0.00\n0.0\n0.0\n0.0e+00\n5.00e+00\n▇▁▁▁▁\nX3TCREDAG\n1575\n0.93\n0.19\n0.71\n0.00\n0.0\n0.0\n0.0e+00\n7.00e+00\n▇▁▁▁▁\nX3TCREDHUMSER\n1575\n0.93\n0.13\n0.52\n0.00\n0.0\n0.0\n0.0e+00\n5.00e+00\n▇▁▁▁▁\nX3TCREDTRANS\n1575\n0.93\n0.09\n0.49\n0.00\n0.0\n0.0\n0.0e+00\n5.00e+00\n▇▁▁▁▁\nX3TCREDENGIN\n1575\n0.93\n0.17\n0.55\n0.00\n0.0\n0.0\n0.0e+00\n5.00e+00\n▇▁▁▁▁\nX3TCREDMISC\n1575\n0.93\n1.13\n1.37\n0.00\n0.0\n1.0\n1.5e+00\n9.00e+00\n▇▂▁▁▁\nX3TGPAMISC\n9592\n0.59\n3.05\n1.01\n0.25\n2.5\n3.5\n4.0e+00\n4.00e+00\n▁▁▃▂▇\nX3TCREDTOT\n1575\n0.93\n24.21\n7.31\n0.00\n22.5\n26.0\n2.9e+01\n3.60e+01\n▁▁▂▇▃\nX3TCREDACAD\n1575\n0.93\n17.89\n6.01\n0.00\n15.5\n19.0\n2.2e+01\n3.10e+01\n▁▁▅▇▁\nX3TCREDCTE\n1575\n0.93\n2.80\n2.42\n0.00\n1.0\n2.0\n4.0e+00\n1.20e+01\n▇▅▂▁▁\nX3TCREDNONA\n1575\n0.93\n3.50\n2.10\n0.00\n2.0\n3.0\n5.0e+00\n9.00e+00\n▅▇▅▃▁\nX3TCREDSTEM\n1575\n0.93\n7.47\n2.69\n0.00\n6.0\n8.0\n9.0e+00\n1.60e+01\n▁▂▇▂▁\nX3TCREDAPIB\n1575\n0.93\n1.21\n2.29\n0.00\n0.0\n0.0\n1.5e+00\n1.30e+01\n▇▁▁▁▁\nX3TCRED9TH\n1575\n0.93\n6.51\n2.01\n0.00\n6.0\n7.0\n7.5e+00\n1.30e+01\n▁▁▇▃▁\nX3TCRED10TH\n1575\n0.93\n6.07\n2.40\n0.00\n6.0\n7.0\n7.5e+00\n1.30e+01\n▂▁▇▃▁\nX3TCRED11TH\n1575\n0.93\n5.79\n2.69\n0.00\n5.5\n6.5\n7.5e+00\n1.30e+01\n▂▁▇▃▁\nX3TCRED12TH\n1575\n0.93\n5.27\n2.80\n0.00\n4.0\n6.0\n7.0e+00\n1.30e+01\n▃▂▇▂▁\nX3TCREDPPSE\n1575\n0.93\n0.21\n0.87\n0.00\n0.0\n0.0\n0.0e+00\n7.00e+00\n▇▁▁▁▁\nX3TCREDSPED\n1575\n0.93\n0.08\n0.50\n0.00\n0.0\n0.0\n0.0e+00\n5.00e+00\n▇▁▁▁▁\nX3TCREDREM\n1575\n0.93\n0.29\n0.90\n0.00\n0.0\n0.0\n0.0e+00\n7.00e+00\n▇▁▁▁▁\nX3TCREDGEN\n1575\n0.93\n19.56\n7.30\n0.00\n15.0\n21.0\n2.5e+01\n3.20e+01\n▂▂▅▇▅\nX3TCREDADV\n1575\n0.93\n2.09\n3.18\n0.00\n0.0\n1.0\n3.0e+00\n1.70e+01\n▇▁▁▁▁\nX3TCREDHON\n1575\n0.93\n2.03\n3.69\n0.00\n0.0\n0.0\n2.0e+00\n1.90e+01\n▇▁▁▁▁\nX3TCREDCLG\n1575\n0.93\n0.19\n0.73\n0.00\n0.0\n0.0\n0.0e+00\n7.00e+00\n▇▁▁▁▁\nX3TCREDMTSC\n1575\n0.93\n6.82\n2.36\n0.00\n6.0\n7.0\n8.0e+00\n1.40e+01\n▁▂▇▃▁\nX3TGPAACAD\n1645\n0.93\n2.57\n0.91\n0.25\n2.0\n2.5\n3.5e+00\n4.00e+00\n▂▂▇▅▆\nX3TGPACTE\n3768\n0.84\n3.01\n0.96\n0.25\n2.5\n3.5\n4.0e+00\n4.00e+00\n▁▁▃▃▇\nX3TGPANONA\n1975\n0.92\n3.20\n0.88\n0.25\n3.0\n3.5\n4.0e+00\n4.00e+00\n▁▁▂▂▇\nX3TGPASTEM\n1679\n0.93\n2.43\n0.93\n0.25\n2.0\n2.5\n3.0e+00\n4.00e+00\n▂▃▇▅▅\nX3TGPA11TH\n4475\n0.81\n2.81\n0.84\n0.25\n2.5\n3.0\n3.5e+00\n4.00e+00\n▁▂▇▅▇\nX3TGPA9TH\n2360\n0.90\n2.72\n0.92\n0.25\n2.0\n3.0\n3.5e+00\n4.00e+00\n▂▂▇▅▇\nX3TGPA10TH\n3518\n0.85\n2.74\n0.89\n0.25\n2.0\n3.0\n3.5e+00\n4.00e+00\n▂▂▇▅▇\nX3TGPA12TH\n5291\n0.77\n2.96\n0.78\n0.25\n2.5\n3.0\n3.5e+00\n4.00e+00\n▁▁▅▅▇\nX3TGPATOT\n1627\n0.93\n2.71\n0.86\n0.25\n2.0\n3.0\n3.5e+00\n4.00e+00\n▂▂▇▆▇\nX3TGPAWGT\n1627\n0.93\n2.83\n0.96\n0.25\n2.0\n3.0\n3.5e+00\n4.75e+00\n▂▅▃▇▃\nX3TAFGPATOT\n1747\n0.93\n2.72\n0.74\n1.00\n2.0\n2.5\n3.5e+00\n4.00e+00\n▃▆▆▆▇\nX3TAGPA10\n3561\n0.85\n2.61\n0.95\n0.25\n2.0\n2.5\n3.5e+00\n4.00e+00\n▂▂▇▅▇\nX3TAGPA11\n4511\n0.81\n2.68\n0.90\n0.25\n2.0\n3.0\n3.5e+00\n4.00e+00\n▂▂▇▅▇\nX3TAGPA12\n5355\n0.77\n2.81\n0.84\n0.25\n2.5\n3.0\n3.5e+00\n4.00e+00\n▁▂▇▅▇\nX3TAGPA09\n2388\n0.90\n2.60\n0.97\n0.25\n2.0\n2.5\n3.5e+00\n4.00e+00\n▃▂▇▅▇\nX3TAGPAWGT\n1645\n0.93\n2.72\n1.03\n0.25\n2.0\n3.0\n3.5e+00\n4.75e+00\n▂▆▅▇▅\nS1ESTIN\n8239\n0.65\n18930.82\n16834.07\n2000.00\n5000.0\n15000.0\n3.0e+04\n5.00e+04\n▇▃▂▁▃\nS2OCC30EARN\n11026\n0.53\n107536.91\n161313.16\n1000.00\n40000.0\n70000.0\n1.0e+05\n1.00e+06\n▇▁▁▁▁\n\nThere are 74 numerical variables (out of 649 total variables) with most of them attributed to GPA and course credits. For example, XT3CREDAPENG are the total number of AP English credits a student has earned. The mean credits among all students in the survey is 0.260. A credit refers to a student passing a one year academic course. X3TGPAWGT is the GPA weighted by honors course, which gives an extra GPA point for an honors course. S2OCC30EARN is the expected occupation earnings at 30 years old, and S1ESTIN is the estimate of tuition and fees at public in-state 4 year college.\nParent Survey\nWhat makes these data unique is the link between a student’s perspective and their parent’s perspective. The parent survey, like the student survey, contains multiple years: the base year and a first year follow-up. As such, the variables begin with “P1” for the base year and “P2” for the follow-up year while the parent’s child is still in school. The parent is asked questions like, “How sure are you that your child will pursue a Bachelor’s degree?” and the parent’s education level. Below, the data clean-up is very similar as the student’s.\n\n\nstudentDataParents <- studentData %>%\n  select(P1RELSHP:P2QHELP4, S3FOCUS) %>%\n  mutate_all(na_if, -5) %>%\n  mutate_all(na_if, -4) %>%\n  mutate_all(na_if, -7) %>%\n  mutate_all(na_if, -8) %>%\n  mutate_all(na_if, -9) \n\nstudentDataParents <- studentDataParents[ , colSums(is.na(studentDataParents)) < 12000]\n\n\n\nThere are only 94 variables in this survey, and only 6 of them are numeric. Compared to the student survey, this is a smaller proportion.\n\n\nskim(studentDataParents%>%select(where(is.numeric)))\n\n\nTable 2: Data summary\nName\nstudentDataParents %>% se…\nNumber of rows\n23503\nNumber of columns\n6\n_______________________\n\nColumn type frequency:\n\nnumeric\n6\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nP1OLDERSIB\n7750\n0.67\n1.13\n1.34\n0\n0\n1\n2\n9\n▇▂▁▁▁\nP1YRBORN1\n7613\n0.68\n1965.36\n6.86\n1944\n1961\n1966\n1970\n1981\n▁▂▇▆▂\nP1YRBORN2\n11017\n0.53\n1964.20\n7.02\n1944\n1960\n1964\n1969\n1981\n▁▃▇▅▂\nP1HOURS1\n8508\n0.64\n40.10\n10.98\n8\n40\n40\n45\n81\n▁▂▇▁▁\nP1HOURS2\n11783\n0.50\n43.30\n10.75\n8\n40\n40\n50\n81\n▁▁▇▁▁\nP1CHANGESCH\n7766\n0.67\n1.20\n1.56\n0\n0\n1\n2\n9\n▇▂▁▁▁\n\nParent survey variables mainly contain the following: demographics, information about relatives/siblings, expectations of the child, information about the child prior to high school, and the parents’ college education and occupation types. Among these numeric variables, we see the number of older siblings (P1OLDERSIB), the year parents were born (P1YRBORN1 and P1YRBORN2), hours worked by each parent per week (P1HOURS1 and P2HOURS2), and the number of times the child has changed schools since kindergarten (P1CHANGESCH).\nTeacher Survey\nHere, we will begin by selecting the variables from the teacher survey. Within HSLS:09, the teacher survey only occurred in the base year. In the naming convention of the teacher questionnaire, these variables begin with “M1” and “N1”. Here “M1” corresponds to surveys of the students’ math teachers and “N1” corresponds to surveys of the students’ science teachers. We also drop variables that have majority NA observations.\n\n\nstudentDataTeacher <- studentData %>% \n  select(M1SEX:N1TFAIL) %>%\n  mutate_all(na_if, -5) %>%\n  mutate_all(na_if, -4) %>%\n  mutate_all(na_if, -7) %>%\n  mutate_all(na_if, -8) %>%\n  mutate_all(na_if, -9)\nstudentDataTeacher <- studentDataTeacher[,colSums(is.na(studentDataTeacher))<12000]\n\n\n\nAfter dropping the majority NA variables, there are now 276 remaining variables from the teacher survey to explore. Questions within the teacher surveys can be grouped into several subcategories.\nDemographic information about the teacher and their qualifications\nTeacher’s perception of the school and classroom environment\nOnly 12 of the teacher variables are numeric. We will skim the numeric variables below.\n\n\nskim(studentDataTeacher%>%select(where(is.numeric)))\n\n\nTable 3: Data summary\nName\nstudentDataTeacher %>% se…\nNumber of rows\n23503\nNumber of columns\n12\n_______________________\n\nColumn type frequency:\n\nnumeric\n12\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nM1HIDEGYR\n6490\n0.72\n1997.49\n10.68\n1972\n1990\n2001\n2006\n2009\n▂▂▂▂▇\nM1BAYR\n6491\n0.72\n1993.24\n11.68\n1968\n1985\n1995\n2004\n2009\n▃▂▅▅▇\nM1MTHYRS912\n6483\n0.72\n10.14\n8.49\n1\n3\n7\n15\n31\n▇▃▂▁▁\nM1TCHYRK8\n8018\n0.66\n2.74\n4.51\n0\n0\n0\n4\n16\n▇▁▁▁▁\nM1TCHYR912\n6699\n0.71\n10.33\n8.53\n1\n3\n8\n15\n31\n▇▃▂▂▂\nM1SCHYRS\n6469\n0.72\n7.29\n6.71\n1\n2\n5\n10\n26\n▇▂▁▁▁\nN1HIDEGYR\n7997\n0.66\n1996.98\n10.44\n1975\n1990\n2000\n2006\n2009\n▂▂▂▅▇\nN1BAYR\n7988\n0.66\n1992.15\n11.38\n1970\n1983\n1995\n2002\n2009\n▅▅▅▇▇\nN1SCIYRS912\n7989\n0.66\n10.33\n7.88\n1\n4\n8\n15\n26\n▇▅▂▁▃\nN1TCHYRK8\n9347\n0.60\n2.31\n3.61\n0\n0\n0\n3\n11\n▇▁▁▁▂\nN1TCHYR912\n8152\n0.65\n10.58\n7.94\n1\n4\n8\n16\n26\n▇▅▂▂▃\nN1SCHYRS\n7981\n0.66\n7.67\n6.15\n1\n3\n6\n11\n21\n▇▃▂▁▂\n\nNote that there are 6 variables for the Math teacher and 6 for the science teacher: HIDEGYR: Year math (or science) teacher earned their highest degree, BAYR: Year math (or science) teacher earned their Bachelor’s degree, M1MTHYRS912: Years math teacher has taught high school math, N1SCIYRS912: Years science teacher has taught high school science, TCHYRK8: Years math (or science) teacher has taught any subject to grades K-8, TCHYR912: Years math (or science) teacher has taught any subject to grades 9-12, and SCHYRS: Years math (or science) teacher has taught any subject at current school.\nThese numeric variables capture some of the qualification data for the teachers. Note that across the 12 numeric variables, the math teacher complete rate tends to be higher (approximately 65-72%). Meanwhile the science teacher complete rate is approximately 60-66%. The distribution of teacher experience is skewed such that there are more inexperienced teachers.\nWithin the categorical variables there are questions about the teacher’s sex, their perception of the school’s rigor and atmosphere, and their perception of the degree of support students receive at home.\nAdministrator Survey\nThe administrator survey occurred in both the base year and the first year follow-up of the survey. Like before, we begin by selecting just the variables from the administrator questionnaire.\n\n\nstudentDataAdmin <- studentData %>% \n  select(A1GRADEPREK:A2TCHSUBJO) %>%\n  mutate_all(na_if, -5) %>%\n  mutate_all(na_if, -4) %>%\n  mutate_all(na_if, -7) %>%\n  mutate_all(na_if, -8) %>%\n  mutate_all(na_if, -9)\nstudentDataAdmin <- studentDataAdmin[,colSums(is.na(studentDataAdmin))<12000]\n\n\n\nAfter dropping the majority NA variables, there are now only 141 remaining variables to consider. We can skim them below:\n\n\nskim(studentDataAdmin%>%select(where(is.numeric)))\n\n\nTable 4: Data summary\nName\nstudentDataAdmin %>% sele…\nNumber of rows\n23503\nNumber of columns\n24\n_______________________\n\nColumn type frequency:\n\nnumeric\n24\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nA1YRSADMIN\n3862\n0.84\n7.63\n5.44\n1\n3\n6\n11\n19\n▇▆▃▂▃\nA1HRTEACHERS\n4408\n0.81\n8.75\n6.44\n0\n5\n8\n10\n60\n▇▂▁▁▁\nA1HRINTMGMNT\n4438\n0.81\n8.86\n6.61\n0\n5\n8\n10\n50\n▇▂▁▁▁\nA1HREXTMGMNT\n4392\n0.81\n6.93\n5.34\n0\n4\n5\n10\n50\n▇▁▁▁▁\nA1HRMONITOR\n4430\n0.81\n6.74\n4.80\n0\n4\n5\n10\n40\n▇▃▁▁▁\nA1HRPARENT\n4403\n0.81\n5.00\n3.59\n0\n3\n5\n5\n40\n▇▁▁▁▁\nA1HRSTUDENT\n4402\n0.81\n5.23\n4.14\n0\n3\n5\n6\n60\n▇▁▁▁▁\nA1HRPAPERWK\n4579\n0.81\n5.72\n5.15\n0\n2\n5\n8\n77\n▇▁▁▁▁\nA1HROTH\n7023\n0.70\n9.25\n6.58\n0\n5\n8\n10\n45\n▇▆▂▁▁\nA2CTESHSCH\n5135\n0.78\n6.04\n10.06\n0\n0\n2\n9\n65\n▇▁▁▁▁\nA2HSSIZE\n2336\n0.90\n1217.27\n807.98\n25\n550\n1150\n1700\n3500\n▇▇▆▂▁\nA2ADA9\n6468\n0.72\n92.01\n12.05\n25\n92\n95\n96\n99\n▁▁▁▁▇\nA2ADA10\n6451\n0.73\n91.80\n12.44\n25\n92\n95\n96\n99\n▁▁▁▁▇\nA2ADA11\n6468\n0.72\n91.60\n12.75\n22\n92\n95\n96\n99\n▁▁▁▁▇\nA2ADA12\n6468\n0.72\n91.04\n13.21\n20\n91\n94\n96\n99\n▁▁▁▁▇\nA2REPEATG11\n9838\n0.58\n4.50\n5.26\n0\n1\n3\n6\n25\n▇▂▁▁▁\nA2RETURN11\n5891\n0.75\n94.84\n5.66\n60\n94\n96\n98\n100\n▁▁▁▂▇\nA2HIGHERED\n3332\n0.86\n72.87\n22.61\n0\n60\n78\n92\n100\n▁▂▃▆▇\nA2WORK\n3638\n0.85\n20.39\n15.42\n10\n10\n10\n30\n90\n▇▃▁▁▁\nA2MILITARY\n3620\n0.85\n4.95\n3.80\n2\n2\n2\n8\n21\n▇▅▁▁▁\nA2PTSTCHRS\n2335\n0.90\n0.43\n0.86\n0\n0\n0\n1\n5\n▇▁▁▁▁\nA2PTALLTCHRS\n5407\n0.77\n3.67\n3.41\n0\n1\n3\n5\n13\n▇▆▂▁▁\nA2FTALLTCHRS\n3051\n0.87\n72.86\n45.56\n0\n37\n68\n100\n230\n▇▇▅▁▁\nA2YRSADMIN\n5315\n0.77\n7.79\n5.44\n1\n3\n6\n11\n19\n▇▆▃▃▃\n\nThe 24 numeric variables pertain to the administrators experience, the hours per work they spend on different activities (working with teachers, parents, students, internal/external management, etc.). They also have data about the proportion of students enrolled in technical programs and average daily attendance by grade. Other variables are about grade repeat percentages and the proportion of seniors entering going on to higher ed. \nThe remaining categorical variables have to do with school type (private vs. public), available programs at the school, and requirements for graduation.\nCounselor Survey\nAgain we can perform similar data work for the counselor survey. Like the administrator survey, there is data for both the base year and the follow-up.\n\n\nstudentDataCounsel <- studentData %>% \n  select(C1FTCNSL:C2FBGRAD) %>%\n  mutate_all(na_if, -5) %>%\n  mutate_all(na_if, -4) %>%\n  mutate_all(na_if, -7) %>%\n  mutate_all(na_if, -8) %>%\n  mutate_all(na_if, -9)\nstudentDataCounsel <- studentDataCounsel[,colSums(is.na(studentDataCounsel))<12000]\n\n\n\nAfter dropping the majority NA variables, there are now only 282 remaining variables to consider. We can skim the numeric variables it below:\n\n\nskim(studentDataCounsel%>%select(where(is.numeric)))\n\n\nTable 5: Data summary\nName\nstudentDataCounsel %>% se…\nNumber of rows\n23503\nNumber of columns\n10\n_______________________\n\nColumn type frequency:\n\nnumeric\n10\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nC1CASELOAD\n2269\n0.90\n347.65\n130.08\n2\n270\n350\n420\n999\n▂▇▃▁▁\nC2CASELOAD\n4359\n0.81\n348.54\n133.77\n40\n260\n350\n425\n800\n▂▇▇▂▁\nC2PCTCALC\n5564\n0.76\n18.23\n18.05\n0\n6\n13\n25\n90\n▇▃▁▁▁\nC2PCTPHYS\n5699\n0.76\n32.94\n31.03\n0\n10\n20\n50\n100\n▇▃▂▁▂\nC2NUMAP\n6303\n0.73\n10.86\n6.15\n1\n6\n10\n15\n23\n▇▇▇▅▅\nC2NUMAPSCI\n6855\n0.71\n2.39\n1.52\n0\n1\n2\n4\n6\n▇▅▅▅▂\nC2NUMAPMATH\n6626\n0.72\n1.83\n0.97\n0\n1\n2\n3\n4\n▂▇▇▆▁\nC2NUMAPCOMP\n7706\n0.67\n0.25\n0.49\n0\n0\n0\n0\n2\n▇▁▂▁▁\nC2PCTAP\n7849\n0.67\n31.86\n21.35\n1\n15\n28\n43\n90\n▆▇▃▂▁\nC2NUMGRADS\n5573\n0.76\n261.69\n164.17\n10\n130\n240\n360\n650\n▇▇▇▃▃\n\nThere are only 10 variables within the Counselor survey that are numeric: CASELOAD: Average caseload for school’s counselors (in each survey year), PCTCALC: Percent of 12th graders who have taken calculus, PCTPHYS: Percent of 12th graders who have taken physics, NUMAP: Total number of AP courses offered, NUMAPSCI: Number of AP science courses offered, NUMAPMATH: Number of AP math courses offered, NUMAPCOMP: Number of AP computer science courses offered, PCTAP: Percent of current 12th graders that are currently enrolled in at least one AP course, and NUMGRADS: The number of seniors that graduated in May or June 2011.\nThe remaining categorical variables have to do with the type of support offered by the school counselors and the sort of school programs a school counselor would be involved (job fairs, work study, etc.).\nConclusions\nAfter performing this data cleaning exercise we have learned that the majority of our data is, in fact, categorical. With these smaller data subsets, it is much easier to understand the data before we begin the machine learning analysis, and we will be able to use machine learning techniques with a lesser burden by using the techniques on each survey subset.\n\n\n\n",
    "preview": "posts/2021-03-15-kristen-jordan-data-work-and-exploration/clipart.png",
    "last_modified": "2021-03-16T14:23:46+00:00",
    "input_file": {}
  },
  {
    "path": "posts/jonathan-sheng-algorithmic-demand-estimation-prediction/",
    "title": "Driving Through a Random Forest: Predicting Automobile Demand",
    "description": "Predictive Performance",
    "author": [
      {
        "name": "Jonathan Arnold",
        "url": {}
      },
      {
        "name": "Sheng Chao Ho",
        "url": {}
      }
    ],
    "date": "2021-03-15",
    "categories": [
      "Jonathan and Sheng"
    ],
    "contents": "\n\nIntroduction\nIn this post, we will use four algorithmic models to predict market shares of automobiles using price, demographic characteristics, and characteristics of the vehicles. The four algorithms we will use are LASSO, CART, Random Forest, and Boosting (we use xgboost for implementation). We will tune these models using 10-fold cross-validation and a discrete grid of hyperparameters, and select the vector of hyperparameters which gives us the smallest root mean squared error (RMSE). Then we will compare the predictive accuracy of the four models to each other, and discuss the results.\nData Preprocessing\nWe begin by loading the data:\n\n\ndf_raw <- haven::read_dta(\"Model_panel_cleaned.dta\")\n\n\n\nAs a reminder, this data contains 88 variables and 6877 observations. Many of these variables are duplicates, and some variables we’d like to use (like market share) are not included in the dataset.\nData Cleaning\nWe clean the data by first dropping a large number of variables which are either duplicates, have zero variance, or are otherwise unnecessary. We take logs of most numeric variables in order to make the distributions more symmetric. Then we clean some problematic observations in the nationality variable. Finally, we make sure that all character vectors in the data frame are converted to factors, so that the models know how to process them.\nPerhaps the most important step is calculating market share. In the style of BLP, we take the sales for each vehicle and divide it by the number of households in the United States for that year. This is based on the implicit assumption that the market size for the automobile market is all household in the US for a given year. Remember that “markets” here simply refer to a year.\nFinally, we calculate a couple of price ratios to capture some notion of cross-price elasticity in the predictive process: the ratio of the price to the average price in the market, and the ratio of the price to the average price of the same class of vehicle in the market.\n\n\ndf<- df_raw %>% \n  select(-starts_with(\"I_\"),-count_trim,-Model_id,-MY_id,\n         -nationality1,-nationality2,\n         -korea,-mexico,-netherlands,-spain,-italy,-germany,\n         -france,-uk,-sweden,-japan,-indian,-china,-canada,\n         -starts_with(\"income_\"),-gas_nominal,-gas_real,\n         -car_size,-car_volume,-hp_to_cyl,-hp_to_weight,\n         -transmission_id,-drivetype_id,-body_original,\n         -model_age,-engine_hp,-mpg_combined,-dpm_combined,\n         -curb_weight_lbs,-trim_name,-cpi,-log_mpg_combined) %>%\n  mutate(log_mpg_city=log(mpg_city)) %>%\n  mutate(log_mpg_hwy=log(mpg_hwy)) %>%\n  mutate(log_dpm_city=log(dpm_city)) %>%\n  mutate(log_dpm_hwy=log(dpm_hwy)) %>%\n  mutate(nationality=case_when(nationality%in%\n                                 c(\"Italy/US\",\"Germany/US\") ~ \"US\",\n                                  nationality == \"\" ~ \"US\",\n                                  TRUE ~ nationality)) %>%\n  select(-c(mpg_city,mpg_hwy,dpm_city,dpm_hwy)) %>%\n  mutate_if(is.character,as.factor) %>%\n  mutate(share=sales/(nb_hh*1000)) %>%\n  group_by(Year) %>%\n  mutate(own_mkt_price_ratio=price/((sum(price)-price)/(n()-1))) %>%\n  group_by(class) %>%\n  mutate(own_class_price_ratio=price/((sum(price)-price)/(n()-1))) %>%\n  ungroup %>%\n  select(-sales,-nb_hh) %>%\n  drop_na()\n\ndf<- as.data.frame(df)\n\n\n\nData Splitting\nNow we need to split the data into training and test samples, along with creating some cross-validation folds within the training set. Before we do so, let’s have a brief look at the distribution of market shares in the data:\n\n\ndf %>% ggplot(aes(x=share)) + geom_histogram(alpha=0.8) + xlab(\"Market Share\")\n\n\n\n\nThe distribution of market shares is heavily right-skewed, which can present a problem when splitting the data. We don’t want all of the high market share observations to end up in either the training or the test set. Thus, we employ stratified sampling with respect to the market share. This means that we first split up the data by market share quartiles, and sample separately from each of these quartiles. This preserves the distribution of market shares between the training and test samples.\n\n\nset.seed(123)\ndf_split <- initial_split(df, strata = share)\ndf_train <- training(df_split)\ndf_test <- testing(df_split)\ndf_folds <- vfold_cv(df_train, strata = share)\n\n\n\n\n\n\nCreating a Recipe\nIn the tidymodels framework, the basis for the model is a recipe: a set of instructions that tell the algorithm what type of \\(y=f(x)\\) formula it is modeling, and any final preprocessing that needs to occur. In our case, we want our \\(y\\), or outcome, to be market share, and our \\(x\\), or predictors, to be all of the remaining variables. We choose to exclude “year” from this list as its function in the data is simply to denote which market an observation is in.\nThere is one major issue with the data in its current form: the total number of levels for all the categorical variables (model, company, nationality, etc.) is almost 800! That translates to almost 800 extra dummy variables when fitting the models. To avoid this explosion in the number of variables, we use the “step_other” function to collapse all the factor levels below a certain threshold. This threshold was chosen by us, the modelers, and the thresholds result in the total number of variables being only slightly greater than 100.\n\n\ndemand_recipe<- recipe(formula= share ~., data=df_train) %>%\n  update_role(Year, new_role=\"Market\") %>%\n  step_other(company,threshold=0.05) %>%\n  step_other(brand,nationality,suv_class,threshold=0.02) %>%\n  step_other(model,threshold=0.0045) %>%\n  step_dummy(all_nominal())\n\n\n\n\n\n\n\nFitting the Models\nLASSO\nLASSO is a regularized linear regression model, and essentially functions as a means to accomplish variable selection algorithmically. In order to do this, a penalty is imposed, and that penalty is the hyperparameter we need to tune.\nIn order for this penalty to make sense, we have to normalize all of the predictors. Otherwise, the penalty we be applied differently depending on the scale and location of that predictor’s distribution.\n\n\n\nglmnet_recipe <- \n  demand_recipe %>%\n  step_normalize(all_predictors(), -all_nominal()) \n\nglmnet_spec <- \n  linear_reg(penalty = tune(), mixture = 1) %>% \n  set_mode(\"regression\") %>% \n  set_engine(\"glmnet\") \n\nglmnet_workflow <- \n  workflow() %>% \n  add_recipe(glmnet_recipe) %>% \n  add_model(glmnet_spec) \n\n\n\nWe tune the model using 10-fold cross-validation, and select the best model based on RMSE. Then we fit this model one last time to the training set.\n\n\nset.seed(63663)\n\nglmnet_tune <- \n  tune_grid(glmnet_workflow, \n            resamples = df_folds, \n            grid = 10) \n\nshow_best(glmnet_tune, metric = \"rmse\")\n#Best model is penalty = 2.037462e-10\n\n\nfinal_glmnet <- \n  glmnet_workflow %>%\n  finalize_workflow(select_best(glmnet_tune, metric = \"rmse\"))\n  \nglmnet_fit <- last_fit(final_glmnet, df_split)\n\n\n\n\n\n\n\n\n\n{\"columns\":[{\"label\":[\"model\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"penalty\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rmse\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"2.037462e-10\",\"3\":\"0.0005341767\"},{\"1\":\"2\",\"2\":\"1.614249e-09\",\"3\":\"0.0005341767\"},{\"1\":\"3\",\"2\":\"2.999630e-08\",\"3\":\"0.0005341777\"},{\"1\":\"4\",\"2\":\"1.036695e-07\",\"3\":\"0.0005343889\"},{\"1\":\"5\",\"2\":\"1.663465e-06\",\"3\":\"0.0005372265\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nThe above table shows the RMSE results for the top five models. We can see that the RMSE is increasing in the penalty hyperparameter, meaning that a lower penalty is superior. This corresponds to less regularization, and thus more non-zero coefficients in the regression.\n\n\n\nFinally, we run the tuned model on the test set and plot the resulting market share predictions in comparison to the actual values.\n\n\nglmnet_plot <- #Plot of predictions vs truth\n  collect_predictions(glmnet_fit) %>%\n  ggplot(aes(share, .pred)) +\n  geom_abline(lty = 2, color = \"gray50\") +\n  geom_point(alpha = 0.5, color = \"midnightblue\") +\n  coord_fixed()\n\nglmnet_plot\n\n\n\n\nThe plot above shows an adequate performance for this model. Errors are still sizable, and there even appears to be somewhat of a downward bias to the model. Predictions tend to be worse for the rarer, larger market shares.\nNow we examine variable importance in this model. What are the features that LASSO selects as most important for predicting automobile market share?\n\n\nglmnet_vip <- \n  glmnet_fit %>% \n   pluck(\".workflow\", 1) %>%   \n   pull_workflow_fit() %>% \n   vip::vip(num_features = 10)\n\nglmnet_vip\n\n\n\n\nSomewhat surprisingly, the own/class price ratio appears as the most important, followed by price. This suggests that the price relationship between a car model and its competitors inside the same class of vehicle significantly contributes to its market share.\nIn addition, we see some of the introduced dummy variables emerge as important, particular Ford and specifically its F-series pickup trucks. These trucks have unusually high market shares, so perhaps their shares are not able to be predicted just by their characteristics.\nCART\nThe next model we will use is a regression tree. The regression tree uses a greedy algorithm to perform recursive splits on the data. If allowed to grow large, these learners can have quite high variance and risk over-fitting. Thus, we use three tuning parameters to “prune” the tree: a complexity cost, a maximum tree depth, and a minimum number of observations per split.\n\n\n\ncart_recipe <- \n  demand_recipe\n\ncart_spec <- \n  decision_tree(cost_complexity = tune(), tree_depth=tune(), min_n = tune()) %>% \n  set_mode(\"regression\") %>% \n  set_engine(\"rpart\") \n\ncart_workflow <- \n  workflow() %>% \n  add_recipe(cart_recipe) %>% \n  add_model(cart_spec) \n\n\n\nWe tune the model using a discrete grid, and then fit the best model to the training data.\n\n\nset.seed(63663)\n\ncart_tune <-\n  tune_grid(cart_workflow, \n            resamples = df_folds, \n            grid = 30,\n            control = control_grid(verbose = TRUE))\n\nshow_best(cart_tune, metric = \"rmse\")\n#Best model is cost_complexity = 2.022630e-09, tree_depth = 12, min_n = 12\n\n\nfinal_cart <- cart_workflow %>%\n  finalize_workflow(select_best(cart_tune, metric = \"rmse\")) %>% fit(df_train)\n\ncart_fit <- last_fit(final_cart, df_split)\n\n\n\n\n\n\nBelow we show the results for the top 5 models.\n\n\n\n{\"columns\":[{\"label\":[\"model\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"cost_complexity\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tree_depth\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"min_n\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rmse\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"2.022630e-09\",\"3\":\"12\",\"4\":\"12\",\"5\":\"0.0004174716\"},{\"1\":\"2\",\"2\":\"1.257329e-07\",\"3\":\"11\",\"4\":\"3\",\"5\":\"0.0004367383\"},{\"1\":\"3\",\"2\":\"4.608657e-06\",\"3\":\"15\",\"4\":\"23\",\"5\":\"0.0004383926\"},{\"1\":\"4\",\"2\":\"2.564866e-07\",\"3\":\"14\",\"4\":\"26\",\"5\":\"0.0004563562\"},{\"1\":\"5\",\"2\":\"1.029368e-04\",\"3\":\"14\",\"4\":\"26\",\"5\":\"0.0004577715\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nWe can see that the RMSE decreases as complexity cost decreases, minimum number of observations per node decreases, and tree depth decreases (slightly).\n\n\n\nLet’s examine the tuned model’s predictive accuracy on the test set. Below we plot the predicted vs. actual market shares.\n\n\ncart_plot <- #Plot of predictions vs truth\n  collect_predictions(cart_fit) %>%\n  ggplot(aes(share, .pred)) +\n  geom_abline(lty = 2, color = \"gray50\") +\n  geom_point(alpha = 0.5, color = \"midnightblue\") +\n  coord_fixed()\n\ncart_plot\n\n\n\n\nThe horizontal lines of predictions demonstrate the discretizing effect that CART tends to have on the outcome space. However, the model appears to have a decent fit, albeit with fairly high variance.\nHere is the variable importance plot for CART:\n\n\ncart_vip <- \n  cart_fit %>% \n  pluck(\".workflow\", 1) %>%   \n  pull_workflow_fit() %>% \n  vip::vip(num_features = 10)\n\ncart_vip\n\n\n\n\nWe see some similarities with LASSO, like the presence of the F-series dummy again and the prominence of price, but some variables are reordered and others are new altogether. Note that variables related to car size and volume seem to take a more prominent role here.\nDecision trees generally come with an added benefit of interpretability, so let’s take a closer look at the model itself:\n\n\n\n\n\nrpart.plot(final_cart$fit$fit$fit)\n\n\n\n\nThis is quite a large tree, and a bit difficult to interpret. We may be able to faintly make out that the first split is along the F-series dummy, and further early splits pertain to price and price ratios, but much more than that becomes quite complex. Perhaps the interpretability advantage of a single tree is not so significant in our case.\nRandom Forest\nWith this relative lack of interpretability in mind, we will take it a few steps further by fitting a random forest to our data. Here we will tune just a couple of parameters: mtry, which is the number of variables considered at each split point, and min_n, which is the minimum number of observations per split. We don’t tune the number of trees; instead, we select the sufficiently large number of 500.\n\n\n\nrf_recipe <- \n  demand_recipe\n\nrf_spec <- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 500) %>% \n  set_mode(\"regression\") %>% \n  set_engine(\"ranger\") \n\nrf_workflow <- \n  workflow() %>% \n  add_recipe(rf_recipe) %>% \n  add_model(rf_spec) \n\n\n\nWe will now tune the model using 10-fold cross-validation.\n\n\nset.seed(63663)\n\nrf_tune <- tune_grid(rf_workflow, \n                     resamples = df_folds, \n                     grid = 20)\n\nshow_best(rf_tune, metric = \"rmse\")\n#Best model is mtry = 10, min_n = 4\n\n\nfinal_rf <- rf_workflow %>%\n  finalize_workflow(select_best(rf_tune, metric = \"rmse\"))\n\nrf_fit <- last_fit(final_rf, df_split)\n\n\n\n\n\n\n\n\n\n{\"columns\":[{\"label\":[\"model\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"mtry\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"min_n\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rmse\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"42\",\"3\":\"3\",\"4\":\"0.0002960400\"},{\"1\":\"2\",\"2\":\"76\",\"3\":\"6\",\"4\":\"0.0003004483\"},{\"1\":\"3\",\"2\":\"58\",\"3\":\"6\",\"4\":\"0.0003007966\"},{\"1\":\"4\",\"2\":\"46\",\"3\":\"9\",\"4\":\"0.0003074919\"},{\"1\":\"5\",\"2\":\"87\",\"3\":\"12\",\"4\":\"0.0003140362\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nThis time-consuming process produces the above results for the top five models. We see overall better results with a smaller number of variables considered at each split, and a smaller number of observations per split - deeper trees.\n\n\n\nFinally, we run the best model on the test set and plot the predictions vs. the actual market shares.\n\n\nrf_plot <- #Plot of predictions vs truth\n  collect_predictions(rf_fit) %>%\n  ggplot(aes(share, .pred)) +\n  geom_abline(lty = 2, color = \"gray50\") +\n  geom_point(alpha = 0.5, color = \"midnightblue\") +\n  coord_fixed()\n\nrf_plot\n\n\n\n\nThese are quite stunning results, compared to the previous models. The random forest demonstrates quite low bias and low variance.\nLet’s have a look at what variables are producing this impressive predictive accuracy by plotting the variable importances:\n\n\nrf_prep<- prep(rf_recipe)\n\nrf_final<- final_rf %>% pull_workflow_spec()\n\nrf_vip<- rf_final %>%\n  set_engine(\"ranger\", importance=\"permutation\") %>%\n  fit(share ~ ., data=juice(rf_prep) %>% select(-Year)) %>%\n  vip()\n\nrf_vip\n\n\n\n\nWe see many of the same variables as before, with some exceptions. Note the extremely high importance of “company_other”: this variable differentiates models produced by the largest automobile companies from those produced by one of the many smaller companies. It is fairly easy to see why this variable might thus be useful for predicting market share.\nAlso note the introduction of the “nb_bodystyle” variable, which counts the number of different classes are accounted for in the various trims of a model. If a model has more than one bodystyle represented among its trims, that model is typically a fairly important model for that brand. In other words, the brand has invested considerably in developing variations on that particular model. Thus, it is sensible that this variable would be predictive of market share.\nBoosting\nThe final algorithm we will try is a boosted tree, implemented using the xgboost algorithm. Boosting, as opposed to random forest, involves quite a bit of tuning: here, we tune six parameters as listed in the code below.\n\n\n\nxgb_recipe <- \n  demand_recipe \n\nxgb_spec <- \n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"regression\") %>% \n  set_engine(\"xgboost\") \n\nxgb_workflow <- \n  workflow() %>% \n  add_recipe(xgb_recipe) %>% \n  add_model(xgb_spec) \n\n\n\nWe tune them using a discrete grid, and examine the results of the top five models.\n\n\nset.seed(82993)\n\nxgb_tune <- tune_grid(xgb_workflow, resamples = df_folds, grid = 60)\n\nshow_best(xgb_tune, metric = \"rmse\")\n\nfinal_xgb <- xgb_workflow %>%\n  finalize_workflow(select_best(xgb_tune, metric = \"rmse\"))\n\nxgb_fit <- last_fit(final_xgb, df_split)\n\n\n\n\n\n\n\n\n\n{\"columns\":[{\"label\":[\"trees\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"min_n\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tree_depth\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"learn_rate\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"loss_reduction\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sample_size\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rmse\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1968\",\"2\":\"36\",\"3\":\"8\",\"4\":\"0.006525845\",\"5\":\"1.135571e-07\",\"6\":\"0.6979129\",\"7\":\"0.0003977069\"},{\"1\":\"1888\",\"2\":\"35\",\"3\":\"12\",\"4\":\"0.029047411\",\"5\":\"1.841420e-09\",\"6\":\"0.2601197\",\"7\":\"0.0004080520\"},{\"1\":\"1462\",\"2\":\"20\",\"3\":\"3\",\"4\":\"0.016690861\",\"5\":\"9.272890e-10\",\"6\":\"0.5241768\",\"7\":\"0.0004119114\"},{\"1\":\"1913\",\"2\":\"17\",\"3\":\"1\",\"4\":\"0.048602925\",\"5\":\"1.223076e-05\",\"6\":\"0.7418305\",\"7\":\"0.0005697625\"},{\"1\":\"1754\",\"2\":\"39\",\"3\":\"2\",\"4\":\"0.081288367\",\"5\":\"7.430793e-01\",\"6\":\"0.5699012\",\"7\":\"0.0008602943\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nThere is actually quite significant variability in the performance of these models. We see that the best model involves a quite large number of trees, a fairly large minimum number of observations with a moderate tree depth, low learning rate, moderate loss reduction, and large sample size. It’s a bit difficult to interpret any patterns from these hyperparameters since there are so many of them, but we can at least note the large min_n compared to CART and random forest, suggesting a shallower tree. This is what we’d expect from a boosting algorithm.\n\n\n\nFinally, we run the model on the test set and plot its predictive accuracy:\n\n\nxgb_plot <- #Plot of predictions vs truth\n  collect_predictions(xgb_fit) %>%\n  ggplot(aes(share, .pred)) +\n  geom_abline(lty = 2, color = \"gray50\") +\n  geom_point(alpha = 0.5, color = \"midnightblue\") +\n  coord_fixed()\n\nxgb_plot\n\n\n\n\nBoosting performs reasonably well - though it is not quite at the level of the random forest. The variance appears to be a bit higher than random forest, while the bias is comparable. Boosting does, however, perform better than both LASSO and CART.\nWe now plot the variable importances for the boosted model.\n\n\nxgb_vip <- \n  xgb_fit %>% \n  pluck(\".workflow\", 1) %>%   \n  pull_workflow_fit() %>% \n  vip::vip(num_features = 10)\n\nxgb_vip\n\n\n\n\nAgain we see somewhat similar results, with Ford, price, and car volume making their usual appearances. We do see the introduction of a couple of new variables, like the pickup truck class and the model age, but overall the results are not extremely different from the other models.\nSummary and Conclusion\nWe’ve now fit and tested four different algorithmic models to predict the market shares of automobiles in the United States. Let’s review their overall performances and compare:\n\n\n\nmetrics_df <- \n  bind_rows(collect_metrics(glmnet_fit) %>% mutate(algo = \"LASSO\"),\n            collect_metrics(cart_fit) %>% mutate(algo = \"CART\"),\n            collect_metrics(rf_fit) %>% mutate(algo = \"Random Forest\"),\n            collect_metrics(xgb_fit) %>% mutate(algo = \"XG Boost\"),\n  )\n\nmetrics_plot <- \n  metrics_df %>% \n  ggplot(aes(algo,.estimate)) +\n  geom_point() +\n  facet_grid(.metric ~ ., scales = \"free_y\")\n\nmetrics_plot\n\n\n\n\nClearly, boosting and random forest dominate LASSO and CART in both RMSE and R-squared. We see exceptional performance from random forest, which boasts an R-squared of greater than 0.9. The RMSE for these top two models is about an order of magnitude lower than the average market share. Thus, the predictive portion of this project has been quite successful: we have proven it is possible to use algorithmic models to accurately predict market shares from price, characteristics, and demographic data.\nWhat we have seen in terms of interpretability has been less impressive. Variable importance plots give us some insight into the black boxes of these models, and we’ve learned that certain variables seem to appear again and again: price, Ford, F-series, company dummies. But though price appears in these plots, we don’t have a notion of its effect size, or what the demand elasticity is for these vehicles. Even CART, with its relative ease of interpretability, was hardly readable due to its complexity. Thus, in order to examine inferential questions about demand estimation we will need to try out some different algorithmic techniques in our coming posts, like causal random forests or double machine learning.\n\n\n\n",
    "preview": "posts/jonathan-sheng-algorithmic-demand-estimation-prediction/jonathan-sheng-algorithmic-demand-estimation-prediction_files/figure-html5/RF_plot_pred_and_vip-1.png",
    "last_modified": "2021-03-16T14:23:46+00:00",
    "input_file": {}
  },
  {
    "path": "posts/jonathan-sheng-algorithmic-demand-estimation-exploratory/",
    "title": "Fords, Fiats, and Figures: Exploring Automobile Data",
    "description": "Exploratory Analysis",
    "author": [
      {
        "name": "Jonathan Arnold",
        "url": {}
      },
      {
        "name": "Sheng Chao Ho",
        "url": {}
      }
    ],
    "date": "2021-03-09",
    "categories": [
      "Jonathan and Sheng"
    ],
    "contents": "\n\n\n\nIntroduction to the Data\nWe are working with data on US automobile sales and characteristics. The dataset is a panel with around 7,000 observations, collected annually from 1985 to 2015. There are 7 categorical characteristics, like nationality and transmission type, and about 30 numerical characteristics, like miles per gallon and size.\nIn this data, an observation is a model-year pair, where “model” is a distinct level of aggregation relative to “brand” or “trim.” To be more specific, an individual automobile may be identified at several different levels: its brand, model, trim, and of course at the highest level of granularity, its VIN (vehicle identification number). For example, a Ford F-150 has a brand identifier (Ford), a model identifier (F), and a trim identifier (150). Though we have characteristics data at the trim level, we only have sales data at the model level. Thus, we’ve aggregated the characteristics data to be at the model level in this dataset. We used a “flagship” aggregation rule: we use the characteristics for the flagship trim of each model as the aggregate characteristics. This aggregation rule may be revisited later.\nIn addition to automobile sales and characteristics, we also have yearly data on several US macroeconomic indices. These include gas prices, household income distributions, and foreign exchange rates for countries from which automobiles may be imported.\nBelow we show some summary data for selected variables, at the year level (for ease of exposition, we only show every other year):\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#ncwkivqrme .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ncwkivqrme .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ncwkivqrme .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ncwkivqrme .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ncwkivqrme .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ncwkivqrme .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ncwkivqrme .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ncwkivqrme .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ncwkivqrme .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ncwkivqrme .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ncwkivqrme .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ncwkivqrme .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ncwkivqrme .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ncwkivqrme .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#ncwkivqrme .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#ncwkivqrme .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ncwkivqrme .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#ncwkivqrme .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ncwkivqrme .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#ncwkivqrme .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ncwkivqrme .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ncwkivqrme .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ncwkivqrme .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ncwkivqrme .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ncwkivqrme .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ncwkivqrme .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ncwkivqrme .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#ncwkivqrme .gt_left {\n  text-align: left;\n}\n\n#ncwkivqrme .gt_center {\n  text-align: center;\n}\n\n#ncwkivqrme .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ncwkivqrme .gt_font_normal {\n  font-weight: normal;\n}\n\n#ncwkivqrme .gt_font_bold {\n  font-weight: bold;\n}\n\n#ncwkivqrme .gt_font_italic {\n  font-style: italic;\n}\n\n#ncwkivqrme .gt_super {\n  font-size: 65%;\n}\n\n#ncwkivqrme .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nYear-Level Summary Statistics, Selected Variables\n    \n    Year\n      No. Models\n      No. Brands\n      Mean Price\n      No. Sales\n      Top Nationality\n      Mean MPG\n      Mean HP\n      Mean Length\n    1985\n      182\n      34\n      9454.428\n      15163386\n      US\n      23.84048\n      102.8360\n      183.6789\n    1987\n      196\n      38\n      9994.751\n      14934768\n      US\n      23.48636\n      108.9208\n      181.3905\n    1989\n      202\n      39\n      10671.578\n      14917530\n      US\n      23.12375\n      121.2554\n      185.7974\n    1991\n      209\n      41\n      10673.387\n      12378014\n      US\n      22.63481\n      127.8219\n      184.6663\n    1993\n      200\n      38\n      10817.916\n      13461858\n      US\n      22.83412\n      135.5796\n      185.3026\n    1995\n      193\n      39\n      11469.942\n      14588646\n      US\n      22.46068\n      144.2261\n      188.2647\n    1997\n      201\n      38\n      12370.492\n      14866421\n      US\n      21.96488\n      160.9176\n      192.9850\n    1999\n      204\n      38\n      12555.160\n      16653783\n      US\n      21.77168\n      167.7466\n      192.0241\n    2001\n      226\n      39\n      12379.414\n      16523184\n      US\n      21.45636\n      178.2513\n      192.8912\n    2003\n      229\n      39\n      12714.017\n      16475475\n      US\n      21.46181\n      187.1438\n      194.5159\n    2005\n      247\n      38\n      12587.862\n      17117875\n      US\n      21.96537\n      196.6551\n      194.1015\n    2007\n      260\n      38\n      11896.931\n      16053692\n      US\n      23.07849\n      201.7121\n      193.0215\n    2009\n      254\n      38\n      12321.794\n      10051333\n      US\n      24.82349\n      200.4500\n      191.0952\n    2011\n      247\n      36\n      12121.126\n      12364086\n      Japan\n      26.01192\n      209.4017\n      191.6562\n    2013\n      252\n      35\n      12108.032\n      15251400\n      Japan\n      29.29800\n      211.0099\n      191.0271\n    2015\n      248\n      35\n      12236.018\n      16827881\n      Japan\n      30.13905\n      207.5616\n      191.2211\n    \n\nAll means are sales-weighted.\nNote that the total number of models in the dataset is almost 700, which means that there is significant variation in the types of models available each year. However, the number of brands is fairly constant across years, with a slight decline towards the end of the time period.\nPrices are rising throughout the time period (note that prices are in 1982 dollars). Sales are quite variable; note in particular the sharp decline in sales in 2009 (likely due to the recession). Finally, note that the most common nationality of car by 2010 was Japan, while it had been the United States for the first 25 years of the data.\nMarket Shares\nSince we’re interested in demand estimation a la BLP, it’s worth examining our data in the context of market shares. Just like BLP, we will treat each year as a market. Market shares can thus be calculated at the model level by dividing sales by the total sales for that year. For the purposes of exploratory analysis, we will ignore analyzing the so-called outside option market share.\nBelow we use a treemap to showcase the median market shares for each brand, grouped together by company. In addition, the median price (inflation-adjusted) for each brand is denoted by its color.\n\n\n\nClearly, the top five or six companies (Ford, GM, Honda, etc.) dominate the US automobile industry, making up around three-quarters of the market in terms of sales. This is perhaps an apt illustration of the Pareto principle: around 80 percent of the revenue is made by around 20 percent of the companies.\nIn addition, this principle is somewhat replicated within companies. We see many larger (and even smaller) manufacturers making most of their sales from their “baseline” brand; for example, think Chevrolet for General Motors or Toyota for Toyota. Then, each company may branch out into other, smaller brands, typically first choosing to create a luxury brand: think Cadillac for General Motors or Lexus for Toyota. The largest companies have several brands appealing to more niche markets: think of the cost-conscious Saturn for General Motors or the outdoorsy Jeep brand for Fiat Chrysler.\nWhat about shares at the model level? Below we plot shares and inflation-adjusted prices for each model across all years.\n\n\n\nA demand curve doesn’t jump off the page from this graph, but we shouldn’t expect it to. Partially this could be due to simultaneity, but also remember that this is a differentiated products market. Thus, our analysis will need to control for different characteristics of the cars in order to estimate a reasonable demand curve.\nThough we can’t visually see the demand curve from this plot, we can make a note of a couple of interesting facts about the automobile market. First, we can clearly see that models with high market share tend to be on the cheaper side - though perhaps not the cheapest. This matches well with the basic intuition that lower prices = higher demand. And second, we see that models with extremely high prices, like Porsches or Jaguars, tend to have rather low market share. This also matches up well with our intuition from the law of demand.\nCharacteristics\nIn order to analyze the data further, we will need to divide up the automobile models by their characteristics. Here, we’ll focus on a few important pieces of information we have in our data: nationality, class, and efficiency.\nNationality\nA total of eleven nationalities of automobile manufacturers are present in our data. The below plot shows how their market shares have evolved over time.\n\n\n\nThe US automobile industry is dominated by domestic automobiles and automobiles from three other countries: Japan, Germany, and Korea. However, domestic manufacturers have over time lost their majority share in the market, mainly being replaced by the growth of Japanese and Korean manufacturers.\nA reasonable question to ask would be whether this radical change in market share by nationality was caused by price changes. To attempt to answer that question, we plot the median price of automobile models by nationality over time:\n\n\n\nThis is an interesting result: the prices of Japanese and US automobiles track each other extremely closely throughout the entire time period. The price of German automobiles somewhat decreases towards the end of the period, which does match up with an overall increase in German market share, but the explosion of Japanese automobiles in the US market is still unexplained.\nThere have been many articles and papers written on the reasons for Japan’s growing dominance in the automobile industry, and most of them focus on the desirable characteristics of the Japanese automobiles relative to those from other countries. We have data on many such characteristics, but we will show one as an example of how automobiles differ systematically in characteristics by nationality.\nCustomers and reviewers of Japanese automobiles often discuss the relatively light weight of Japanese cars, relative to American or German counterparts. Below we plot the median prices and weights of cars from each of the four main nationalities for each year of our data.\n\n\n\nThis plot shows clear separations between the nationalities on the weight dimension. Japanese and Korean automobiles are the lightest, whereas American and German automobiles tend to be heavier. Certainly weight alone isn’t responsible for the Japanese dominance in the US market, but this at least shows us that there are some noticeable distinctions in characteristics that might help to predict market shares when we enter that stage of our project.\nClass\nThere are several different types, or classes, of automobiles sold on the market: sedans, pickup trucks, SUVs, etc. Our data contain eight such class identifiers. Over the 30-year time period that we analyze, the market composition by class has changed signficantly. See the following plot for a summary of the relevant trends:\n\n\n\nOverall, the most stark trend is the decreasing market share of sedans, and the increasing market share of SUVs. The increasing market share of SUVs is a topic of some significant discussion. Popular explanations are that SUVs offer the family-friendly size of minivans with better style, and that the high driving position is desirable to buyers. Interestingly, little is said about price; in fact, SUVs are rather more expensive and less efficient than their sedan or minivan counterparts. Clearly, characteristics like size and style matter considerably for automobile demand.\nDoes the demand curve differ by class? Take a look at the following (winsorized) plot to see:\n\n\n\nEach point in the plot represents a model. This plot gives us some interesting intuition about demand elasticities across different classes of vehicles. For example, demand for minivans and pickup trucks appears almost flat, implying a very elastic demand curve. Particularly for minivans, this integrates well with our intuition about these types of vehicles: buyers are purchasing these vehicles for practical purposes, and are fairly cost-sensitive.\nCoupes, on the other hand, tell a different story. While there appears to be a flat portion of the demand curve, there is also an almost vertical portion. Towards the top, you may find expensive sports cars like Porsches and Jaguars. These vehicles are probably purchased by buyers who are looking for style and luxury over cost, and thus have a more inelastic demand.\nSedans and SUVs are the default vehicles for most US buyers, and thus seem to have a demand curve that falls somewhere in between the former two categories. While many options are available for cost-conscious buyers, we can see that there are more expensive luxury versions available, and demand for these versions is less elastic.\nEfficiency\nAs we’ve seen, automobile characteristics like nationality and class have been changing significantly from 1985 to 2015, and these characteristics matter to consumers. But at least superficially, they have little to do with how a given car actually performs. For this information, we can turn to metrics such as horsepower and fuel efficiency.\nMetrics like horsepower give information about the power of a car’s engine; loosely, the higher the horsepower, the faster a car can drive and the faster it accelerates. However, it is also important to consider the ratio of horsepower to weight, as a lower horsepower but lighter car can sometimes outrun a heavier, higher horsepower vehicle.\nThe number of cylinders in the engine is a similar metric: the more cylinders, the more power the engine tends to have. However, the differences have become smaller as new technologies have improved engine efficiency.\nFinally, the price you pay for a more powerful engine, whether measured in horespower of number of cylinders, is typically a loss of fuel efficiency. This can significantly increase the cost of owning and operating the vehicle.\nOver time, we see some striking trends in these metrics:\n\n\n\nHorsepower has significantly increased over time, even when accounting for changes in car weight. The median number of cylinders started out at 4, increased to 6, and in recent years has returned to 4. All the while, the median miles per gallon was fairly constant until the mid-2000s, when it began to significantly increase. We might conjecture that consumers began to value fuel efficiency more than they did earlier. In addition, the introduction of hybrid and electric cars to the market would surely increase the median miles per gallon.\nDoes horsepower correlate with market share? We might surmise that if customers value horsepower, we would see a positive correlation with horsepower and market share. However, the data tells a different story:\n\n\n\nThere’s no obvious association here. By the way, this isn’t unique to horsepower - even the fuel efficiency variables show rather little association with market share.\nOn the other hand, when we look at the association between horsepower and price, we see a much stronger correlation:\n\n\n\nThis positive correlation is fairly consistent over time. Thus, while factors like horsepower may not be strong predictors of market share, they may still be correlated with price.\n\n\n\n",
    "preview": "posts/jonathan-sheng-algorithmic-demand-estimation-exploratory/prev_image.jpg",
    "last_modified": "2021-03-16T14:23:46+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-04-three-rules-of-r/",
    "title": "Everything in R is an Object",
    "description": "The First Deep Truth of R",
>>>>>>> 90861b92ad3cad3aafc2ce29a84ea7e697965064
    "author": [
      {
        "name": "Amit Gandhi",
        "url": {}
      }
    ],
<<<<<<< HEAD
    "date": "2021-02-28",
    "categories": [
      "lecture"
    ],
    "contents": "\n\n\n\nTopics:\nbibliography (Jonathan)\nFootnotes\nAsides\nHeaders and levels\nmarkdown tables\nrendering R tables\ninserting images, hyperlinks, boldface lettering, etc.\nunderstanding the structure of YAML metadata\ncode chunk options\nWhat is YAML?\nThe initial portion of your Rmarkdown document, fenced in between the 3 dashes --- on the top and bottom, a represents the YAML metadata or YAML frontmatter of the document. It is named according to the fact the top section of the document is written in the YAML language syntax - YAML is an recursive acronym that stands for YAML ain’t markup language.\nThe metadata defined by the code defines properties of the document that control aspects of its content, appearance, and formatting. Much of the ability to extend and customize the functionality of an Rmarkdown document arises from a suitable specification of the YAML metadata, and hence it is worth some investment of effort to learn the fundamentals.\nThe general language guide is a useful reference, and the connection between R and YAML is best appreciated from the vignette associated with the ymlthis package.\nThe basic idea of YAML is to collect as data a set of key value pairs key: value, e.g.,\n---\nauthor: Amit Gandhi\n---\nThe structure of metadata is isomorphic to a named list in R. In particular we can convert from a list to a YAML specification.\n\n\nmetaDat <- list(author = \"Amit Gandhi\")\nyml(metaDat)\n\n\n---\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\n---\n\ndraw_yml_tree(metaDat)\n\n\n└── author: Amit Gandhi\n\nOr vice-versa, the metadata of a document can be retreived as a named list in R\n\n\ndocDat <- rmarkdown::metadata\nstr(docDat)\n\n\nList of 9\n $ title      : chr \"Elements of Rmarkdown and R\"\n $ description: chr \"A look at some of the elements of style for your blog posts.\\n\"\n $ author     :List of 1\n  ..$ :List of 1\n  .. ..$ name: chr \"Amit Gandhi\"\n $ date       : chr \"02-28-2021\"\n $ output     :List of 1\n  ..$ distill::distill_article:List of 1\n  .. ..$ self_contained: logi FALSE\n $ css        : chr \"styles.css\"\n $ params     :List of 1\n  ..$ year:List of 1\n  .. ..$ value: int 80\n $ preview    : chr \"https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/rmarkdown.png\"\n $ categories : chr \"lecture\"\n\nThe other key idea is that of nesting - a field in the YAML frontmatter can have other key-value pairs as its value. The nesting is indicated by an indented space\n---\nauthor: Amit Gandhi\noutput: distill::article:\n          self_contained: true\n\n---          \nThe analogous data structure in R is a nested list\n\n\nmetaDat <- list(author = \"Amit Gandhi\", output = list(`distill::article` = list(self_contained = \"TRUE\" ) ) )\nyml(metaDat)\n\n\n---\nauthor: Amit Gandhi\noutput:\n  distill::article:\n    self_contained: 'TRUE'\ndate: '`r format(Sys.Date())`'\n---\n\nThe hierarchical structure can be visualized as\n\n\ndraw_yml_tree(metaDat)\n\n\n├── author: Amit Gandhi\n└── output:\n    └── distill::article:\n        └── self_contained: 'TRUE'\n\nTo understand the functionality the YAML nested syntax is achieving, observe that the value of the field outpt in the frontmatter indicates the function used to render the Rmarkdown file. The function in this case is distill::article. If we examine the options to this function, we can see many potential arguments.\n\n\nhelp_console(\"distill_article\", \"distill\", format = \"html\")\n\n\n\ndistill_article\n\n\nR Documentation\n\n\nR Markdown format for Distill articles\n\n\nDescription\n\n\nScientific and technical writing, native to the web.\n\n\nUsage\n\n\ndistill_article(\n  toc = FALSE,\n  toc_depth = 3,\n  toc_float = TRUE,\n  fig_width = 6.5,\n  fig_height = 4,\n  fig_retina = 2,\n  fig_caption = TRUE,\n  dev = \"png\",\n  smart = TRUE,\n  self_contained = TRUE,\n  highlight = \"default\",\n  highlight_downlit = TRUE,\n  mathjax = \"default\",\n  extra_dependencies = NULL,\n  theme = NULL,\n  css = NULL,\n  includes = NULL,\n  keep_md = FALSE,\n  lib_dir = NULL,\n  md_extensions = NULL,\n  pandoc_args = NULL,\n  ...\n)\n\n\nArguments\n\n\ntoc\n\n\n\nTRUE to include a table of contents in the output\n\n\n\ntoc_depth\n\n\n\nDepth of headers to include in table of contents\n\n\n\ntoc_float\n\n\n\nFloat the table of contents to the left when the article is displayed at widths > 1000px. If set to FALSE or the width is less than 1000px the table of contents will be placed above the article body.\n\n\n\nfig_width\n\n\n\nDefault width (in inches) for figures\n\n\n\nfig_height\n\n\n\nDefault height (in inches) for figures\n\n\n\nfig_retina\n\n\n\nScaling to perform for retina displays (defaults to 2, which currently works for all widely used retina displays). Set to NULL to prevent retina scaling. Note that this will always be NULL when keep_md is specified (this is because fig_retina relies on outputting HTML directly into the markdown document).\n\n\n\nfig_caption\n\n\n\nTRUE to render figures with captions\n\n\n\ndev\n\n\n\nGraphics device to use for figure output (defaults to png)\n\n\n\nsmart\n\n\n\nProduce typographically correct output, converting straight quotes to curly quotes, — to em-dashes, – to en-dashes, and … to ellipses.\n\n\n\nself_contained\n\n\n\nProduce a standalone HTML file with no external dependencies, using data: URIs to incorporate the contents of linked scripts, stylesheets, images, and videos. Note that even for self contained documents MathJax is still loaded externally (this is necessary because of its size).\n\n\n\nhighlight\n\n\n\nSyntax highlighting style. Supported styles include “default”, “rstudio”, “tango”, “pygments”, “kate”, “monochrome”, “espresso”, “zenburn”, “breezedark”, and “haddock”. Pass NULL to prevent syntax highlighting.\n\n\n\nhighlight_downlit\n\n\n\nUse the downlit package to highlight R code (including providing hyperlinks to function documentation).\n\n\n\nmathjax\n\n\n\nInclude mathjax. The “default” option uses an https URL from a MathJax CDN. The “local” option uses a local version of MathJax (which is copied into the output directory). You can pass an alternate URL or pass NULL to exclude MathJax entirely.\n\n\n\nextra_dependencies\n\n\n\nAdditional function arguments to pass to the base R Markdown HTML output formatter html_document_base\n\n\n\ntheme\n\n\n\nCSS file with theme variable definitions\n\n\n\ncss\n\n\n\nOne or more css files to include\n\n\n\nincludes\n\n\n\nNamed list of additional content to include within the document (typically created using the includes function).\n\n\n\nkeep_md\n\n\n\nKeep the markdown file generated by knitting.\n\n\n\nlib_dir\n\n\n\nDirectory to copy dependent HTML libraries (e.g. jquery, bootstrap, etc.) into. By default this will be the name of the document with _files appended to it.\n\n\n\nmd_extensions\n\n\n\nMarkdown extensions to be added or removed from the default definition or R Markdown. See the rmarkdown_format for additional details.\n\n\n\npandoc_args\n\n\n\nAdditional command line options to pass to pandoc\n\n\n\n…\n\n\n\nAdditional function arguments to pass to the base R Markdown HTML output formatter html_document_base\n\n\n\nDetails\n\n\nDistill articles feature attractive, reader-friendly typography, flexible layout options for visualizations, and full support for footnotes and citations.\n\n\nWe can see many options associated with the function. If we want to use the default values we can simply associate the value default with the field distill::article.\n---\n<yaml>\noutput:\n  distill::distill_article: default\n<yaml>\n---\nBut if we wish to set any of the arguments, we must engage another nest of key value pairs, e.g.,\n\n\nmetaDat <- list(author = \"Amit Gandhi\", output = list(`distill::article` = list(self_contained = \"TRUE\", toc = \"TRUE\" ) ) )\nyml(metaDat)\n\n\n---\nauthor: Amit Gandhi\noutput:\n  distill::article:\n    self_contained: 'TRUE'\n    toc: 'TRUE'\ndate: '`r format(Sys.Date())`'\n---\n\ndraw_yml_tree(metaDat)\n\n\n├── author: Amit Gandhi\n└── output:\n    └── distill::article:\n        ├── self_contained: 'TRUE'\n        └── toc: 'TRUE'\n\nInstead of nested data capturing key-value pairs (which are named lists), the value of a field if its more complex than a simple value can be an unnamed vector, such as\n\n\nmetaDat <- list(author = c(\"Amit Gandhi\", \"coauthor\"), output = list(`distill::article` = list(self_contained = \"TRUE\", toc = \"TRUE\" ) ) )\nyml(metaDat)\n\n\n---\nauthor:\n- Amit Gandhi\n- coauthor\noutput:\n  distill::article:\n    self_contained: 'TRUE'\n    toc: 'TRUE'\ndate: '`r format(Sys.Date())`'\n---\n\nObserve this is captured in YAML code as\n---\nauthor:\n- A\n- B\n- C\n---\nwhere each element of the vector is entered with a new line along with a - without a need for indentation.\nA slight elaboration of this pattern is grouped data, as arises with the params field in the frontmatter\n---\nparams:\n- a: 1.0\n  input: numeric\n- data: data.csv\n  input: text\n---\nwhich is useful to group related data. The corresponding R data structure is an unnamed list, e.g.,\n\n\nlist(params = list( list(a = 1.0, input = \"numeric\"), list(data = \"data.csv\", input = \"text\") ) ) %>% yml()\n\n\n---\nparams:\n- a: 1.0\n  input: numeric\n- data: data.csv\n  input: text\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\n---\n\nThere are a few differences with R and YAML that should be recognized from our exercise. The first is that string values do not have to be quoted, unless they contain special characters, e.g.,\n---\ntitle: 'R Markdown: An Introduction'\n---\nThe string value is quoted because of the presence of the special character (a colon).\nAlso observe that whereas the logical values in R are TRUE/FALSE, in YAML they can be yes/no, true/false, or on/off.\nOn the usefulness of parameterized documents\nTHe parameter field in the YAML front matter as it allows for the creation of parameterized reports. Such report generation is especially powerful when used in conjunction with the glue and epoxy packages, which we explore below.\nLets use the BLP data (borrowing from Jonathan and Sheng’s project.)\nFirst import the data\n\n\ncarDat = read_csv(\"../jonathan-sheng-algorithmic-demand-estimation/blp.csv\")\n\n\n\nLets use a dplyr verb to count the number of observations by model_year\n\n\ncarDat %>%\n  count(model_year)\n\n\n# A tibble: 20 x 2\n   model_year     n\n *      <dbl> <int>\n 1         71   131\n 2         72   193\n 3         73    69\n 4         74    81\n 5         75   131\n 6         76    88\n 7         77   101\n 8         78    91\n 9         79    90\n10         80   125\n11         81   130\n12         82    88\n13         83    95\n14         84   211\n15         85   122\n16         86    97\n17         87   120\n18         88   101\n19         89    87\n20         90    66\n\nContrast it with the so called market variable\n\n\ncarDat %>%\n  count(market)\n\n\n# A tibble: 20 x 2\n   market     n\n *  <dbl> <int>\n 1      1    92\n 2      2    89\n 3      3    86\n 4      4    72\n 5      5    93\n 6      6    99\n 7      7    95\n 8      8    95\n 9      9   102\n10     10   103\n11     11   116\n12     12   110\n13     13   115\n14     14   113\n15     15   136\n16     16   130\n17     17   143\n18     18   150\n19     19   147\n20     20   131\n\nWe can use the glue package to weave the data together with text. Effectively we can Lets foreshadow the application.\nThe simplest application of glue is\n\n\na <- \"Amit\"\nglue(\"My name is {a}\")\n\n\nMy name is Amit\n\nwe can paste together distinct strings\n\n\na <- \"Amit\"\nb <- 712\nglue(\"My name is {a}\", \"I teach Econ {b}\")\n\n\nMy name is AmitI teach Econ 712\n\nIt is useful to add a separator\n\n\na <- \"Amit\"\nb <- 712\nglue(\"My name is {a}\", \"I teach Econ {b}\", .sep = \", \")\n\n\nMy name is Amit, I teach Econ 712\n\nThe function naturally vectorizes\n\n\na <- c(\"Amit\", \"Amit\")\nb <- c(712, 712)\nglue(\"My name is {a}\", \"I teach Econ {b}\", .sep = \", \") \n\n\nMy name is Amit, I teach Econ 712\nMy name is Amit, I teach Econ 712\n\nwhich is a character vector of length 2\nIf we want to collapse the vector into text that can be rendered in markdown we must use the results = asis chunk option and collapse the resulting vector.\n\n\nglue(\"My name is {a}\", \"I teach Econ {b}\", .sep = \", \") %>%\n  glue_collapse(\"\\n\")\n\n\nMy name is Amit, I teach Econ 712 My name is Amit, I teach Econ 712\n\nIf we want to use data masking and reference variables directly we can via glue_data()\n\n\ndemoDat <- tribble(\n  ~name, ~course,\n  \"Amit\", 712,\n  \"Amit\", 712\n)\n\ndemoDat %>% \n  glue_data(\"My name is {name}, and I teach Econ {course}\")\n\n\nMy name is Amit, and I teach Econ 712\nMy name is Amit, and I teach Econ 712\n\nWe can use the epoxy package to seamlessly blend text and code with a new engine for knitr.\n\nMy name is Amit and the course I teach is Econ 712\nMy name is Amit and the course I teach is Econ 712\n\nThe combination of epoxy and glue are powerful when connected to parameter meta data. We can thus write\n\nIn the year 1971 there were 131 car models.\nIn the year 1972 there were 193 car models.\nIn the year 1973 there were 69 car models.\nIn the year 1974 there were 81 car models.\nIn the year 1975 there were 131 car models.\nIn the year 1976 there were 88 car models.\nIn the year 1977 there were 101 car models.\nIn the year 1978 there were 91 car models.\nIn the year 1979 there were 90 car models.\nIn the year 1980 there were 125 car models.\nIn the year 1981 there were 130 car models.\nIn the year 1982 there were 88 car models.\nIn the year 1983 there were 95 car models.\nIn the year 1984 there were 211 car models.\nIn the year 1985 there were 122 car models.\nIn the year 1986 there were 97 car models.\nIn the year 1987 there were 120 car models.\nIn the year 1988 there were 101 car models.\nIn the year 1989 there were 87 car models.\nIn the year 1990 there were 66 car models.\n\nBuilding YAML objects from a pipeline\nOne of the powerful features of the Tidyverse is its natural ability to express data pipelines.\nI look at data pipelines rather broadly as the encapsulation of most computations.\nIt is helpful to recall/recognize the two fundamental rules of R:\nEverything that exists in R is an object\nEverything that happens in R is a function call\nThus a natural way to builld or develop a thought process is to start with a simple object and layer complexity by transforming the object via function calls.\nObjects in R are data structures. The interpretation of the data structure is given by the class() of the object. Applying a function to an object to yield another object can thus be seen as a manipulation of a data structure. In this fashion, general programming in R becomes a form of data analysis!\nAn important construct to aid this form of analysis is the pipe operator %>%. It passes an object into a function (in its first argument) and the object resulting from the function call can be passed to another function, and so on, resulting in a data pipeline!\nLets examine this process with the ymlthis package. We have already seen that YAML metadata maps to an R data structure (effectively a named list with nested lists/vectors).\nHow can we conceptually develop the data. Lets start with the creation of a yml object\n\n\nymlDat <-\n  yml()\n\n\n\nObserve the class and underlying base type.\n\n\nclass(ymlDat)\n\n\n[1] \"yml\"\n\ntypeof(ymlDat)\n\n\n[1] \"list\"\n\nWe can see the data structure named ymlDat is of class yml which is underneath the hood a list of data that can be interpreted as YAML metadata by appropriate functions. In particular functions that start with yml_*() take and return yml objects,\n\n\nyml() %>% \n  yml_title(\"Economics and ML\") %>%\n  yml_output(rmarkdown::html_document(toc = TRUE))\n\n\n---\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\ntitle: Economics and ML\noutput:\n  rmarkdown::html_document:\n    toc: true\n---\n\n\n\nyml_empty() %>%\n  yml_author(c(\"Amit GAndhi\", \"coauthor\"), affiliation = \"University of Pennsylvania\", url = \"www.upenn.edu\") %>%\n  yml_title(\"A discussion of Rmarkdown\") %>%\n  yml_description(\"A deeper look into pipelines\") %>%\n  yml_distill_opts(\n    twitter_site = \"xxx\",\n    collection = distill_collection(\n      share = c(\"twitter\", \"linkedin\")\n    )\n  )\n\n\n---\nauthor:\n- name: Amit GAndhi\n  affiliation: University of Pennsylvania\n  url: www.upenn.edu\n- name: coauthor\n  affiliation: University of Pennsylvania\n  url: www.upenn.edu\ntitle: A discussion of Rmarkdown\ndescription: A deeper look into pipelines\ncollection:\n  post:\n    share:\n    - twitter\n    - linkedin\ntwitter:\n  site: xxx\n---\n\nWe can add parameters\n\n\nyml() %>% \n  yml_params(country = \"Turkey\")\n\n\n---\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\nparams:\n  country: Turkey\n---\n\nWe can also add a bibliography\n\n\nyml() %>% \n  yml_citations(bibliography = \"refs.bib\")\n\n\n---\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\nbibliography: refs.bib\n---\n\nWe can instead add references manually instead of throught a .bib file\n\n\nref <- reference(\n  id = \"fenner2012a\",\n  title = \"One-click science marketing\",\n  author = list(\n    family = \"Fenner\",\n    given = \"Martin\"\n  ),\n  `container-title` = \"Nature Materials\",\n  volume = 11L,\n  URL = \"https://doi.org/10.1038/nmat3283\",\n  DOI = \"10.1038/nmat3283\",\n  issue = 4L,\n  publisher = \"Nature Publishing Group\",\n  page = \"261-263\",\n  type = \"article-journal\",\n  issued = list(\n    year = 2012,\n    month = 3\n  )\n)\n\nyml() %>%\n  yml_reference(ref)\n\n\n---\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\nreference:\n- id: fenner2012a\n  title: One-click science marketing\n  author:\n    family: Fenner\n    given: Martin\n  container-title: Nature Materials\n  volume: 11\n  URL: https://doi.org/10.1038/nmat3283\n  DOI: 10.1038/nmat3283\n  issue: 4\n  publisher: Nature Publishing Group\n  page: 261-263\n  type: article-journal\n  issued:\n    year: 2012.0\n    month: 3.0\n---\n\nWe can then reference the entry using @id in Rmarkdown.\nFinally we can create the markdown text that produces the YAML frontmatter via\n\n---\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\n---\n\nData Frame pipelines\nLets imitate the workflow, but for a data set. A tibble is a class of an object. We act on the tibble with verbs. The major verbs are given by the dplyr package.\nVerbs\nWe are going to cover a set of functions that take a data frame as an input and return a new version of the data frame.\nThese functions are called verbs and come from the dplyr package. If you are familiar with running database queries, note that all of these verbs map onto SQL commands. In fact, R can be set up so that dplyr is called over a database rather than a local data frame in memory.\nThere are over 40 verbs in the dplyr package, though most are a minor variant or specific application of another verb. We start with four of them, all of which are related to selecting and arranging rows and columns:\nselect a subset of rows from the original data set (filter)\nselect a subset of columns from the original data set (select)\nsort the rows of a data set (arrange)\nIn all verb functions, the first argument is the original data frame and the output is a new data frame. Here, we will also see the functions between and %in% to assist with the filtering command and desc to assist with arranging the rows of a data set.\nNote that verbs do not modify the original data; they operate on a copy of the original data. We have to make an explicit name for the new data set if we want to save it for use elsewhere.\nChoosing rows\nIt is often useful to take a subset of the rows of an existing data set, for example if you want to build a model on a certain subpopulation or highlight a particular part of the data in a plot.\nA standard way to take a subset of our data is to select rows based on conditions about the variables in the data set. To do this we use the filter function, which accepts a statement about variable in the data set. Only rows where the statements are true will be returned. For example, here is how we use the filter command to select the foods that have more than 150 calories grams of sugar in each serving:\n\n\nfood %>%\n  filter(calories > 150)\n\n\n# A tibble: 20 x 17\n   item       food_group calories total_fat sat_fat cholesterol sodium\n   <chr>      <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl>\n 1 Avocado    fruit           160      14.6   2.13            0      7\n 2 Chickpea   grains          180       2.9   0.309           0    243\n 3 Beef       meat            288      19.5   7.73           87    384\n 4 Catfish    fish            240      14.5   3.25           69    398\n 5 Cheese     dairy           350      26.9  16.6            83    955\n 6 Chicken    meat            237      13.4   3.76           87    404\n 7 Clam       fish            180       8     1.60           56    400\n 8 Cod        fish            211      10.8   2.22           57    401\n 9 Halibut    fish            239      17.7   3.10           59    103\n10 Lamb       meat            292      20.7   8.76           96    394\n11 Oat        grains          389       6     1.22            0      2\n12 Oyster     fish            160       7.9   1.85           57    595\n13 Penne      grains          157       0.9   0.175           0    233\n14 Pork       meat            271      17     6.17           90    384\n15 Salmon     fish            171       7.5   1.31           62    467\n16 Scallop    fish            217      10.9   2.22           54    487\n17 Sour Cream dairy           214      20.9  13.0            44     53\n18 Swordfish  fish            177       8.2   1.96           47    494\n19 Tuna       fish            153       3.9   0.811          53    366\n20 Turkey     meat            187       7     2.00           77     69\n# … with 10 more variables: carbs <dbl>, fiber <dbl>, sugar <dbl>,\n#   protein <dbl>, iron <dbl>, vitamin_a <dbl>, vitamin_c <dbl>,\n#   wiki <chr>, description <chr>, color <chr>\n\nThe output data set has only 20 rows, compared to the 62 in the original data. Other comparisons can be done with <, >= and <=. There is also a special function called between that is often useful. For example, here are the rows that have between 2 and 3 grams of total fat:\n\n\nfood %>%\n  filter(between(total_fat, 2, 3))\n\n\n# A tibble: 4 x 17\n  item  food_group calories total_fat sat_fat cholesterol sodium carbs\n  <chr> <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl> <dbl>\n1 Chic… grains          180       2.9   0.309           0    243 30.0 \n2 Quin… grains          143       2.2   0.226           0    196 26.4 \n3 Shri… fish            144       2.3   0.446         206    613  1.24\n4 Pota… vegetable       104       2     0.458           0    254 19.4 \n# … with 9 more variables: fiber <dbl>, sugar <dbl>, protein <dbl>,\n#   iron <dbl>, vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>,\n#   description <chr>, color <chr>\n\nIf you want to filter on a categorical variable, you can use the %in% operator to select specific categories. Here is the code to filter only the fish and vegetable variables:\n\n\nfood %>%\n  filter(food_group %in% c(\"fish\", \"vegetable\"))\n\n\n# A tibble: 30 x 17\n   item       food_group calories total_fat sat_fat cholesterol sodium\n   <chr>      <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl>\n 1 Asparagus  vegetable        20       0.1   0.046           0      2\n 2 String Be… vegetable        31       0.1   0.026           0      6\n 3 Bell Pepp… vegetable        26       0     0.059           0      2\n 4 Crab       fish             87       1     0.222          78    293\n 5 Broccoli   vegetable        34       0.3   0.039           0     33\n 6 Cabbage    vegetable        24       0.1   0.016           0     18\n 7 Carrot     vegetable        41       0.2   0.037           0     69\n 8 Catfish    fish            240      14.5   3.25           69    398\n 9 Cauliflow… vegetable        25       0     0.032           0     30\n10 Celery     vegetable        14       0.1   0.043           0     80\n# … with 20 more rows, and 10 more variables: carbs <dbl>,\n#   fiber <dbl>, sugar <dbl>, protein <dbl>, iron <dbl>,\n#   vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>, description <chr>,\n#   color <chr>\n\nAs with the other verbs, we can chain together multiple calls to produce more complex logic. For example, this code selects fruits that have more than 150 calories per serving:\n\n\nfood %>%\n  filter(calories > 150) %>%\n  filter(food_group %in% c(\"fruit\"))\n\n\n# A tibble: 1 x 17\n  item  food_group calories total_fat sat_fat cholesterol sodium carbs\n  <chr> <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl> <dbl>\n1 Avoc… fruit           160      14.6    2.13           0      7  8.53\n# … with 9 more variables: fiber <dbl>, sugar <dbl>, protein <dbl>,\n#   iron <dbl>, vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>,\n#   description <chr>, color <chr>\n\nWhich results in a reduced data set with only 1 row (avocados). You can also use == to test equality (food_group == \"fruit\") or != to test whether a variable is not equal to a specific value.\nIt is also possible to create a chain of calls that then get piped into a call to the ggplot function.\nFor example, here is a plot of the fruits and vegetables with the Avocado outlier removed (by limiting the maximum available total fat).\n\n\nfood %>%\n  filter(food_group %in% c(\"vegetable\", \"fruit\")) %>%\n  filter(total_fat < 10) %>%\n  ggplot() +\n    geom_point(aes(x = calories, y = total_fat, color = food_group)) +\n    geom_text_repel(aes(x = calories, y = total_fat, label = item)) +\n    scale_color_viridis_d()\n\n\n\n\nThe pattern of a starting with a data set, applying a number of transformations, and then creating a visualization of the data will become a common pattern.\nData and Layers\nNow that we know how to create a subset of our data, let’s use this new knowledge to build some interesting data visualizations. To start, create a data set that just consists of the food types that are in the meat food group:\n\n\nfood_meat <- filter(food, food_group %in% c(\"meat\"))\nfood_meat\n\n\n# A tibble: 6 x 17\n  item  food_group calories total_fat sat_fat cholesterol sodium carbs\n  <chr> <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl> <dbl>\n1 Beef  meat            288      19.5    7.73          87    384     0\n2 Chic… meat            237      13.4    3.76          87    404     0\n3 Duck  meat            132       5.9    2.32          77     74     0\n4 Lamb  meat            292      20.7    8.76          96    394     0\n5 Pork  meat            271      17      6.17          90    384     0\n6 Turk… meat            187       7      2.00          77     69     0\n# … with 9 more variables: fiber <dbl>, sugar <dbl>, protein <dbl>,\n#   iron <dbl>, vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>,\n#   description <chr>, color <chr>\n\nOne of the core ideas behind the Grammar of Graphics is that complex visualizations can be constructed by layering relatively simply elements on top of one another.\nWhat if we wanted to put together two layers where one layer uses the food data set and the other uses food_meat? To do this, we can override the default data set in a layer with the option data =. This will use a different data set within a particular layer. For example, here is how we can layer the meat data set on top of the rest of the food items.\n\n\nfood %>%\n  ggplot() +\n    geom_point(aes(x = calories, y = total_fat)) +\n    geom_point(aes(x = calories, y = total_fat), data = food_meat)\n\n\n\n\nThis plot, however, does not look any different than it would if we were just to plot all of the food together. The second layer of points just sits unassumingly on top of the rest of the data. To rectify this, we can color each layer a different color in order to distinguish them from one another. Let’s try to highlight the meat food group in a navy blue, while making the rest of the points a light grey:\n\n\nfood %>%\n  ggplot() +\n    geom_point(aes(x = calories, y = total_fat), color = \"grey85\") +\n    geom_point(aes(x = calories, y = total_fat), color = \"navy\", data = food_meat)\n\n\n\n\nWe now have a plot that shows exactly where the meats are relative to the other food items. We can further build up the plot by showing the names of just these rows of the dataset as well:\n\n\nfood %>%\n  ggplot() +\n    geom_point(aes(x = calories, y = total_fat), color = \"grey85\") +\n    geom_point(aes(x = calories, y = total_fat), color = \"navy\", data = food_meat) +\n    geom_text_repel(\n      aes(x = calories, y = total_fat, label = item),\n      color = \"navy\",\n      data = food_meat\n    )\n\n\n\n\nNotice that the code is starting to get a bit more complicated and some of the graphic layers are becoming a bit long. This is a good place to use the shorthand notation to inherit aesthetics across layers, like this:\n\n\nfood %>%\n  ggplot(aes(calories, total_fat)) +\n    geom_point(color = \"grey85\") +\n    geom_point(color = \"navy\", data = food_meat) +\n    geom_text_repel(aes(label = item), color = \"navy\", data = food_meat)\n\n\n\n\nNotice how a relatively small set of commands can be put together in different ways to build a variety of plots. Already, we are making further progress towards building informative and beautiful graphics in R!\nSelecting Columns\nIt is also possible to take a subset of the columns in a data set. To do this, we make use of the verb select. We pass it the names of the variables we want to keep in the output data set, in the (possibly new) order that we want the columns to be arranged in. Here, for example, is a new version of the foods data set containing only the food item name followed by the amount of Vitamin A and Vitamin C:\n\n\nfood %>%\n  select(item, vitamin_a, vitamin_c)\n\n\n# A tibble: 61 x 3\n   item        vitamin_a vitamin_c\n   <chr>           <dbl>     <dbl>\n 1 Apple               1         8\n 2 Asparagus          15         9\n 3 Avocado             3        17\n 4 Banana              1        15\n 5 Chickpea            0         3\n 6 String Bean        14        27\n 7 Beef                0         0\n 8 Bell Pepper        63       317\n 9 Crab                0         5\n10 Broccoli           12       149\n# … with 51 more rows\n\nWe will not need to use the select verb as often as filter because for the most part having extra variables around does not effect data visualizations or data models. However, it can be useful to displaying results and building tables.\nAs we saw above, the Vitamin A and Vitamin C columns were cut-off in the original output but are not visible in the selected data set version. Removing and reordering unneeded columns are important applied operations.\nArranging Rows\nThe verb filter determined a subset of rows to keep from the original data set. The arrange verb, in contrast, keeps all of the original data but re-orders its rows.\nSpecifically, we give it one or more variable names and it sorts the data by the first variable from smallest to largest (or alphabetically for character variables). In the case of ties, the second variable is used if given. More variables can be given to further break additional ties. Here is an example where we order the data set first by food_group and then by calories:\n\n\nfood %>%\n  arrange(food_group, calories)\n\n\n# A tibble: 61 x 17\n   item       food_group calories total_fat sat_fat cholesterol sodium\n   <chr>      <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl>\n 1 Milk       dairy            60       3.2   1.86           10     40\n 2 Yogurt     dairy            99       1.1   0.742           5     53\n 3 Sour Cream dairy           214      20.9  13.0            44     53\n 4 Cheese     dairy           350      26.9  16.6            83    955\n 5 Crab       fish             87       1     0.222          78    293\n 6 Lobster    fish             97       0.5   0.106          71    700\n 7 Haddock    fish            128       3.7   0.69           66    402\n 8 Flounder   fish            133       4.2   0.867          56    417\n 9 Shrimp     fish            144       2.3   0.446         206    613\n10 Tuna       fish            153       3.9   0.811          53    366\n# … with 51 more rows, and 10 more variables: carbs <dbl>,\n#   fiber <dbl>, sugar <dbl>, protein <dbl>, iron <dbl>,\n#   vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>, description <chr>,\n#   color <chr>\n\nIn the new data set all of the dairy products come up first followed by the fish products. Within each group, the items are sorted from the lowest to highest number of calories.\nThe ordering can be reversed (i.e., from the highest to the lowest value) be wrapping a variable in the function desc(), such as this ordering from the most saturated fat to the least:\n\n\nfood %>%\n  arrange(desc(sat_fat))\n\n\n# A tibble: 61 x 17\n   item       food_group calories total_fat sat_fat cholesterol sodium\n   <chr>      <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl>\n 1 Cheese     dairy           350      26.9   16.6           83    955\n 2 Sour Cream dairy           214      20.9   13.0           44     53\n 3 Lamb       meat            292      20.7    8.76          96    394\n 4 Beef       meat            288      19.5    7.73          87    384\n 5 Pork       meat            271      17      6.17          90    384\n 6 Chicken    meat            237      13.4    3.76          87    404\n 7 Catfish    fish            240      14.5    3.25          69    398\n 8 Halibut    fish            239      17.7    3.10          59    103\n 9 Duck       meat            132       5.9    2.32          77     74\n10 Cod        fish            211      10.8    2.22          57    401\n# … with 51 more rows, and 10 more variables: carbs <dbl>,\n#   fiber <dbl>, sugar <dbl>, protein <dbl>, iron <dbl>,\n#   vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>, description <chr>,\n#   color <chr>\n\nIn the result here, “Cheese” has been placed at the top of the data set, followed by “Sour Cream” and “Lamb”.\nGrouping and Summarizing\nA rather important verb is summarize that collapses a data frame by using summary functions. Using this verb requires that we explain exactly how the data should be summarized. We will introduce several helper functions to make this process slightly easier.\nLet’s start with an example. Here, we summarize our food data set by indicating the mean (average) value of the sugar variable across the entire data set:\n\n\nfood %>%\n  summarize(mean(sugar))\n\n\n# A tibble: 1 x 1\n  `mean(sugar)`\n          <dbl>\n1          3.42\n\nA helper function will format the column a little differently that is more usable for data analysis.\n\n\nfood %>%\n  summarize(sm_mean(sugar))\n\n\n# A tibble: 1 x 1\n  sugar_mean\n       <dbl>\n1       3.42\n\nHere we used the function sm_mean inside of the function summarize to produce the output. We specified which variable to compute the mean of by giving its name inside of the sm_mean function. The results shows us that the average amount of sugar in a 100g portion of all of the foods is 3.419g.\nIn order to compute multiple summaries at once, we can pass multiple functions together are once. For example, here we compute the mean value of three nutritional measurements:\n\n\nfood %>%\n  summarize(sm_mean(sugar), sm_mean(calories), sm_mean(vitamin_a))\n\n\n# A tibble: 1 x 3\n  sugar_mean calories_mean vitamin_a_mean\n       <dbl>         <dbl>          <dbl>\n1       3.42          114.           16.1\n\nNotice that R creates a new data set and intelligently chooses the variable names. There are a number of other useful summary functions that work similarly, such as sm_min, sm_max, sm_sum, and sm_sd (standard deviation).\nMultiple output values\nSome summary functions return multiple columns for a given variable. For example, sm_quartiles gives the five-number summary of a variable: its minimum value, the first quartile (25th percentile), the median (50th percentile), the third quartile (75th percentile), and the maximum value. As with the other summary functions, smart variable names are automatically created in R:\n\n\nfood %>%\n  summarize(sm_quartiles(calories))\n\n\n# A tibble: 1 x 5\n  calories_min calories_q1 calories_median calories_q3 calories_max\n         <dbl>       <dbl>           <dbl>       <dbl>        <dbl>\n1           12          34              87         171          389\n\nFunctions such as sm_deciles and sm_percentiles give a similar output, but with additional cutoff values. These can be useful in trying to describe the distribution of numeric variables in large data sets.\nSummarizing the data set to a single row can be useful for understanding the general trends in a data set or highlighting outliers. However, the real power of the summary function comes when we pair it with grouped manipulations. This will allow us to produce summaries within one or more grouping variables in our data set.\nWhen we use the group_by function, subsequent uses of the summarize function will produce a summary that describes the properties of variables within the variable used for grouping. The variable name(s) placed inside of the group_by function indicate which variable(s) should be used for the groups. For example, here we compute the mean number of calories of each food group:\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_mean(calories))\n\n\n# A tibble: 6 x 2\n  food_group calories_mean\n* <chr>              <dbl>\n1 dairy              181. \n2 fish               167. \n3 fruit               54.9\n4 grains             196. \n5 meat               234. \n6 vegetable           37.4\n\nNotice that the output data set contains a column for the grouping variable (food_group) and the summarized variable (calories_mean). The summarized variable name is exactly the same as the non-grouped version and the final line of code looks exactly the same as before. However, the output data set now contains six rows, one for each food group.\nAny summarization function that can be used for an ungrouped data set can also be used for a grouped data set. Also, as before, we can put multiple summary functions together to obtain different measurements of each group.\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_mean(calories), sm_mean(total_fat))\n\n\n# A tibble: 6 x 3\n  food_group calories_mean total_fat_mean\n* <chr>              <dbl>          <dbl>\n1 dairy              181.          13.0  \n2 fish               167.           7.22 \n3 fruit               54.9          1.04 \n4 grains             196.           2.56 \n5 meat               234.          13.9  \n6 vegetable           37.4          0.281\n\nNotice that the automatically produced variable names should make it clear which column corresponds to each summary function.\nThere are several additional summary functions that will be useful for analyzing data. The function sm_count takes no arguments and returns a variable called count that counts the total number of rows in the data set:\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_count())\n\n\n# A tibble: 6 x 2\n  food_group count\n* <chr>      <int>\n1 dairy          4\n2 fish          14\n3 fruit         16\n4 grains         5\n5 meat           6\n6 vegetable     16\n\nThis tells us how many times each type of food group occurs in the data set. Similarly, the function sm_na_count tells us how many values of a variable are missing:\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_count(), sm_na_count(calories))\n\n\n# A tibble: 6 x 3\n  food_group count calories_na_count\n* <chr>      <int>             <int>\n1 dairy          4                 0\n2 fish          14                 0\n3 fruit         16                 0\n4 grains         5                 0\n5 meat           6                 0\n6 vegetable     16                 0\n\nIn this case there are no missing values for the calories variable.\nThe summary function sm_paste collapses all of the values in a character variable. For example, applying this summary it to the item category after grouping by color, we can see all of the foods in the data set associated with a specific color:\n\n\nfood %>%\n  group_by(color) %>%\n  summarize(sm_paste(item))\n\n\n# A tibble: 8 x 2\n  color  item_paste                                                   \n* <chr>  <chr>                                                        \n1 brown  Chickpea; Mushroom; Oat; Quinoa; Brown Rice                  \n2 green  Asparagus; Avocado; String Bean; Bell Pepper; Broccoli; Cabb…\n3 orange Cantaloupe; Carrot; Orange; Sweet Potato; Tangerine          \n4 pink   Grapefruit; Peach; Salmon; Shrimp                            \n5 purple Grape; Plum                                                  \n6 red    Apple; Beef; Crab; Duck; Lamb; Lobster; Strawberry; Tomato; …\n7 white  Catfish; Cauliflower; Chicken; Clam; Cod; Flounder; Halibut;…\n8 yellow Banana; Cheese; Corn; Lemon; Pineapple                       \n\nFinally, note that it is possible to define your own summary functions using other R functions. To do this, we have to specify the name of the new variable explicitly. For example, here is an alternative way of computing the mean of the amount of Vitamin A within each food color:\n\n\nfood %>%\n  group_by(color) %>%\n  summarize(avg_vitamin_a = mean(vitamin_a)) %>%\n  arrange(desc(avg_vitamin_a))\n\n\n# A tibble: 8 x 2\n  color  avg_vitamin_a\n  <chr>          <dbl>\n1 orange        141.  \n2 green          11.1 \n3 pink            8.75\n4 yellow          4.4 \n5 purple          4   \n6 red             2.78\n7 white           2.63\n8 brown           0   \n\nGeometries for summaries\nWe can use summarized data sets to produce new data visualizations. For example, consider summarizing the average number of calories, average total fat, and number of items in each food groups. We can take this data and construct a scatter plot that shows the average fat and calories of each food group, along with informative labels. Here’s the code to make this visualization:\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_mean(calories), sm_mean(total_fat), sm_count()) %>%\n  ggplot(aes(calories_mean, total_fat_mean)) +\n    geom_point(aes(size = count), color = \"grey85\") +\n    geom_text_repel(aes(label = food_group))\n\n\n\n\nScatterplots are often useful for displaying summarized information. There are two additional geom types that often are useful specifically for the case of summarized data sets.\nIf we want to create a bar plot, where the heights of the bars as given by a column in the data set, we can use the geom_col layer type. For this, assign a categorical variable to the x-aesthetic and the count variable to the y-aesthetic. For example, here is a bar plot showing the number of items in each food group:\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_count()) %>%\n  ggplot() +\n    geom_col(aes(x = food_group, y = count))\n\n\n\n\nThere are two specific things to keep in mind with the geom_col layer. First, there are two color-related aes categories: the border of the bars (color) and the color used to shade the inside of the bars (fill). We can change these exactly as we did with the single color value used with scatter plots. Also, if we want to produce a bar plot with horizontal bars, this can be done by adding the special layer coord_flip() at the end of the plotting command.\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_count()) %>%\n  ggplot(aes(x = food_group, y = count)) +\n    geom_col(color = \"black\", fill = \"white\") +\n    coord_flip()\n\n\n\n\nI find that using a white fill color and a black border is often a good-looking starting point. Also, you will notice that making the bars horizontal will make it easier to read the category names when there are a larger number of categories.\nIt is possible to group a data set by multiple variables. To do this, we can provide additional variables to the group_by function separated by commas. For example, we could group the food data set into food group and color, and summarize each combination of the two:\n\n\nfood %>%\n  group_by(food_group, color) %>%\n  summarize(sm_count(), sm_mean(calories))\n\n\n# A tibble: 21 x 4\n# Groups:   food_group [6]\n   food_group color  count calories_mean\n   <chr>      <chr>  <int>         <dbl>\n 1 dairy      white      3         124. \n 2 dairy      yellow     1         350  \n 3 fish       pink       2         158. \n 4 fish       red        3         112. \n 5 fish       white      9         187. \n 6 fruit      green      4          77.2\n 7 fruit      orange     3          44.7\n 8 fruit      pink       2          35.5\n 9 fruit      purple     2          57.5\n10 fruit      red        2          42  \n# … with 11 more rows\n\nNotice that now there is one row for each combination of the two groups. However, there is no row for combinations that do not exist. So, there is no row for pink dairy products nor for white fruit. Examples of several common uses for multiple groups are given in the exercises.\nMutate verb\nThe final core dplyr verb that we will look at is used to create a new variable in our data set based on other variables that are already present. This verb is called mutate, and works by giving it the name of the variable you want to create followed by the code that describes how to construct the variable in terms of the rest of the data.\nAs an example, consider computing the number of calories in an 200g portion of each food. All of the variables in the data set are currently given as 100g portions, so to compute this we need to multiply the calories variables by 2. To do this, we use the mutate verb to name and describe a new variable calories_200g.\n\n\nfood %>%\n  mutate(calories_200g = calories * 2)\n\n\n# A tibble: 61 x 18\n   item       food_group calories total_fat sat_fat cholesterol sodium\n   <chr>      <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl>\n 1 Apple      fruit            52       0.1   0.028           0      1\n 2 Asparagus  vegetable        20       0.1   0.046           0      2\n 3 Avocado    fruit           160      14.6   2.13            0      7\n 4 Banana     fruit            89       0.3   0.112           0      1\n 5 Chickpea   grains          180       2.9   0.309           0    243\n 6 String Be… vegetable        31       0.1   0.026           0      6\n 7 Beef       meat            288      19.5   7.73           87    384\n 8 Bell Pepp… vegetable        26       0     0.059           0      2\n 9 Crab       fish             87       1     0.222          78    293\n10 Broccoli   vegetable        34       0.3   0.039           0     33\n# … with 51 more rows, and 11 more variables: carbs <dbl>,\n#   fiber <dbl>, sugar <dbl>, protein <dbl>, iron <dbl>,\n#   vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>, description <chr>,\n#   color <chr>, calories_200g <dbl>\n\nNotice that there is a new variable named calories_200g that has been added as the last column in the data set. Because it is added at the end of the data set, it gets hidden in the output shown above. Making use of select allows us to see the new values:\n\n\nfood %>%\n  mutate(calories_200g = calories * 2) %>%\n  select(item, food_group, calories, calories_200g)\n\n\n# A tibble: 61 x 4\n   item        food_group calories calories_200g\n   <chr>       <chr>         <dbl>         <dbl>\n 1 Apple       fruit            52           104\n 2 Asparagus   vegetable        20            40\n 3 Avocado     fruit           160           320\n 4 Banana      fruit            89           178\n 5 Chickpea    grains          180           360\n 6 String Bean vegetable        31            62\n 7 Beef        meat            288           576\n 8 Bell Pepper vegetable        26            52\n 9 Crab        fish             87           174\n10 Broccoli    vegetable        34            68\n# … with 51 more rows\n\nAnd now we can see that the new column has been created by doubling the number given the calories column.\nNote that mutate can also be used to modify any existing column in the data set by using the name of an extant variable. In this case the position of the variable within the tables does not change.\nThe mutate verb itself has a relatively straightforward syntax. The main challenge is knowing how to apply and chain together the various transformations that are useful within an analysis. In the next few sections, we highlight several common types of operations that we will be useful in subsequent applications.\nConditional values\nMany of the uses for the mutate verb involve assigning one value when a set of conditions is true and another if the conditions are false. For example, consider creating a new variable called sugar_level based on the relative amount of sugar in each food item. We might classify a food has having a “high” sugar level if has more than 10g of sugar per 100g serving, and a “normal” amount otherwise. In order to create this variable, we need the function if_else.\nThe if_else function has three parts: a TRUE/FALSE statement, the value to use when the statement is true, and the value to use when it is false. Here is an example to create our new variable:\n\n\nfood %>%\n  mutate(sugar_level = if_else(sugar > 10, \"high\", \"normal\")) %>%\n  select(item, food_group, sugar, sugar_level)\n\n\n# A tibble: 61 x 4\n   item        food_group sugar sugar_level\n   <chr>       <chr>      <dbl> <chr>      \n 1 Apple       fruit      10.4  high       \n 2 Asparagus   vegetable   1.88 normal     \n 3 Avocado     fruit       0.66 normal     \n 4 Banana      fruit      12.2  high       \n 5 Chickpea    grains      5.29 normal     \n 6 String Bean vegetable   1.4  normal     \n 7 Beef        meat        0    normal     \n 8 Bell Pepper vegetable   4.2  normal     \n 9 Crab        fish        0    normal     \n10 Broccoli    vegetable   1.7  normal     \n# … with 51 more rows\n\nLooking at the first rows of data, we see that apples and bananas are classified as high sugar foods, whereas the other sugar levels are given the sugar level category of “normal”.\nThe if_else function can be used to produce any number of categories by using it multiple times. Let’s modify our sugar level variable to now have three categories: “high” (over 10g), “low” (less than 1g), and “normal” (between 1g and 10g). There are several different ways to get to the same result, but I find the easiest is to start by assigning a default value and then changing the value of the new variable in sequence. For example, here some code that produces our new categories:\n\n\nfood %>%\n  mutate(sugar_level = \"default\") %>%\n  mutate(sugar_level = if_else(sugar < 1, \"low\", sugar_level)) %>%\n  mutate(sugar_level = if_else(sugar > 10, \"high\", sugar_level)) %>%\n  mutate(sugar_level = if_else(between(sugar, 1, 10), \"normal\", sugar_level)) %>%\n  select(item, food_group, sugar, sugar_level)\n\n\n# A tibble: 61 x 4\n   item        food_group sugar sugar_level\n   <chr>       <chr>      <dbl> <chr>      \n 1 Apple       fruit      10.4  high       \n 2 Asparagus   vegetable   1.88 normal     \n 3 Avocado     fruit       0.66 low        \n 4 Banana      fruit      12.2  high       \n 5 Chickpea    grains      5.29 normal     \n 6 String Bean vegetable   1.4  normal     \n 7 Beef        meat        0    low        \n 8 Bell Pepper vegetable   4.2  normal     \n 9 Crab        fish        0    low        \n10 Broccoli    vegetable   1.7  normal     \n# … with 51 more rows\n\nIn each if_else step we are telling the mutate function that if the condition is false set sugar_level equal to itself. In other words, if the condition does not hold, do not change the value of the variable.\nIn may wonder why we created a “default” value for the variable sugar_level. It would have been one less line of code to set the default value to “normal” and remove the final mutate function. The reason for the approach above is three-fold. First, it’s easier to understand what the code is doing in it’s current format because each condition (“high”, “normal”, and “low”) is explicitly coded. Secondly, it creates a nice check on our code and data. If we find a row of the output that still has the value “default” we will know that there is a problem somewhere. Finally, the code above will more safely handle the issues with missing values, and issue that we will return to shortly.\nFactors\nR has a special data type called a “factor” (abbreviated “fct”) that is specifically designed to handle categorical variables. It is typically not a good idea to store data as a factor because the resulting variables have some odd, error-producing, behaviors. However, it can be useful to create a factor as part of a mutate function just prior to creating a data visualizations.\nFor us, biggest difference between factors and character vectors is that a factor vector has a default ordered of its unique values, called the factor’s “levels”. Creating and understanding factors is useful because it allows us to change the ordering of categories within visualizations and models (which by default is done alphabetically).\nOne of the easiest ways to produce a factor variable with a given order is through the function fct_inorder. It will order the categories in the same order that they (first) appear in the data set. Combining this with the arrange function provides a lot of control over how categories become ordered. For example, the following code produces a bar plot of the food groups in our data set arranged from the largest category to the smallest category:\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_count()) %>%\n  arrange(desc(count)) %>%\n  mutate(food_group = fct_inorder(food_group)) %>%\n  ggplot() +\n    geom_col(aes(food_group, count))\n\n\n\n\nOther useful functions for manipulating categories include fct_relevel for manually putting one category first and fct_lump_n for combining together the smallest categories into a collective “Other” category.\nMutate summaries\nAll of summary functions that were introduced in the previous notebook can also be applied within the mutate version. Instead of reducing the data to a single summary row, summarizing within the mutate verb duplicates the summary statistic in each row of the data set. Here is an example of including the average number of calories across all rows of the data set:\n\n\nfood %>%\n  mutate(sm_mean(calories))\n\n\n# A tibble: 61 x 18\n   item       food_group calories total_fat sat_fat cholesterol sodium\n   <chr>      <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl>\n 1 Apple      fruit            52       0.1   0.028           0      1\n 2 Asparagus  vegetable        20       0.1   0.046           0      2\n 3 Avocado    fruit           160      14.6   2.13            0      7\n 4 Banana     fruit            89       0.3   0.112           0      1\n 5 Chickpea   grains          180       2.9   0.309           0    243\n 6 String Be… vegetable        31       0.1   0.026           0      6\n 7 Beef       meat            288      19.5   7.73           87    384\n 8 Bell Pepp… vegetable        26       0     0.059           0      2\n 9 Crab       fish             87       1     0.222          78    293\n10 Broccoli   vegetable        34       0.3   0.039           0     33\n# … with 51 more rows, and 11 more variables: carbs <dbl>,\n#   fiber <dbl>, sugar <dbl>, protein <dbl>, iron <dbl>,\n#   vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>, description <chr>,\n#   color <chr>, calories_mean <dbl>\n\nAs with any call to mutate, all of the original variables are kept in the output and the new variable is added at the end. Using select we can verify that the average calories has in fact been added to each row of the table.\n\n\nfood %>%\n  mutate(sm_mean(calories)) %>%\n  select(item, food_group, calories, calories_mean)\n\n\n# A tibble: 61 x 4\n   item        food_group calories calories_mean\n   <chr>       <chr>         <dbl>         <dbl>\n 1 Apple       fruit            52          114.\n 2 Asparagus   vegetable        20          114.\n 3 Avocado     fruit           160          114.\n 4 Banana      fruit            89          114.\n 5 Chickpea    grains          180          114.\n 6 String Bean vegetable        31          114.\n 7 Beef        meat            288          114.\n 8 Bell Pepper vegetable        26          114.\n 9 Crab        fish             87          114.\n10 Broccoli    vegetable        34          114.\n# … with 51 more rows\n\nThe power of mutate summaries becomes particularly clear when grouping the data. If we group the data set by one or more variables and apply a summary function within a mutation, the repeated summaries will be done within each group. Here is an example of adding the average calories of each food group to the data set:\n\n\nfood %>%\n  group_by(food_group) %>%\n  mutate(sm_mean(calories)) %>%\n  select(item, food_group, calories, calories_mean)\n\n\n# A tibble: 61 x 4\n# Groups:   food_group [6]\n   item        food_group calories calories_mean\n   <chr>       <chr>         <dbl>         <dbl>\n 1 Apple       fruit            52          54.9\n 2 Asparagus   vegetable        20          37.4\n 3 Avocado     fruit           160          54.9\n 4 Banana      fruit            89          54.9\n 5 Chickpea    grains          180         196. \n 6 String Bean vegetable        31          37.4\n 7 Beef        meat            288         234. \n 8 Bell Pepper vegetable        26          37.4\n 9 Crab        fish             87         167. \n10 Broccoli    vegetable        34          37.4\n# … with 51 more rows\n\nFollowing this with a filter, for example, would allow us to select all of the foods that have a less than average number of calories within their food group. We will see many examples of grouped mutate summaries throughout our applications.\nLabels and themes\nWe have seen a number of ways to create and modify data visualizations. One thing that we did not cover was how to label our axes.\nWhile many data visualization guides like to stress the importance of labelling axes, while in the exploratory phase of analysis it is often best to simply use the default labels provided by R. These are useful for a number of reasons. First, they require minimal effort and make it easy to tweak axes, variables, and other settings without spending time tweaking with the labels. Secondly, the default labels use the variable names in our dataset. When writing code this is exactly what we need to know about a variable to use it in additional plots, models, and data manipulation tasks.\nOf course, once we want to present our results to others, it is essential to provide more detailed descriptions of the axes and legends in our plot. Fortunately, this is relatively easy using the grammar of graphics.\nIn order to change the labels in a plot, we can use the labs function as an extra part of our plot. Inside the function, we assign labels to the names of aes values that you want to describe. Leaving a value unspecified will keep the default value in place. Labels for the x-axis and y-axis will be go on the sides of the plot. Labels for other aesthetics such as size and color will be placed in the legend. Here is an example of a scatterplot with labels for the three aesthetics:\n\n\nfood %>%\n  ggplot() +\n    geom_point(aes(x = calories, y = sat_fat, color = food_group)) +\n    labs(\n      x = \"Calories per 100g\",\n      y = \"Saturated Fat (grams per 100g)\",\n      color = \"Food Group\"\n    )\n\n\n\n\nNotice that the descriptions inside of the labs function is fairly long. The code here breaks it up by putting each argument on its own line (indented a further two spaces). This is good practice when using functions with a lot of arguments.\nWe can also had a title (and optional subtitle and caption) to the plot by adding these as named arguments to the labs function.\n\n\nfood %>%\n  ggplot() +\n    geom_point(aes(x = calories, y = sat_fat, color = food_group)) +\n    labs(\n      title = \"Main title\",\n      subtitle = \"A little more detail\",\n      caption = \"Perhaps the source of the data?\"\n    )\n\n\n\n\nAnother way to prepare our graphics for publication is to modify the theme of a plot. One useful option is to set the default plot to theme_minimal. As the name implies, it removes most of the clutter of other choices while keeping grid lines and other visual cues to help interpret a dataset.\nWhen presenting information for external publication, I prefer to use the theme called theme_sm based on the work of Edward Tufte. To set the theme, just call the following line of code sometime before making your plot:\n\n\ntheme_set(theme_sm())\n\n\n\nNow, when we construct a plot it will use the newly assigned theme:\n\n\nfood %>%\n  ggplot() +\n    geom_point(aes(x = sugar, y = total_fat))\n\n\n\n\nThe Tufte theme is designed to use as little “ink” as possible, thus focusing the reader on the data. It can be a bit too minimal when first exploring the dataset, but is a great tool for presenting your results.\n\n\n\n",
    "preview": "https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/rmarkdown.png",
    "last_modified": "2021-03-02T13:15:42+00:00",
=======
    "date": "2021-03-04",
    "categories": [
      "lecture"
    ],
    "contents": "\nIntroduction\nR is a rich software language for “programming with data” to quote the chief designer John Chambers (Chambers 1998) of the precursor and inspiration for R - the S programming language.\nWhile diverse in its applications, R is based on a few unifying design principles that allows one to separate the forest from the trees in developing R software for solving a problem.\nA useful summary of these principles for understanding the behavior of R code is captured by the memorable slogans:\n\nEverything in R is an object.\n— John Chambers\n\n\nEverything that happens in R is the result of a function call.\n— John Chambers\n\n\nNames have objects, objects don’t have names.\n— Hadley Wickham\n\nWe will refer to these principles as the deep truths of R.\nAlthough these principles are omnipresent in R, they are reaffirmed and take center stage in the jump from “base R” (the original, core R language) to “modern R” as formalized by the Tidyverse ecosystem of packages.1\nThe first of these principles is arguably the most important to initiate an understanding of the full trilogy, and we begin our discussion there.\nEverything in R is an Object\nEvery entity that gets used in R is an object of some kind, and all computations involve constructing and manipulating objects in some form.\nHowever, the word “object” has many connotations in computer programming, particularly in relation to “object-oriented programming.” Hence it is crucial to recognize the more general meaning of objects in R.\n“Everything in R is an object” in the sense of being a data structure that can be manipulated and analyzed. As Chambers (1998) writes, an object in R is a “dynamically created, self-describing container for data.”\nWhen complemented with the fact that R is a language designed to “program with data,” this means that everything in R is analyzable as a data. This is arguably what fundamentally distinguishes R from other languages - it achieves the capabilities of general purpose programming language through a paradigm that is centered around data structures and analysis of those structures.\nTo unpack the Chambers defintion of R objects, the two distinct ideas he raises are “containers of data” and “self-describing.”\nThese map directly to the intrinsic attributes that are associated to every R object. Every object in R has (1) a mode or type and (2) a length. These are intrinsic attributes of every R object.\n\n\nmode(1:10) #mode\n\n\n[1] \"numeric\"\n\ntypeof(1:10) #type\n\n\n[1] \"integer\"\n\nlength(1:10) #length\n\n\n[1] 10\n\nThe fact every object has a length means they are vector-like in some fashion and can be approached as a data structure, e.g., we can in principle access, manipulate, and analyze any R object through common data techniques, e.g., the data underlying an object x can be examined via a subsetting operation x[[i]] for i from 1:length(x).\nWhile this kind of data analysis and manipulation is immediate and natural in the case of numerical vectors, it can more novel and revealing when applied to different R objects.\n\n\ntypeof(quote(x+y))\n\n\n[1] \"language\"\n\nlength(quote(x+y))\n\n\n[1] 3\n\ncat(\"\\n\")\n\n\n\nfor (i in seq_along(quote(x+y))) {\n  ex <- quote(x+y)\n  cat(ex[[i]], \" \", typeof(ex[[i]]), \"\\n\" )\n}\n\n\n+   symbol \nx   symbol \ny   symbol \n\nNot all objects subsetted like vectors despite being data containers with a length. function objects are notorious in this respect:\n\n\n#What is a function\nf <- function() print(\"Hello World\")\ntypeof(f)\n\n\n[1] \"closure\"\n\nlength(f)\n\n\n[1] 1\n\n\nf[[1]]\nError in f[[1]] : object of type 'closure' is not subsettable\n\nWe can however extract the underlying data via of a function object “as a container of data” through alternative function calls:\n\n\nformals(f)\n\n\nNULL\n\nbody(f)\n\n\nprint(\"Hello World\")\n\nenvironment(f)\n\n\n<environment: R_GlobalEnv>\n\nIn addition to being containers of data, R objects are “self describing” in the Chambers definition. The key challenge with data structures of any form is to have a guide for interpreting what the underlying data mean.\n-The first clue as to the data meaning is the “base type” as given by typeof().\nOf course, the interpretation of this data depend on the object type. The mode or type separates (1) data objects from (2) language objects. The data objects have modes that include numeric integer, character, logical, etc, whereas the language objects include function, call, expression, etc.\nWhereas the mode attribute was central to R’s precursor language S, object types are a more common to distinguish different families of objects. The type of an object we will reference as its base type (to distinguish from what we will later discuss as the object’s “class,” which is an enrichment of the object’s base type).\nThere are a fixed set of 25 types defined by core-R. They are listed below, categorized by their distinct data interpretation.\nVectors include types NULL, logical, integer, double, complex, character, list, and raw.\n\n\ntypeof(NULL)\n\n\n[1] \"NULL\"\n\ntypeof(1L)\n\n\n[1] \"integer\"\n\ntypeof(1i)\n\n\n[1] \"complex\"\n\nFunctions include types closure (regular R functions), special (internal functions), and builtin (primitive functions).\n\n\ntypeof(mean)\n\n\n[1] \"closure\"\n\ntypeof(`[`)\n\n\n[1] \"special\"\n\ntypeof(sum)    \n\n\n[1] \"builtin\"\n\nEnvironments have type environment.\n\n\ntypeof(globalenv())\n\n\n[1] \"environment\"\n\nThe S4 type is used for S4 classes that don’t inherit from an existing base type.\n\n\nmle_obj <- stats4::mle(function(x = 1) (x - 2) ^ 2)\ntypeof(mle_obj)\n\n\n[1] \"S4\"\n\nLanguage components include symbol (aka name), language (usually called calls), and pairlist (used for function arguments) types.\n\n\ntypeof(quote(a))\n\n\n[1] \"symbol\"\n\ntypeof(quote(a + 1))\n\n\n[1] \"language\"\n\ntypeof(formals(mean))\n\n\n[1] \"pairlist\"\n\nexpression is a special purpose type that’s only returned by parse() and expression(). Expressions are generally not needed in user code.\nThe remaining types are esoteric and rarely seen in R. They are important primarily for connections to C code: externalptr, weakref, bytecode, promise, ..., and any.\nAll other attributes of an R object beyond its base type are a set of metadata associated with the object. This metadata is attached to the main object but subordinate in status. These attributes can be found en masse through a call to attributes()\n\n\nattributes(1:10)\n\n\nNULL\n\nIn this case the object has no additional attributes beyond its intrinsic attributes and hence the call returns a NULL value.\nMore generally, attributes are represented as a named list in R and can have value NULL\n\n\nx <- matrix(1:9, nrow = 3)\nattributes(x)\n\n\n$dim\n[1] 3 3\n\ntypeof(attributes(x))\n\n\n[1] \"list\"\n\nAn attribute that is often helpful for interpreting an object’s data is the object’s class. The class attribute is used by R’s native object oriented system - the S3 system. Not all objects have the class attribute, and those that do we can are designated “OO objects” (short for “object-oriented”). This can be confusing in lieu of the fact (and discussed above) that everything in R is an object!\nHowever as Wikham writes (Advanced R, page 291), “while everything is an object, not everything is object-oriented.” Hence the objects in R will come in two flavors that we can designate base objects and OO objects.\n\nThe type of an object we will reference as its base type - this is because irrespective of whether an object is a base object or an OO object, its underlying type belongs to a pre-defined set established by R-core that was described above.\nHence even OO objects have a base type. What distinguishes OO types is that they will have at least an additional “class” attribute. The class attribute can then be seen as an extension of the functionality of its underlying base type.\nAs an aside - the S language, which is the basis for the core R language - was developed before the design of an OOP (Object Oriented Programming) system that introduced formal OO capabilities to the language. The original system - the S3 system - remains the simplest, most flexible, and most popular system used for R programming and package development. We focus attention on it here. Hence the simplest OO objects are S3 objects - e.g., a base type object with at least a class attribute.\nTo appreciate the S3 system, it is useful to observe that R is at heart a functional programming language, e.g., functions are first-class functions. This means that objects in R are functions just like any other object, e.g., they are just another data structure. It is not surprising then that the S3 system brings OOP capabilities through functions the thus adopts the OOP through a paradigm of generic functions, where the different methods for manipulating different classes of objects that achieve a common functionality are associated with a generic function. For example the print() function behaves differently\n\n\nsome_data <- list(x = c(1,2), y = c(3,4))\nprint(some_data)\n\n\n$x\n[1] 1 2\n\n$y\n[1] 3 4\n\nattributes(some_data)\n\n\n$names\n[1] \"x\" \"y\"\n\nclass(some_data) <- c(\"data.frame\")\nattributes(some_data)$row.names = c(1L,2L)\nsome_data\n\n\n  x y\n1 1 3\n2 2 4\n\n## of course there are convenience functions for creating a data frame from a list that automate this process.\nas.data.frame(list(x = c(1,2), y = c(3,4)))\n\n\n  x y\n1 1 3\n2 2 4\n\nHow did this happen, e.g., the output of the list data structure change depending on the class attribute. The magic arises because the function print is actually a generic. As Hadley describes it (p. 300): \"The generic is a middleman: its job is to define the interface (i.e., the arguments) then find the right implementation for the job. The implementation for a specific class is called a method, and the generic finds that method by performing method dispatch.\nThe fact that print is a generic is revealed by its body, which is a single line that calls UseMethod.\n\n\nbody(print)\n\n\nUseMethod(\"print\")\n\nThe UseMethod function inspects the class attribute of the first argument and seeks the appropriate method (function). The methods are named according to the generic.class convention. Hence printing the data frame above should seek a method by the name of print.data.frame. To check this behavior, we can use the helper function sloop::s3_dispatch()\n\n\nsloop::s3_dispatch(print(some_data))\n\n\n=> print.data.frame\n * print.default\n\nThe “=>” in the output indicates the method that is called, confirming our characterization of the method dispatch process. A more thorough examination of method dispatch is given in Chapter 13 of Advanced R.\nAn object can have multiple classes, e.g., the class attribute takes the value of a character vector. For example, a tibble is an enhanced data frame, and has 3 classes. Lets convert our data into a tibble:\n\n\nclass(some_data) <- append(c(\"tbl_df\", \"tbl\"), class(some_data))\nsome_data\n\n\n# A tibble: 2 x 2\n      x     y\n* <dbl> <dbl>\n1     1     3\n2     2     4\n\nsloop::s3_dispatch(print(some_data))\n\n\n   print.tbl_df\n=> print.tbl\n * print.data.frame\n * print.default\n\nIn the case of objects with multiple classes, method dispatch first seeks a method for the first class, and then the second class, and so forth.\nOne useful feature of tibbles is that they readily support list columns. Data frames and tibbles are lists of equal length vectors.\n\n\n\nThe vectors contained inside of a data frame or tibble are typically atomic vectors.\n\n\n\nHowever recall lists are also vectors (so called recursive vectors as discussed above). Thus if instead of an atomic vector, a tibble held a list as a column, this would give rise to (an appropriately called) list column\n\n\n\nAnd because lists are recursive, the elements of a list column can be other lists, e.g, tibbles themselves!\n\n\n\nThis enables some very powerful workflows with data and empirical modeling. As an example, suppose we want to break a large data set into multiple sub-data sets by split according to the values of a group variable, and run a regression among the remaining variables for each group separately. How can we examine the pattern of values of the regression coefficient among the groups.\nThe key function to enable list columns that are populated with tibbles is nest(). In particular as Hadley explains, “Pass nest() the names of the columns to put into each individual tibble. nest() will create one row for each unique value of the remaining variables.” (determine citation)\nConsider the example from the tidymodels tutorials:\n\n\nlibrary(tidymodels)\n\ndata(Orange)\n\nOrange <- as_tibble(Orange)\nOrange\n\n\n# A tibble: 35 x 3\n   Tree    age circumference\n   <ord> <dbl>         <dbl>\n 1 1       118            30\n 2 1       484            58\n 3 1       664            87\n 4 1      1004           115\n 5 1      1231           120\n 6 1      1372           142\n 7 1      1582           145\n 8 2       118            33\n 9 2       484            69\n10 2       664           111\n# … with 25 more rows\n\nThere is clear correlation between age and circumference for each class of tree.\n\n\ncor(Orange$age, Orange$circumference)\n\n\n[1] 0.9135189\n\nggplot(Orange) + geom_line(aes(x = age, y = circumference, color = Tree))\n\n\n\n\n\n\nOrange %>% group_by(Tree) %>% summarize(correlation = cor(circumference,age)) %>% arrange(Tree)\n\n\n# A tibble: 5 x 2\n  Tree  correlation\n  <ord>       <dbl>\n1 3           0.988\n2 1           0.985\n3 5           0.988\n4 2           0.987\n5 4           0.984\n\nNow if we wish to examine the statistical properties of the bivariate correlation for each group, the task becomes more complicated. We can examine a proper correlation test at the aggregate level\n\n\ncor_agg <- cor.test(Orange$age,Orange$circumference)\ncor_agg\n\n\n\n    Pearson's product-moment correlation\n\ndata:  Orange$age and Orange$circumference\nt = 12.9, df = 33, p-value = 1.931e-14\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8342364 0.9557955\nsample estimates:\n      cor \n0.9135189 \n\ncor_agg %>% class()\n\n\n[1] \"htest\"\n\nThe output takes the form of a rich collection of information that is a data structure of class htest. To convert this information into consumable data for analyses, we will “tidy” it (a running themse in the “R for Data Science” book and a key principle that unifies the package in the tidyverse.)\nWe tidy the data with the tidy() function:\n\n\ntidy(cor_agg)\n\n\n# A tibble: 1 x 8\n  estimate statistic  p.value parameter conf.low conf.high method     \n     <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>      \n1    0.914      12.9 1.93e-14        33    0.834     0.956 Pearson's …\n# … with 1 more variable: alternative <chr>\n\nwhich produces a single row (one observation - in this case a single test) with each variable/dimension of the test being a column.\nWe can use this workflow to generate a tidy data set on the statistical properties of the correlation across the subgroups of our data. This is enabled via the nest-map-unnest pattern.\nFirst we nest the data to create a list column:\n\n\nOrange %>% nest(data = c(circumference, age))\n\n\n# A tibble: 5 x 2\n  Tree  data            \n  <ord> <list>          \n1 1     <tibble [7 × 2]>\n2 2     <tibble [7 × 2]>\n3 3     <tibble [7 × 2]>\n4 4     <tibble [7 × 2]>\n5 5     <tibble [7 × 2]>\n\nWe can add to the pipeline by mapping the correlation test across each tibble in the list column\n\n\nOrange %>% nest(data = c(circumference, age)) %>%\n  mutate(test = map(data, ~cor.test(.$age, .$circumference)))\n\n\n# A tibble: 5 x 3\n  Tree  data             test   \n  <ord> <list>           <list> \n1 1     <tibble [7 × 2]> <htest>\n2 2     <tibble [7 × 2]> <htest>\n3 3     <tibble [7 × 2]> <htest>\n4 4     <tibble [7 × 2]> <htest>\n5 5     <tibble [7 × 2]> <htest>\n\nNotice this produces another list column consisting of elements of the htest class. Now we need to tidy each one, which will give us a list column of tibbles:\n\n\nOrange %>% nest(data = c(circumference, age)) %>%\n  \n  mutate(test = \n           map(data, ~cor.test(.$age, .$circumference))) %>%\n  \n  mutate(testdat = map(test,tidy))\n\n\n# A tibble: 5 x 4\n  Tree  data             test    testdat         \n  <ord> <list>           <list>  <list>          \n1 1     <tibble [7 × 2]> <htest> <tibble [1 × 8]>\n2 2     <tibble [7 × 2]> <htest> <tibble [1 × 8]>\n3 3     <tibble [7 × 2]> <htest> <tibble [1 × 8]>\n4 4     <tibble [7 × 2]> <htest> <tibble [1 × 8]>\n5 5     <tibble [7 × 2]> <htest> <tibble [1 × 8]>\n\nIf we inspect an element of the testdat variable, we will see a tidy data frame associated to the correlation test applied to a group of the data:\n\n\n(Orange %>% nest(data = c(circumference, age)) %>%\n  \n  mutate(test = \n           map(data, ~cor.test(.$age, .$circumference))) %>%\n  \n  mutate(testdat = map(test,tidy)))$testdat[[1]]\n\n\n# A tibble: 1 x 8\n  estimate statistic  p.value parameter conf.low conf.high method     \n     <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>      \n1    0.985      13.0  4.85e-5         5    0.901     0.998 Pearson's …\n# … with 1 more variable: alternative <chr>\n\n\n\ncortestDat <-\nOrange %>% nest(data = c(circumference, age)) %>%\n  \n  mutate(test = \n           map(data, ~cor.test(.$age, .$circumference))) %>%\n  \n  mutate(testdat = map(test,tidy)) %>%\n  unnest(testdat) %>%\n  select(-data, -test)\n\n\n\n\n\nggplot(cortestDat) + geom_point(aes(x = p.value, y = estimate))\n\n\n\n\nS3 Atomic Vectors\nAtomic vectors also have S3 variants. Base R includes definitions for several important S3 atomic vectors to represent:\nCategorical data using factor vectors\nDates using Date vectors\nDate_times using POSIXct vectors\nDurations using difftime vectors\nThese S3 vectors (also called augmented vectors to signal their augmented attributes relative to their base vector type) and their connections to base type vectors are pictured below:\n\n\n\nHere we discuss factor vectors, which are built on top of integer vectors that can take one of a pre-defined set of values. A factor vector is defined on top of an integer vector through two additional attributes: (1): a class of “factor” which distinguishes factors from standard integer vectors, and (2): levels which are a set of allowed values.\n\n\nx <- factor(c(\"a\", \"b,\", \"c\", \"d\"))\nx\n\n\n[1] a  b, c  d \nLevels: a b, c d\n\ntypeof(x)\n\n\n[1] \"integer\"\n\nunclass(x)\n\n\n[1] 1 2 3 4\nattr(,\"levels\")\n[1] \"a\"  \"b,\" \"c\"  \"d\" \n\nR has functionality that allows you to immediately tabulate a factor vector based on the set of potential levels (as opposed to the observed levels)\n\n\nsex_char <- c(\"m\", \"m\")\nsex_factor <- factor(sex_char, levels = c(\"m\", \"f\"))\ntable(sex_char)\n\n\nsex_char\nm \n2 \n\ntable(sex_factor)\n\n\nsex_factor\nm f \n2 0 \n\nOrdered factors are a slightly different stripe of factors (an added class ordered) that orders the factor levels in a meaningful way that can be helpful for visualizations or modeling. We have already seen an example above in the case of the Orange data set:\n\n\nOrange$Tree\n\n\n [1] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4 5 5 5 5 5\n[34] 5 5\nLevels: 3 < 1 < 5 < 2 < 4\n\nclass(Orange$Tree)\n\n\n[1] \"ordered\" \"factor\" \n\nwhich explains how Tree was arranged in the summary tables (based on this order).\nWhen we import data we will generally want to convert character vectors in the data set into factors. The following workflow that we illustrate with a data set on European automobile sales and product characteristics leverages the across() functionality from dplyr 1.0.0 to achieve these purposes and provides useful summaries.\n\n\ncarData <- read_csv(\"../../data/total.csv\")\nglimpse(carData)\n\n\nRows: 139,307\nColumns: 90\n$ brand               <chr> \"alfa_romeo\", \"alfa_romeo\", \"alfa_romeo\"…\n$ continent           <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ bodystyle           <chr> \"com\", \"com\", \"com\", \"com\", \"com\", \"com\"…\n$ dup                 <dbl> 7834, 10302, 12393, 29626, 12797, 1868, …\n$ year                <dbl> 2011, 2010, 2013, 2014, 2012, 2016, 2012…\n$ month               <dbl> 8, 9, 3, 10, 6, 7, 2, 5, 10, 11, 3, 6, 6…\n$ time                <dbl> 20, 9, 39, 58, 30, 79, 26, 41, 34, 23, 8…\n$ muninumber          <dbl> 1657, 1102, 239, 1201, 213, 1422, 220, 1…\n$ market_ids          <dbl> 708, 168, 1263, 1823, 834, 2682, 840, 14…\n$ sales               <dbl> 1, 3, 1, 2, 4, 1, 3, 1, 1, 1, 1, 1, 1, 1…\n$ shares              <dbl> 1.467567e-04, 4.549936e-05, 3.746721e-04…\n$ product_ids         <dbl> 4, 5, 4, 5, 4, 4, 4, 4, 4, 5, 3, 3, 4, 3…\n$ car_ids             <dbl> 20, 28, 20, 26, 24, 19, 17, 20, 17, 28, …\n$ firm_ids            <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ nvals               <dbl> 6, 57, 11, 50, 81, 16, 73, 46, 3, 73, 7,…\n$ numbersold          <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ station_network     <dbl> 0, 6, 1, 118, 3, 1, 10, 1, 1, 1, 1, 2, 1…\n$ muni                <chr> \"skaun\", \"sandnes\", \"hurdal\", \"bergen\", …\n$ transmission        <chr> \"man\", \"man\", \"man\", \"man\", \"aut\", \"man\"…\n$ prices              <dbl> 3.499, 2.499, 3.399, 1.899, 3.549, 3.199…\n$ trans               <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1…\n$ ev                  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ length              <dbl> 0.435, 0.406, 0.435, 0.406, 0.435, 0.435…\n$ power_over_weight   <dbl> 0.13178295, 0.09633028, 0.13178295, 0.07…\n$ inversefuelecon     <dbl> 0.5447272, 0.5621190, 0.5447272, 0.86750…\n$ county              <chr> \"trÃ\\u0083Â\\u0083Ã\\u0082Â¸ndelag\", \"roga…\n$ model               <chr> \"giulietta\", \"mito\", \"giulietta\", \"mito\"…\n$ drivetrain          <chr> \"2wd\", \"2wd\", \"2wd\", \"2wd\", \"2wd\", \"2wd\"…\n$ fueltype            <chr> \"gasoline\", \"gasoline\", \"gasoline\", \"gas…\n$ displacement        <dbl> 1368, 1368, 1368, 875, 1368, 1368, 1368,…\n$ effect_kw           <dbl> 125, 77, 125, 62, 125, 110, 88, 125, 88,…\n$ emissions           <dbl> 0, 0, 134, 98, 121, 127, 149, 134, 149, …\n$ latitude            <dbl> 63.30867, 58.85233, 60.43157, 60.37877, …\n$ longitude           <dbl> 10.083460, 5.750746, 11.065035, 5.321423…\n$ land                <dbl> 213.05, 285.55, 260.98, 445.00, 161.72, …\n$ freshwater          <dbl> 11.12, 19.06, 23.98, 19.70, 3.81, 66.66,…\n$ totalarea           <dbl> 224.17, 304.61, 284.96, 464.70, 165.53, …\n$ hh                  <dbl> 2653, 27025, 1201, 125929, 11846, 931, 2…\n$ medianincome        <dbl> 585497.8, 561638.1, 498247.4, 507902.6, …\n$ population          <dbl> 6814.0, 65935.0, 2669.0, 274379.0, 29191…\n$ diesel              <dbl> 16.10978, 14.35810, 16.29313, 15.71055, …\n$ gasoline            <dbl> 14.06, 12.45, 14.65, 14.60, 14.56, 13.88…\n$ cpi                 <dbl> 0.8727615, 0.8671065, 0.8991517, 0.92931…\n$ mintemp             <dbl> 5.6, 2.1, -23.3, 1.4, 2.1, 8.2, -18.5, -…\n$ maxtemp             <dbl> 24.0, 20.1, 7.5, 19.5, 22.5, 29.9, 12.0,…\n$ electricity         <dbl> 364.0284, 443.5326, 376.7662, 245.6011, …\n$ parkingfee          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ numberofdoors       <dbl> 5, 3, 5, 3, 5, 5, 5, 5, 5, 3, 4, 4, 5, 4…\n$ numberofseats       <dbl> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5…\n$ weight              <dbl> 1290, 1090, 1290, 1130, 1290, 1280, 1280…\n$ fueleconomy         <dbl> 0.58, 0.57, 0.58, 0.42, 0.52, 0.56, 0.64…\n$ numberofcylinders   <dbl> 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4…\n$ effect_hp           <dbl> 170, 105, 170, 85, 170, 150, 120, 170, 1…\n$ range               <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ popdensity          <dbl> 31.983103, 230.905270, 10.226837, 616.58…\n$ price_over_income   <dbl> 0.5976111, 0.4449485, 0.6821913, 0.37389…\n$ n_fuel              <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2…\n$ n_bodystyle         <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 7…\n$ n_drivetrain        <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1…\n$ n_transmission      <dbl> 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2…\n$ n_brand             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ n_model             <dbl> 175, 267, 175, 267, 175, 175, 175, 175, …\n$ n_county            <dbl> 15, 11, 1, 6, 1, 12, 1, 11, 17, 3, 3, 7,…\n$ n_numberofdoors     <dbl> 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 3, 3, 4, 3…\n$ n_numberofseats     <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ mintemp_dbev        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ maxtemp_dbev        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ electricity_dbev    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ parkingfee_dbev     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ range_dbev          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ msize               <dbl> 44.21667, 450.41666, 20.01667, 2098.8167…\n$ delta               <dbl> -8.826588, -9.995170, -7.888710, -11.828…\n$ evsn                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ lnlength            <dbl> -0.8324093, -0.9014022, -0.8324093, -0.9…\n$ lndisplacement      <dbl> 7.221105, 7.221105, 7.221105, 6.774224, …\n$ lnpow               <dbl> -2.026599, -2.339973, -2.026599, -2.5873…\n$ lninv               <dbl> -0.6074703, -0.5760418, -0.6074703, -0.1…\n$ lnstation           <dbl> 0.0000000, 1.7917595, 0.0000000, 4.77068…\n$ lnevsn              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ trend               <dbl> 2, 1, 4, 5, 3, 7, 3, 4, 3, 2, 8, 8, 3, 8…\n$ dummy               <dbl> 0.4081760, 0.3011693, 0.3698604, 0.43076…\n$ dummy2              <dbl> 526.5470, 328.2745, 477.1200, 486.7686, …\n$ demand_instruments0 <dbl> 1, 0, 1, 0, 4, 3, 5, 4, 5, 5, 2, 2, 3, 1…\n$ demand_instruments1 <dbl> 2, 2, 2, 0, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3…\n$ demand_instruments2 <dbl> 0, 1, 1, 0, 3, 3, 1, 3, 3, 1, 2, 2, 0, 2…\n$ demand_instruments3 <dbl> 2, 2, 2, 0, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3…\n$ demand_instruments4 <dbl> 61, 12, 55, 17, 53, 42, 65, 52, 66, 64, …\n$ demand_instruments5 <dbl> 75, 76, 77, 78, 71, 71, 73, 75, 70, 74, …\n$ demand_instruments6 <dbl> 26, 53, 53, 54, 51, 51, 25, 51, 51, 25, …\n$ demand_instruments7 <dbl> 79, 78, 79, 81, 76, 75, 75, 76, 75, 76, …\n\nLets select which of the 90 variables are character columns:\n\n\ncarData %>% select(where(is.character)) %>%\n  glimpse()\n\n\nRows: 139,307\nColumns: 8\n$ brand        <chr> \"alfa_romeo\", \"alfa_romeo\", \"alfa_romeo\", \"alfa…\n$ bodystyle    <chr> \"com\", \"com\", \"com\", \"com\", \"com\", \"com\", \"com\"…\n$ muni         <chr> \"skaun\", \"sandnes\", \"hurdal\", \"bergen\", \"ski\", …\n$ transmission <chr> \"man\", \"man\", \"man\", \"man\", \"aut\", \"man\", \"man\"…\n$ county       <chr> \"trÃ\\u0083Â\\u0083Ã\\u0082Â¸ndelag\", \"rogaland\", …\n$ model        <chr> \"giulietta\", \"mito\", \"giulietta\", \"mito\", \"giul…\n$ drivetrain   <chr> \"2wd\", \"2wd\", \"2wd\", \"2wd\", \"2wd\", \"2wd\", \"2wd\"…\n$ fueltype     <chr> \"gasoline\", \"gasoline\", \"gasoline\", \"gasoline\",…\n\n\n\ncarData <- carData %>% mutate(across(c(year,month,time,muninumber,market_ids), as.factor)) %>% \n  mutate(across(where(is.character), as.factor))\n\ncarData %>% glimpse()\n\n\nRows: 139,307\nColumns: 90\n$ brand               <fct> alfa_romeo, alfa_romeo, alfa_romeo, alfa…\n$ continent           <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ bodystyle           <fct> com, com, com, com, com, com, com, com, …\n$ dup                 <dbl> 7834, 10302, 12393, 29626, 12797, 1868, …\n$ year                <fct> 2011, 2010, 2013, 2014, 2012, 2016, 2012…\n$ month               <fct> 8, 9, 3, 10, 6, 7, 2, 5, 10, 11, 3, 6, 6…\n$ time                <fct> 20, 9, 39, 58, 30, 79, 26, 41, 34, 23, 8…\n$ muninumber          <fct> 1657, 1102, 239, 1201, 213, 1422, 220, 1…\n$ market_ids          <fct> 708, 168, 1263, 1823, 834, 2682, 840, 14…\n$ sales               <dbl> 1, 3, 1, 2, 4, 1, 3, 1, 1, 1, 1, 1, 1, 1…\n$ shares              <dbl> 1.467567e-04, 4.549936e-05, 3.746721e-04…\n$ product_ids         <dbl> 4, 5, 4, 5, 4, 4, 4, 4, 4, 5, 3, 3, 4, 3…\n$ car_ids             <dbl> 20, 28, 20, 26, 24, 19, 17, 20, 17, 28, …\n$ firm_ids            <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ nvals               <dbl> 6, 57, 11, 50, 81, 16, 73, 46, 3, 73, 7,…\n$ numbersold          <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ station_network     <dbl> 0, 6, 1, 118, 3, 1, 10, 1, 1, 1, 1, 2, 1…\n$ muni                <fct> skaun, sandnes, hurdal, bergen, ski, lÃÂÃÂ¦rdal, asker, vindafjord, re, lier, hol, volda, grimstad, horten, kristiansand, ballangen, sandnes, bergen, oslo, sarpsborg, bÃÂÃÂ¦rum, bÃÂÃÂ¸mlo, porsgrunn\n$ transmission        <fct> man, man, man, man, aut, man, man, man, …\n$ prices              <dbl> 3.499, 2.499, 3.399, 1.899, 3.549, 3.199…\n$ trans               <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1…\n$ ev                  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ length              <dbl> 0.435, 0.406, 0.435, 0.406, 0.435, 0.435…\n$ power_over_weight   <dbl> 0.13178295, 0.09633028, 0.13178295, 0.07…\n$ inversefuelecon     <dbl> 0.5447272, 0.5621190, 0.5447272, 0.86750…\n$ county              <fct> trÃÂÃÂ¸ndelag, rogaland, akershus, hordaland, akershus, sogn og fjordane, akershus, rogaland, vestfold, buskerud, buskerud, mÃÂÃÂ¸re og romsdal, aust-agder, vestfold, vest-agder, nordland, rogaland, hordaland, oslo, ÃÂÃÂ¸stfold, akershus, hordaland, telemark\n$ model               <fct> giulietta, mito, giulietta, mito, giulie…\n$ drivetrain          <fct> 2wd, 2wd, 2wd, 2wd, 2wd, 2wd, 2wd, 2wd, …\n$ fueltype            <fct> gasoline, gasoline, gasoline, gasoline, …\n$ displacement        <dbl> 1368, 1368, 1368, 875, 1368, 1368, 1368,…\n$ effect_kw           <dbl> 125, 77, 125, 62, 125, 110, 88, 125, 88,…\n$ emissions           <dbl> 0, 0, 134, 98, 121, 127, 149, 134, 149, …\n$ latitude            <dbl> 63.30867, 58.85233, 60.43157, 60.37877, …\n$ longitude           <dbl> 10.083460, 5.750746, 11.065035, 5.321423…\n$ land                <dbl> 213.05, 285.55, 260.98, 445.00, 161.72, …\n$ freshwater          <dbl> 11.12, 19.06, 23.98, 19.70, 3.81, 66.66,…\n$ totalarea           <dbl> 224.17, 304.61, 284.96, 464.70, 165.53, …\n$ hh                  <dbl> 2653, 27025, 1201, 125929, 11846, 931, 2…\n$ medianincome        <dbl> 585497.8, 561638.1, 498247.4, 507902.6, …\n$ population          <dbl> 6814.0, 65935.0, 2669.0, 274379.0, 29191…\n$ diesel              <dbl> 16.10978, 14.35810, 16.29313, 15.71055, …\n$ gasoline            <dbl> 14.06, 12.45, 14.65, 14.60, 14.56, 13.88…\n$ cpi                 <dbl> 0.8727615, 0.8671065, 0.8991517, 0.92931…\n$ mintemp             <dbl> 5.6, 2.1, -23.3, 1.4, 2.1, 8.2, -18.5, -…\n$ maxtemp             <dbl> 24.0, 20.1, 7.5, 19.5, 22.5, 29.9, 12.0,…\n$ electricity         <dbl> 364.0284, 443.5326, 376.7662, 245.6011, …\n$ parkingfee          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ numberofdoors       <dbl> 5, 3, 5, 3, 5, 5, 5, 5, 5, 3, 4, 4, 5, 4…\n$ numberofseats       <dbl> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5…\n$ weight              <dbl> 1290, 1090, 1290, 1130, 1290, 1280, 1280…\n$ fueleconomy         <dbl> 0.58, 0.57, 0.58, 0.42, 0.52, 0.56, 0.64…\n$ numberofcylinders   <dbl> 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4…\n$ effect_hp           <dbl> 170, 105, 170, 85, 170, 150, 120, 170, 1…\n$ range               <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ popdensity          <dbl> 31.983103, 230.905270, 10.226837, 616.58…\n$ price_over_income   <dbl> 0.5976111, 0.4449485, 0.6821913, 0.37389…\n$ n_fuel              <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2…\n$ n_bodystyle         <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 7…\n$ n_drivetrain        <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1…\n$ n_transmission      <dbl> 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2…\n$ n_brand             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ n_model             <dbl> 175, 267, 175, 267, 175, 175, 175, 175, …\n$ n_county            <dbl> 15, 11, 1, 6, 1, 12, 1, 11, 17, 3, 3, 7,…\n$ n_numberofdoors     <dbl> 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 3, 3, 4, 3…\n$ n_numberofseats     <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ mintemp_dbev        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ maxtemp_dbev        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ electricity_dbev    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ parkingfee_dbev     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ range_dbev          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ msize               <dbl> 44.21667, 450.41666, 20.01667, 2098.8167…\n$ delta               <dbl> -8.826588, -9.995170, -7.888710, -11.828…\n$ evsn                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ lnlength            <dbl> -0.8324093, -0.9014022, -0.8324093, -0.9…\n$ lndisplacement      <dbl> 7.221105, 7.221105, 7.221105, 6.774224, …\n$ lnpow               <dbl> -2.026599, -2.339973, -2.026599, -2.5873…\n$ lninv               <dbl> -0.6074703, -0.5760418, -0.6074703, -0.1…\n$ lnstation           <dbl> 0.0000000, 1.7917595, 0.0000000, 4.77068…\n$ lnevsn              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ trend               <dbl> 2, 1, 4, 5, 3, 7, 3, 4, 3, 2, 8, 8, 3, 8…\n$ dummy               <dbl> 0.4081760, 0.3011693, 0.3698604, 0.43076…\n$ dummy2              <dbl> 526.5470, 328.2745, 477.1200, 486.7686, …\n$ demand_instruments0 <dbl> 1, 0, 1, 0, 4, 3, 5, 4, 5, 5, 2, 2, 3, 1…\n$ demand_instruments1 <dbl> 2, 2, 2, 0, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3…\n$ demand_instruments2 <dbl> 0, 1, 1, 0, 3, 3, 1, 3, 3, 1, 2, 2, 0, 2…\n$ demand_instruments3 <dbl> 2, 2, 2, 0, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3…\n$ demand_instruments4 <dbl> 61, 12, 55, 17, 53, 42, 65, 52, 66, 64, …\n$ demand_instruments5 <dbl> 75, 76, 77, 78, 71, 71, 73, 75, 70, 74, …\n$ demand_instruments6 <dbl> 26, 53, 53, 54, 51, 51, 25, 51, 51, 25, …\n$ demand_instruments7 <dbl> 79, 78, 79, 81, 76, 75, 75, 76, 75, 76, …\n\n\n\ncarData %>%\n  summarize(across(where(is.factor), nlevels))\n\n\n# A tibble: 1 x 13\n  brand bodystyle  year month  time muninumber market_ids  muni\n  <int>     <int> <int> <int> <int>      <int>      <int> <int>\n1    44         9     8    12    96        416       3251   416\n# … with 5 more variables: transmission <int>, county <int>,\n#   model <int>, drivetrain <int>, fueltype <int>\n\nHow many years of data for each municpality\n\n\ncarData %>%\ngroup_by(muninumber, year) %>% count()\n\n\n# A tibble: 3,251 x 3\n# Groups:   muninumber, year [3,251]\n   muninumber year      n\n   <fct>      <fct> <int>\n 1 101        2010     82\n 2 101        2011     85\n 3 101        2012     96\n 4 101        2013     94\n 5 101        2014     77\n 6 101        2015     81\n 7 101        2016     87\n 8 101        2017     81\n 9 104        2010    111\n10 104        2011    111\n# … with 3,241 more rows\n\n  #summarize(across(where(is.factor), nlevels))\n\n\n\nBase R will tend to create factor vectors often because when data is read using read.csv(), character vectors are automatically coerced into factors.\n\n\ncarData <- read.csv(\"../../data/total.csv\")\n\n\n\n\n\nlibrary(readr)\ncarData2 <- read_csv(\"../../data/total.csv\")\nglimpse(carData)\n\n\nRows: 139,307\nColumns: 90\n$ brand               <chr> \"alfa_romeo\", \"alfa_romeo\", \"alfa_romeo\"…\n$ continent           <int> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ bodystyle           <chr> \"com\", \"com\", \"com\", \"com\", \"com\", \"com\"…\n$ dup                 <int> 7834, 10302, 12393, 29626, 12797, 1868, …\n$ year                <int> 2011, 2010, 2013, 2014, 2012, 2016, 2012…\n$ month               <int> 8, 9, 3, 10, 6, 7, 2, 5, 10, 11, 3, 6, 6…\n$ time                <int> 20, 9, 39, 58, 30, 79, 26, 41, 34, 23, 8…\n$ muninumber          <int> 1657, 1102, 239, 1201, 213, 1422, 220, 1…\n$ market_ids          <int> 708, 168, 1263, 1823, 834, 2682, 840, 14…\n$ sales               <int> 1, 3, 1, 2, 4, 1, 3, 1, 1, 1, 1, 1, 1, 1…\n$ shares              <dbl> 1.467567e-04, 4.549936e-05, 3.746721e-04…\n$ product_ids         <int> 4, 5, 4, 5, 4, 4, 4, 4, 4, 5, 3, 3, 4, 3…\n$ car_ids             <int> 20, 28, 20, 26, 24, 19, 17, 20, 17, 28, …\n$ firm_ids            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ nvals               <int> 6, 57, 11, 50, 81, 16, 73, 46, 3, 73, 7,…\n$ numbersold          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ station_network     <int> 0, 6, 1, 118, 3, 1, 10, 1, 1, 1, 1, 2, 1…\n$ muni                <chr> \"skaun\", \"sandnes\", \"hurdal\", \"bergen\", …\n$ transmission        <chr> \"man\", \"man\", \"man\", \"man\", \"aut\", \"man\"…\n$ prices              <dbl> 3.499, 2.499, 3.399, 1.899, 3.549, 3.199…\n$ trans               <int> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1…\n$ ev                  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ length              <dbl> 0.435, 0.406, 0.435, 0.406, 0.435, 0.435…\n$ power_over_weight   <dbl> 0.13178295, 0.09633028, 0.13178295, 0.07…\n$ inversefuelecon     <dbl> 0.5447272, 0.5621190, 0.5447272, 0.86750…\n$ county              <chr> \"trÃ\\u0083Â\\u0083Ã\\u0082Â¸ndelag\", \"roga…\n$ model               <chr> \"giulietta\", \"mito\", \"giulietta\", \"mito\"…\n$ drivetrain          <chr> \"2wd\", \"2wd\", \"2wd\", \"2wd\", \"2wd\", \"2wd\"…\n$ fueltype            <chr> \"gasoline\", \"gasoline\", \"gasoline\", \"gas…\n$ displacement        <int> 1368, 1368, 1368, 875, 1368, 1368, 1368,…\n$ effect_kw           <int> 125, 77, 125, 62, 125, 110, 88, 125, 88,…\n$ emissions           <int> 0, 0, 134, 98, 121, 127, 149, 134, 149, …\n$ latitude            <dbl> 63.30867, 58.85233, 60.43157, 60.37877, …\n$ longitude           <dbl> 10.083460, 5.750746, 11.065035, 5.321423…\n$ land                <dbl> 213.05, 285.55, 260.98, 445.00, 161.72, …\n$ freshwater          <dbl> 11.12, 19.06, 23.98, 19.70, 3.81, 66.66,…\n$ totalarea           <dbl> 224.17, 304.61, 284.96, 464.70, 165.53, …\n$ hh                  <int> 2653, 27025, 1201, 125929, 11846, 931, 2…\n$ medianincome        <dbl> 585497.8, 561638.1, 498247.4, 507902.6, …\n$ population          <dbl> 6814.0, 65935.0, 2669.0, 274379.0, 29191…\n$ diesel              <dbl> 16.10978, 14.35810, 16.29313, 15.71055, …\n$ gasoline            <dbl> 14.06, 12.45, 14.65, 14.60, 14.56, 13.88…\n$ cpi                 <dbl> 0.8727615, 0.8671065, 0.8991517, 0.92931…\n$ mintemp             <dbl> 5.6, 2.1, -23.3, 1.4, 2.1, 8.2, -18.5, -…\n$ maxtemp             <dbl> 24.0, 20.1, 7.5, 19.5, 22.5, 29.9, 12.0,…\n$ electricity         <dbl> 364.0284, 443.5326, 376.7662, 245.6011, …\n$ parkingfee          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ numberofdoors       <int> 5, 3, 5, 3, 5, 5, 5, 5, 5, 3, 4, 4, 5, 4…\n$ numberofseats       <int> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5…\n$ weight              <int> 1290, 1090, 1290, 1130, 1290, 1280, 1280…\n$ fueleconomy         <dbl> 0.58, 0.57, 0.58, 0.42, 0.52, 0.56, 0.64…\n$ numberofcylinders   <int> 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4…\n$ effect_hp           <int> 170, 105, 170, 85, 170, 150, 120, 170, 1…\n$ range               <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ popdensity          <dbl> 31.983103, 230.905270, 10.226837, 616.58…\n$ price_over_income   <dbl> 0.5976111, 0.4449485, 0.6821913, 0.37389…\n$ n_fuel              <int> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2…\n$ n_bodystyle         <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 7…\n$ n_drivetrain        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1…\n$ n_transmission      <int> 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2…\n$ n_brand             <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ n_model             <int> 175, 267, 175, 267, 175, 175, 175, 175, …\n$ n_county            <int> 15, 11, 1, 6, 1, 12, 1, 11, 17, 3, 3, 7,…\n$ n_numberofdoors     <int> 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 3, 3, 4, 3…\n$ n_numberofseats     <int> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ mintemp_dbev        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ maxtemp_dbev        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ electricity_dbev    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ parkingfee_dbev     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ range_dbev          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ msize               <dbl> 44.21667, 450.41666, 20.01667, 2098.8167…\n$ delta               <dbl> -8.826588, -9.995170, -7.888710, -11.828…\n$ evsn                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ lnlength            <dbl> -0.8324093, -0.9014022, -0.8324093, -0.9…\n$ lndisplacement      <dbl> 7.221105, 7.221105, 7.221105, 6.774224, …\n$ lnpow               <dbl> -2.026599, -2.339973, -2.026599, -2.5873…\n$ lninv               <dbl> -0.6074703, -0.5760418, -0.6074703, -0.1…\n$ lnstation           <dbl> 0.0000000, 1.7917595, 0.0000000, 4.77068…\n$ lnevsn              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ trend               <int> 2, 1, 4, 5, 3, 7, 3, 4, 3, 2, 8, 8, 3, 8…\n$ dummy               <dbl> 0.4081760, 0.3011693, 0.3698604, 0.43076…\n$ dummy2              <dbl> 526.5470, 328.2745, 477.1200, 486.7686, …\n$ demand_instruments0 <dbl> 1, 0, 1, 0, 4, 3, 5, 4, 5, 5, 2, 2, 3, 1…\n$ demand_instruments1 <dbl> 2, 2, 2, 0, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3…\n$ demand_instruments2 <dbl> 0, 1, 1, 0, 3, 3, 1, 3, 3, 1, 2, 2, 0, 2…\n$ demand_instruments3 <dbl> 2, 2, 2, 0, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3…\n$ demand_instruments4 <dbl> 61, 12, 55, 17, 53, 42, 65, 52, 66, 64, …\n$ demand_instruments5 <dbl> 75, 76, 77, 78, 71, 71, 73, 75, 70, 74, …\n$ demand_instruments6 <dbl> 26, 53, 53, 54, 51, 51, 25, 51, 51, 25, …\n$ demand_instruments7 <dbl> 79, 78, 79, 81, 76, 75, 75, 76, 75, 76, …\n\n\n\n\nChambers, John M. 1998. Programming with Data: A Guide to the s Language. Springer Science & Business Media.\n\n\nThe tidyverse is a standardization and formalization of functional and meta-programming capabilities of R. The popularization and resurgence of R through the tidyverse owes an unusual amount to the influential packages and writings of Hadley Wickham - the author of Advanced R and co-author of R for Data Science.↩︎\n",
    "preview": "https://genialebooks.com/wp-content/uploads/2019/05/fd985c69272ef1d23a9ab3f19c918252-210x315.jpg",
    "last_modified": "2021-03-09T03:32:39+00:00",
>>>>>>> 90861b92ad3cad3aafc2ce29a84ea7e697965064
    "input_file": {}
  },
  {
    "path": "posts/2021-02-27-kristenjordanproject/",
    "title": "Predicting Post-High School Outcomes",
    "description": "Revised project introduction.",
    "author": [
      {
        "name": "Kristen Beamer",
        "url": {}
      },
      {
        "name": "Jordan Peeples",
        "url": {}
      }
    ],
    "date": "2021-03-03",
    "categories": [
      "Jordan and Kristen's project"
    ],
    "contents": "\nQuestion of Interest\nWe are interested in studying the determinants of students’ post high school outcomes. We will begin by asking questions about which factors lead a student to pursue post-secondary education. Subsequently, we would like to better understand determinants that influence a student to attend a 2-year or technical college versus a traditional 4-year school. Are these decisions more related to individual characteristics or school fixed effects, or is there another underlying factor? How do student expectations compare to their actual outcomes?\nConditional on attending a traditional 4-year school, we want to determine the factors that may prompt a student to pursue a STEM major.\nData\nIn order to analyze these questions, we utilize public-use data from the United States High School Longitudinal Study from 2009-2013 (HSLS:09). This is a rich data set comprised of parent, teacher, school counselor, and student surveys. HSLS:09 also holds information on schools included in the sample.\nHSLS:09 provides important variables that influence students post-high school trajectories. Some information contained include courses taken by the student and the frequency and subject matter of meetings with school counselors. In addition, the restricted-use version of HSLS:09 contains standardized testing scores by student, such as scores on the PSAT, SAT, or AP exams (if the student took the test). Even without testing, the rich nature of the public-use HSLS:09 should provide ample information to unpack determinants of educational attainment.\nAnother interesting lens of the HSLS:09 survey is that it tracks students’ educational goals over their high school career. Starting in 9th grade, the students are asked about their plans after high school, and this can be directly compared to their true post-high school outcomes. Since there is an abundance of information within HSLS:09, the work so far has been wrangling the 6,000+ different variables that exist within the data.\nThe first step is to load the data. We rename it for easier code interpretability.\n\n\n#import\nurlSchool <- url(\"https://www.dropbox.com/s/bzoyhrtj3gi4t1t/36423-0001-Data.rda?raw=1\")\nurlStudent <- url(\"https://www.dropbox.com/s/x26tsp84rcn48gj/36423-0002-Data.rda?raw=1\")\nload(urlSchool)\nload(urlStudent)\n# rename\nschoolData <- da36423.0001\nstudentData <- da36423.0002\n\n\n\nGiven that HSLS:09 holds over 6,000 variables, we will start our examination of the data by selecting just student interview questions. In later iterations of this project we will select other surveys, such as the survey for parents, teachers, or counselors. In this chunk of code we drop variables that have been suppressed for public use, and rename some complicated categorical variables.\n\n\nstudentDataStudents <- studentData %>%\n  select(X3TCREDENG:S1TALKFUTURE, S3FOCUS) %>%\n  mutate_all(na_if, -5) %>%\n  mutate_all(na_if, -4) %>%\n  mutate_all(na_if, -7) %>%\n  mutate_all(na_if, -8) %>%\n  mutate_all(na_if, -9) %>%\n  mutate(S1EDUEXPECT = recode(S1EDUEXPECT, \"(01) Less than high school\" = \"Less than HS\",\n                              \"(02) High school diploma or GED\" = \"HS Diploma/GED\",\n                              \"(03) Start an Associate's degree\" = \"Start Assoc.\",\n                              \"(04) Complete an Associate's degree\" = \"Complete Assoc.\",\n                              \"(05) Start a Bachelor's degree\" = \"Start Bachelor's\",\n                              \"(06) Complete a Bachelor's degree\" = \"Complete Bachelor's\",\n                              \"(07) Start a Master's degree\" = \"Start Master's\",\n                              \"(08) Complete a Master's degree\" = \"Complete Master's\",\n                              \"(09) Start Ph.D/M.D/Law/other prof degree\" = \"Start PhD\",\n                              \"(10) Complete Ph.D/M.D/Law/other prof degree\" = \"Complete PhD\",\n                              \"(11) Don't know\" = \"Don't know\")) %>%\n  mutate(S3FOCUS = recode(S3FOCUS, \"(1) Taking classes from postsecondary institution\" = \"Postsecondary\",\n                          \"(2) Participating in an apprenticeship program\" = \"Apprenticeship\",\n                          \"(3) Working for pay\" = \"Work\",\n                          \"(4) Serving in the military\" = \"Military\",\n                          \"(5) Starting family or taking care of your/his/her children\" = \"Childcare\",\n                          \"(6) Attending high school or homeschool\" = \"Continued school\",\n                          \"(7) Taking course to prepare for the GED/other high school equivalency exam\" = \"GED Prep\",\n                          \"(8) Equally focused on more than one of these\" = \"Multiple\"))\nstudentDataStudents <- studentDataStudents[ , colSums(is.na(studentDataStudents)) < 12000]\n\n\n\nThese steps drop the student data from 6,608 to 365 variables over 23,503 observations. This will be a much easier place to begin unpacking the wealth of information within the data.\nSummary Statistics\nNow, with our cleaned subset of the HSLS:09 data, we can examine preliminary summary statistics on our main dependent variable of interest.\n\n\n  ggplot(data=studentDataStudents, aes(x=S3FOCUS)) +geom_bar(color=\"darkblue\", fill=\"lightblue\") +\n    labs(title=\"Question: What is your main focus as of Nov. 1, 2013?\",\n         x=\"Student Responses\",\n         y=\"Frequency\")\n\n\n\n\nModels\nIn order to approach these questions, we will begin by growing trees for each of our questions as stated above. It will be important to utilize appropriate cross-validation and tuning in order to properly characterize the underlying mechanisms at play. We are currently determining which chunk of variables to focus on, as a classification tree is computationally heavier than a regression tree. We have already estimated an initial tree as practice on the student interview only. We want to clean the data in a way that avoids repetitive variables and includes possible important ones.\nReferences\nUnited States Department of Education. Institute of Education Sciences. National Center for Education Statistics. High School Longitudinal Study, 2009-2013 [United States]. Inter-university Consortium for Political and Social Research [distributor], 2016-05-12. https://doi.org/10.3886/ICPSR36423.v1\n\n\n\n",
    "preview": "posts/2021-02-27-kristenjordanproject/distill-preview.png",
    "last_modified": "2021-03-09T03:27:18+00:00",
    "input_file": {}
  },
  {
    "path": "posts/cathrine_gi_project/",
    "title": "Predicting Hospital Exit",
    "description": "Project introduction",
    "author": [
      {
        "name": "Catherine Ishitani",
        "url": {}
      },
      {
        "name": "Gi Kim",
        "url": {}
      }
    ],
    "date": "2021-03-03",
    "categories": [
      "Catherine and Gi's project"
    ],
    "contents": "\nResearch question\nCan we predict whether a hospital will exit from a market?\nMore specifically, predict whether it will shut down, convert to a clinic, be acquired, or continue participating in a market.\nFeature selection: given many potentially relevant variables, which are most important for prediction?\nNon-linearity: is a hospital’s underlying exit decision making process well captured by a non-linear model?\n\n\n\nFigure 1: Hospital closures, 2003-2011 (Source: Harvard School of Public Health)\n\n\n\nMotivation\nHospital exit is an important policy issue in its own right (e.g., access to care in rural communities and during COVID). Another initial inspiration for this project was to try to empirically investigate revealed preference assumptions used in dynamic entry models. That is, a firm’s exit reveals something about the structure of its underlying profit. However, to the extent that a firm’s exit is a complex function of capital constraints and factors related and unrelated to profits, it may not reveal much about expected profitability.\nWe expect that ML techniques such as RF may be able to outperform regression methods. Intuitively, a hospital’s actual decision making process may resemble a decision tree more than a linear function of expected profits. It’s not hard to come up with hypothetical non-linearities for hospitals:\nCapital constraints and non-profit utility: A non-profit hospital may prefer to stay open with low expected profits but be constrained in borrowing more to do so (Lakdawalla and Phillipson 2006). In contrast, public or for-profit hospitals may enjoy easier access to capital– from donors and local governments, or parent systems and equity capital markets, respectively (Duggan 2000).\nMultiple agents: hospital systems and debtholders may make participation decisions on behalf of hospitals that are not expected utility maximizing (Stulz 1990).\nUncertainty: risk averse managers may prefer a hospital’s scrap value, or alternate uses of capital, to uncertain future profits (Wedig et al. 1989).\nPreliminary algorithmic modeling plan\nFirst, we plan to build and prune a classification tree using the CART algorithm. Our first ~7 years of data can be used as the training set, and the last ~3 years as a test set. Next, we plan to grow a random forest, tuning the number of variables considered at each split as needed. We will attempt to interpret the models using variable importance plots, e.g., based on the Gini splitting index. We also plan to try bagging and boosting trees.\nWhy RF?\nWe have high dimensional data, so we plan to rely on RF for variable selection.\nRF is hard to overfit, provides good predictive performance and some interpretability.\nRF predicts relatively better when the underlying process is highly nonlinear, e.g., in the context of uncertainty and frictions (Coulombe et al. 2020).\nIt may be informative to compare the performance of RF against multinomial logit or linear methods for classification and try to assess how important nonlinearity is. If we are lucky, inspection of the pruned tree, variable importance plots, and the first weak learner variables may give us a sense of whether capital constraints, debt and system ownership, or opportunity costs of capital predict exit, and what factors specifically differentiate closures from conversions and acquisitions.\nData\n\n\n\nWe are still adding variables to our data, but here are some preliminary descriptive statistics. The key outcome variable is a hospital’s market participation decision in each year:\n\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  57834 \n\n \n          |  absorbed |    bought |   convert |  downsize |     enter | \n          |-----------|-----------|-----------|-----------|-----------|\n          |       132 |      2227 |        45 |      7054 |       583 | \n          |     0.002 |     0.039 |     0.001 |     0.122 |     0.010 | \n          |-----------|-----------|-----------|-----------|-----------|\n\n          |      exit |    invest | no change | switch np | \n          |-----------|-----------|-----------|-----------|\n          |       629 |      6824 |     39758 |       582 | \n          |     0.011 |     0.118 |     0.687 |     0.010 | \n          |-----------|-----------|-----------|-----------|\n\n\n\n \n\nWe observe ~6,300 hospitals over 2008-2017 (or as early as 1996, with some more work).\nOur explanatory variables include hospital characteristics (e.g., non-profit, rural, # of beds) and financial data, along with market demand and competition factors. We have ~80 explanatory variables (~33 of which are categorical; the remainder are quantitative) before including lags.\nIf we skim the data, it looks like this:\n\n\nskim(hcris)\n\n\nTable 1: Data summary\nName\nhcris\nNumber of rows\n57834\nNumber of columns\n88\n_______________________\n\nColumn type frequency:\n\ncharacter\n5\nnumeric\n83\n________________________\n\nGroup variables\nNone\nVariable type: character\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\nid\n0\n1\n7\n7\n0\n6299\n0\nmloczip\n0\n1\n0\n10\n11238\n8209\n0\nhrrcode\n0\n1\n0\n3\n4\n307\n0\nexit_reason\n0\n1\n0\n12\n57098\n8\n0\noutcome\n0\n1\n4\n9\n0\n9\n0\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nnum_prvdr_num\n0\n1.00\n266757.89\n155382.08\n10001.00\n140202.00\n251325.50\n390232.50\n6.730600e+05\n▇▇▆▆▁\nyear\n0\n1.00\n2012.48\n2.85\n2008.00\n2010.00\n2012.00\n2015.00\n2.017000e+03\n▇▇▇▇▇\nown\n100\n1.00\n2.05\n0.69\n1.00\n2.00\n2.00\n3.00\n3.000000e+00\n▃▁▇▁▃\ndsh\n2147\n0.96\n0.48\n0.50\n0.00\n0.00\n0.00\n1.00\n1.000000e+00\n▇▁▁▁▇\nteach\n100\n1.00\n0.05\n0.21\n0.00\n0.00\n0.00\n0.00\n1.000000e+00\n▇▁▁▁▁\nminorteach\n0\n1.00\n0.24\n0.43\n0.00\n0.00\n0.00\n0.00\n1.000000e+00\n▇▁▁▁▂\ncatholic\n100\n1.00\n0.11\n0.31\n0.00\n0.00\n0.00\n0.00\n1.000000e+00\n▇▁▁▁▁\nrural\n0\n1.00\n0.35\n0.48\n0.00\n0.00\n0.00\n1.00\n1.000000e+00\n▇▁▁▁▅\nmcare\n100\n1.00\n0.49\n0.19\n0.00\n0.41\n0.50\n0.59\n1.000000e+00\n▁▂▇▂▁\nmcaid\n100\n1.00\n0.16\n0.12\n0.00\n0.08\n0.16\n0.22\n1.000000e+00\n▇▃▁▁▁\nuncomp\n17328\n0.70\n14.94\n27.05\n0.04\n1.90\n5.79\n15.97\n2.826700e+02\n▇▁▁▁▁\nmcaid_exp\n0\n1.00\n0.19\n0.39\n0.00\n0.00\n0.00\n0.00\n1.000000e+00\n▇▁▁▁▂\nsystem\n11214\n0.81\n0.59\n0.49\n0.00\n0.00\n1.00\n1.00\n1.000000e+00\n▆▁▁▁▇\nvi\n0\n1.00\n0.43\n0.49\n0.00\n0.00\n0.00\n1.00\n1.000000e+00\n▇▁▁▁▆\nregion9\n0\n1.00\n5.98\n2.55\n1.00\n4.00\n6.00\n9.00\n9.000000e+00\n▂▆▂▆▇\nregion4\n0\n1.00\n2.80\n1.03\n1.00\n2.00\n3.00\n4.00\n4.000000e+00\n▂▇▁▅▇\nwage_index\n25082\n0.57\n0.98\n0.19\n0.68\n0.85\n0.93\n1.05\n1.930000e+00\n▇▅▂▁▁\ntacmi\n25028\n0.57\n1.50\n0.34\n0.43\n1.28\n1.48\n1.68\n4.880000e+00\n▃▇▁▁▁\ntot_pop\n2391\n0.96\n723217.85\n1563713.92\n682.00\n37001.50\n161605.00\n697181.00\n1.017029e+07\n▇▁▁▁▁\nwhite\n395\n0.99\n0.78\n0.17\n0.03\n0.66\n0.81\n0.92\n1.000000e+00\n▁▁▂▅▇\nhighschool\n395\n0.99\n0.31\n0.08\n0.06\n0.25\n0.30\n0.36\n5.500000e-01\n▁▅▇▅▁\ncollege\n395\n0.99\n0.16\n0.06\n0.02\n0.12\n0.16\n0.20\n4.300000e-01\n▃▇▅▁▁\nunempl\n395\n0.99\n0.08\n0.03\n0.00\n0.06\n0.07\n0.10\n2.900000e-01\n▃▇▂▁▁\nmed_inc\n395\n0.99\n54607.66\n14408.88\n20281.04\n45078.89\n52115.87\n60430.00\n1.374222e+05\n▂▇▂▁▁\nuninsur\n8964\n0.85\n0.13\n0.06\n0.01\n0.09\n0.12\n0.17\n4.600000e-01\n▆▇▂▁▁\npublic_insur\n8964\n0.85\n0.33\n0.08\n0.08\n0.28\n0.32\n0.38\n7.100000e-01\n▁▇▇▁▁\nprivate_insur\n8964\n0.85\n0.66\n0.10\n0.20\n0.60\n0.66\n0.73\n9.300000e-01\n▁▁▆▇▂\nelderly\n395\n0.99\n0.15\n0.04\n0.04\n0.12\n0.14\n0.17\n5.700000e-01\n▇▇▁▁▁\npoverty\n395\n0.99\n0.16\n0.06\n0.01\n0.12\n0.15\n0.19\n4.900000e-01\n▂▇▂▁▁\ndsh_pct\n31284\n0.46\n0.16\n0.14\n0.00\n0.08\n0.12\n0.18\n1.200000e+01\n▇▁▁▁▁\ndsh_adj\n31328\n0.46\n3.20\n5.58\n0.00\n0.38\n1.18\n3.62\n1.153400e+02\n▇▁▁▁▁\nstcd\n100\n1.00\n56.14\n22.94\n11.00\n39.00\n54.00\n74.00\n9.500000e+01\n▃▇▃▇▅\ncntrl\n100\n1.00\n23.48\n6.51\n12.00\n21.00\n23.00\n32.00\n3.300000e+01\n▃▁▇▁▃\nserv\n100\n1.00\n18.47\n19.47\n10.00\n10.00\n10.00\n10.00\n9.000000e+01\n▇▁▁▁▁\nbdtot\n100\n1.00\n152.08\n184.69\n1.00\n33.00\n84.00\n201.00\n2.877000e+03\n▇▁▁▁▁\nadmtot\n100\n1.00\n6119.98\n9019.69\n1.00\n675.00\n2143.00\n8240.75\n1.511830e+05\n▇▁▁▁▁\nipdtot\n100\n1.00\n36478.92\n51541.35\n1.00\n5547.00\n17605.50\n46843.00\n7.618890e+05\n▇▁▁▁▁\npaytot\n102\n1.00\n54071960.06\n101976471.66\n0.00\n7698813.00\n19167053.50\n58394079.25\n2.702995e+09\n▇▁▁▁▁\nexptot\n102\n1.00\n137667782.58\n257157170.36\n257512.00\n18304790.25\n46559045.50\n150104210.00\n5.543478e+09\n▇▁▁▁▁\nfte\n102\n1.00\n863.08\n1433.81\n0.00\n162.00\n359.00\n986.00\n3.053300e+04\n▇▁▁▁▁\nfcounty\n100\n1.00\n29038.88\n15597.95\n1001.00\n17051.00\n28124.00\n42079.00\n5.604500e+04\n▅▇▆▆▇\ncah\n3\n1.00\n0.23\n0.42\n0.00\n0.00\n0.00\n0.00\n1.000000e+00\n▇▁▁▁▂\nbought\n102\n1.00\n0.03\n0.18\n0.00\n0.00\n0.00\n0.00\n1.000000e+00\n▇▁▁▁▁\nsysid\n22640\n0.61\n1363.76\n2352.01\n1.00\n92.00\n294.50\n1012.00\n9.605000e+03\n▇▁▁▁▁\nsysowned\n102\n1.00\n0.61\n0.49\n0.00\n0.00\n1.00\n1.00\n1.000000e+00\n▅▁▁▁▇\nbought_is\n102\n1.00\n0.01\n0.11\n0.00\n0.00\n0.00\n0.00\n1.000000e+00\n▇▁▁▁▁\nabsorbed\n57736\n0.00\n1.00\n0.00\n1.00\n1.00\n1.00\n1.00\n1.000000e+00\n▁▁▇▁▁\nabsorbing\n57739\n0.00\n1.00\n0.00\n1.00\n1.00\n1.00\n1.00\n1.000000e+00\n▁▁▇▁▁\nmale\n5829\n0.90\n0.49\n0.02\n0.37\n0.49\n0.49\n0.50\n7.200000e-01\n▁▇▁▁▁\nno_ins\n7988\n0.86\n0.13\n0.06\n0.01\n0.08\n0.12\n0.16\n4.600000e-01\n▆▇▂▁▁\npub_ins\n7988\n0.86\n0.34\n0.08\n0.09\n0.29\n0.34\n0.39\n7.100000e-01\n▁▇▇▁▁\npriv_ins\n7988\n0.86\n0.66\n0.10\n0.20\n0.59\n0.66\n0.73\n9.100000e-01\n▁▁▅▇▂\ntot\n0\n1.00\n211529.64\n204495.44\n3440.00\n67499.00\n140011.00\n298232.00\n1.106583e+06\n▇▂▁▁▁\nhrr_sh\n100\n1.00\n0.05\n0.10\n0.00\n0.01\n0.02\n0.05\n9.500000e-01\n▇▁▁▁▁\nexit\n0\n1.00\n0.01\n0.12\n0.00\n0.00\n0.00\n0.00\n1.000000e+00\n▇▁▁▁▁\nenter\n0\n1.00\n0.01\n0.10\n0.00\n0.00\n0.00\n0.00\n1.000000e+00\n▇▁▁▁▁\nyrs_missed\n57621\n0.00\n1.86\n1.26\n1.00\n1.00\n2.00\n2.00\n9.000000e+00\n▇▁▁▁▁\nbought_ss\n102\n1.00\n0.02\n0.14\n0.00\n0.00\n0.00\n0.00\n1.000000e+00\n▇▁▁▁▁\nswitch\n0\n1.00\n0.01\n0.12\n0.00\n0.00\n0.00\n0.00\n1.000000e+00\n▇▁▁▁▁\nswitch2np\n0\n1.00\n0.01\n0.10\n0.00\n0.00\n0.00\n0.00\n1.000000e+00\n▇▁▁▁▁\nage\n0\n1.00\n10.54\n3.45\n1.00\n8.00\n11.00\n13.00\n1.600000e+01\n▂▃▇▇▆\ninvest\n881\n0.98\n0.00\n0.51\n-1.00\n0.00\n0.00\n0.00\n1.000000e+00\n▂▁▇▁▂\ncont\n0\n1.00\n0.98\n0.16\n0.00\n1.00\n1.00\n1.00\n1.000000e+00\n▁▁▁▁▇\nptnt_opex\n1455\n0.97\n150.42\n235.34\n3.96\n19.94\n53.66\n175.64\n1.644550e+03\n▇▁▁▁▁\noth_costs\n38076\n0.34\n4.65\n14.34\n-36.02\n0.01\n0.30\n2.43\n1.256900e+02\n▁▇▁▁▁\ntot_costs\n1455\n0.97\n152.25\n238.08\n4.02\n20.15\n54.28\n177.62\n1.654300e+03\n▇▁▁▁▁\nrev_tot\n2712\n0.95\n169.21\n308.40\n-71.27\n20.80\n56.72\n188.67\n7.000000e+03\n▇▁▁▁▁\nrev_netptnt\n2712\n0.95\n156.05\n277.18\n0.00\n19.24\n53.29\n178.85\n6.804950e+03\n▇▁▁▁▁\nnet_income\n1486\n0.97\n6.82\n68.85\n-5702.48\n-0.47\n1.40\n9.02\n5.676190e+03\n▁▁▇▁▁\nptnt_income\n1449\n0.97\n-2.38\n86.32\n-5899.20\n-3.44\n-0.18\n4.16\n1.049143e+04\n▁▇▁▁▁\ncash\n1448\n0.97\n19.60\n82.30\n-1996.92\n0.02\n1.55\n9.42\n3.606410e+03\n▁▇▁▁▁\ndebt\n1448\n0.97\n24.85\n95.43\n0.00\n0.00\n0.64\n8.75\n3.046200e+03\n▇▁▁▁▁\ntot_assets\n1448\n0.97\n178.38\n350.73\n-2.99\n13.20\n46.50\n171.89\n2.762280e+03\n▇▁▁▁▁\nfa_tot\n1448\n0.97\n78.19\n174.84\n-587.52\n4.74\n21.24\n78.48\n3.628610e+03\n▇▁▁▁▁\ncapex\n9422\n0.84\n9.82\n21.70\n-25.24\n0.60\n2.42\n9.31\n1.524700e+02\n▇▂▁▁▁\nliquid\n8219\n0.86\n2.47\n1.75\n0.08\n1.27\n2.06\n3.17\n9.200000e+00\n▇▆▂▁▁\nrev_adm\n2810\n0.95\n0.03\n0.03\n0.01\n0.02\n0.03\n0.04\n2.900000e-01\n▇▁▁▁▁\nptnt_mgn\n3169\n0.95\n-0.01\n0.15\n-0.63\n-0.07\n0.00\n0.07\n3.700000e-01\n▁▁▅▇▂\nni_mgn\n2994\n0.95\n0.04\n0.11\n-0.45\n-0.01\n0.04\n0.09\n3.800000e-01\n▁▁▇▆▁\nuncomp_mgn\n17328\n0.70\n0.08\n0.06\n0.00\n0.04\n0.07\n0.10\n5.500000e-01\n▇▂▁▁▁\ncapex_mgn\n9422\n0.84\n0.06\n0.09\n-0.27\n0.02\n0.05\n0.08\n5.900000e-01\n▁▇▃▁▁\nlevg\n1486\n0.97\n1256.84\n277154.47\n-3831512.00\n0.00\n0.00\n0.86\n6.526006e+07\n▇▁▁▁▁\nnetdebt\n1448\n0.97\n5.25\n106.15\n-3606.41\n-3.18\n0.00\n3.51\n2.759120e+03\n▁▁▇▁▁\n\nOur data sources are:\nCenter for Medicare & Medicaid Services (CMS) Hospital Cost Report Information System (HCRIS): financial data for US providers (hospitals)\nAmerican Hospital Association (AHA): hospital characteristics; tracks exits and ownership changes\nAmerican Community Survey (ACS): market demographics\nOther CMS data: average Medicare patient complexity, local wages, (possibly) other local providers\n\n\n\n",
    "preview": "posts/cathrine_gi_project/distill-preview.png",
    "last_modified": "2021-03-03T02:46:16+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-28-elements-of-distill-and-rmarkdown/",
    "title": "Elements of Rmarkdown and R",
    "description": "A look at some of the elements of style for your blog posts.",
    "author": [
      {
        "name": "Amit Gandhi",
        "url": {}
      }
    ],
    "date": "2021-02-28",
    "categories": [
      "lecture"
    ],
    "contents": "\n\n\n\nTopics:\nbibliography (Jonathan)\nFootnotes\nAsides\nHeaders and levels\nmarkdown tables\nrendering R tables\ninserting images, hyperlinks, boldface lettering, etc.\nunderstanding the structure of YAML metadata\ncode chunk options\nWhat is YAML?\nThe initial portion of your Rmarkdown document, fenced in between the 3 dashes --- on the top and bottom, a represents the YAML metadata or YAML frontmatter of the document. It is named according to the fact the top section of the document is written in the YAML language syntax - YAML is an recursive acronym that stands for YAML ain’t markup language.\nThe metadata defined by the code defines properties of the document that control aspects of its content, appearance, and formatting. Much of the ability to extend and customize the functionality of an Rmarkdown document arises from a suitable specification of the YAML metadata, and hence it is worth some investment of effort to learn the fundamentals.\nThe general language guide is a useful reference, and the connection between R and YAML is best appreciated from the vignette associated with the ymlthis package.\nThe basic idea of YAML is to collect as data a set of key value pairs key: value, e.g.,\n---\nauthor: Amit Gandhi\n---\nThe structure of metadata is isomorphic to a named list in R. In particular we can convert from a list to a YAML specification.\n\n\nmetaDat <- list(author = \"Amit Gandhi\")\nyml(metaDat)\n\n\n---\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\n---\n\ndraw_yml_tree(metaDat)\n\n\n└── author: Amit Gandhi\n\nOr vice-versa, the metadata of a document can be retreived as a named list in R\n\n\ndocDat <- rmarkdown::metadata\nstr(docDat)\n\n\nList of 9\n $ title      : chr \"Elements of Rmarkdown and R\"\n $ description: chr \"A look at some of the elements of style for your blog posts.\\n\"\n $ author     :List of 1\n  ..$ :List of 1\n  .. ..$ name: chr \"Amit Gandhi\"\n $ date       : chr \"02-28-2021\"\n $ output     :List of 1\n  ..$ distill::distill_article:List of 1\n  .. ..$ self_contained: logi FALSE\n $ css        : chr \"styles.css\"\n $ params     :List of 1\n  ..$ year:List of 1\n  .. ..$ value: int 80\n $ preview    : chr \"https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/rmarkdown.png\"\n $ categories : chr \"lecture\"\n\nThe other key idea is that of nesting - a field in the YAML frontmatter can have other key-value pairs as its value. The nesting is indicated by an indented space\n---\nauthor: Amit Gandhi\noutput: distill::article:\n          self_contained: true\n\n---          \nThe analogous data structure in R is a nested list\n\n\nmetaDat <- list(author = \"Amit Gandhi\", output = list(`distill::article` = list(self_contained = \"TRUE\" ) ) )\nyml(metaDat)\n\n\n---\nauthor: Amit Gandhi\noutput:\n  distill::article:\n    self_contained: 'TRUE'\ndate: '`r format(Sys.Date())`'\n---\n\nThe hierarchical structure can be visualized as\n\n\ndraw_yml_tree(metaDat)\n\n\n├── author: Amit Gandhi\n└── output:\n    └── distill::article:\n        └── self_contained: 'TRUE'\n\nTo understand the functionality the YAML nested syntax is achieving, observe that the value of the field outpt in the frontmatter indicates the function used to render the Rmarkdown file. The function in this case is distill::article. If we examine the options to this function, we can see many potential arguments.\n\n\nhelp_console(\"distill_article\", \"distill\", format = \"html\")\n\n\n\ndistill_article\n\n\nR Documentation\n\n\nR Markdown format for Distill articles\n\n\nDescription\n\n\nScientific and technical writing, native to the web.\n\n\nUsage\n\n\ndistill_article(\n  toc = FALSE,\n  toc_depth = 3,\n  toc_float = TRUE,\n  fig_width = 6.5,\n  fig_height = 4,\n  fig_retina = 2,\n  fig_caption = TRUE,\n  dev = \"png\",\n  smart = TRUE,\n  self_contained = TRUE,\n  highlight = \"default\",\n  highlight_downlit = TRUE,\n  mathjax = \"default\",\n  extra_dependencies = NULL,\n  theme = NULL,\n  css = NULL,\n  includes = NULL,\n  keep_md = FALSE,\n  lib_dir = NULL,\n  md_extensions = NULL,\n  pandoc_args = NULL,\n  ...\n)\n\n\nArguments\n\n\ntoc\n\n\n\nTRUE to include a table of contents in the output\n\n\n\ntoc_depth\n\n\n\nDepth of headers to include in table of contents\n\n\n\ntoc_float\n\n\n\nFloat the table of contents to the left when the article is displayed at widths > 1000px. If set to FALSE or the width is less than 1000px the table of contents will be placed above the article body.\n\n\n\nfig_width\n\n\n\nDefault width (in inches) for figures\n\n\n\nfig_height\n\n\n\nDefault height (in inches) for figures\n\n\n\nfig_retina\n\n\n\nScaling to perform for retina displays (defaults to 2, which currently works for all widely used retina displays). Set to NULL to prevent retina scaling. Note that this will always be NULL when keep_md is specified (this is because fig_retina relies on outputting HTML directly into the markdown document).\n\n\n\nfig_caption\n\n\n\nTRUE to render figures with captions\n\n\n\ndev\n\n\n\nGraphics device to use for figure output (defaults to png)\n\n\n\nsmart\n\n\n\nProduce typographically correct output, converting straight quotes to curly quotes, — to em-dashes, – to en-dashes, and … to ellipses.\n\n\n\nself_contained\n\n\n\nProduce a standalone HTML file with no external dependencies, using data: URIs to incorporate the contents of linked scripts, stylesheets, images, and videos. Note that even for self contained documents MathJax is still loaded externally (this is necessary because of its size).\n\n\n\nhighlight\n\n\n\nSyntax highlighting style. Supported styles include “default”, “rstudio”, “tango”, “pygments”, “kate”, “monochrome”, “espresso”, “zenburn”, “breezedark”, and “haddock”. Pass NULL to prevent syntax highlighting.\n\n\n\nhighlight_downlit\n\n\n\nUse the downlit package to highlight R code (including providing hyperlinks to function documentation).\n\n\n\nmathjax\n\n\n\nInclude mathjax. The “default” option uses an https URL from a MathJax CDN. The “local” option uses a local version of MathJax (which is copied into the output directory). You can pass an alternate URL or pass NULL to exclude MathJax entirely.\n\n\n\nextra_dependencies\n\n\n\nAdditional function arguments to pass to the base R Markdown HTML output formatter html_document_base\n\n\n\ntheme\n\n\n\nCSS file with theme variable definitions\n\n\n\ncss\n\n\n\nOne or more css files to include\n\n\n\nincludes\n\n\n\nNamed list of additional content to include within the document (typically created using the includes function).\n\n\n\nkeep_md\n\n\n\nKeep the markdown file generated by knitting.\n\n\n\nlib_dir\n\n\n\nDirectory to copy dependent HTML libraries (e.g. jquery, bootstrap, etc.) into. By default this will be the name of the document with _files appended to it.\n\n\n\nmd_extensions\n\n\n\nMarkdown extensions to be added or removed from the default definition or R Markdown. See the rmarkdown_format for additional details.\n\n\n\npandoc_args\n\n\n\nAdditional command line options to pass to pandoc\n\n\n\n…\n\n\n\nAdditional function arguments to pass to the base R Markdown HTML output formatter html_document_base\n\n\n\nDetails\n\n\nDistill articles feature attractive, reader-friendly typography, flexible layout options for visualizations, and full support for footnotes and citations.\n\n\nWe can see many options associated with the function. If we want to use the default values we can simply associate the value default with the field distill::article.\n---\n<yaml>\noutput:\n  distill::distill_article: default\n<yaml>\n---\nBut if we wish to set any of the arguments, we must engage another nest of key value pairs, e.g.,\n\n\nmetaDat <- list(author = \"Amit Gandhi\", output = list(`distill::article` = list(self_contained = \"TRUE\", toc = \"TRUE\" ) ) )\nyml(metaDat)\n\n\n---\nauthor: Amit Gandhi\noutput:\n  distill::article:\n    self_contained: 'TRUE'\n    toc: 'TRUE'\ndate: '`r format(Sys.Date())`'\n---\n\ndraw_yml_tree(metaDat)\n\n\n├── author: Amit Gandhi\n└── output:\n    └── distill::article:\n        ├── self_contained: 'TRUE'\n        └── toc: 'TRUE'\n\nInstead of nested data capturing key-value pairs (which are named lists), the value of a field if its more complex than a simple value can be an unnamed vector, such as\n\n\nmetaDat <- list(author = c(\"Amit Gandhi\", \"coauthor\"), output = list(`distill::article` = list(self_contained = \"TRUE\", toc = \"TRUE\" ) ) )\nyml(metaDat)\n\n\n---\nauthor:\n- Amit Gandhi\n- coauthor\noutput:\n  distill::article:\n    self_contained: 'TRUE'\n    toc: 'TRUE'\ndate: '`r format(Sys.Date())`'\n---\n\nObserve this is captured in YAML code as\n---\nauthor:\n- A\n- B\n- C\n---\nwhere each element of the vector is entered with a new line along with a - without a need for indentation.\nA slight elaboration of this pattern is grouped data, as arises with the params field in the frontmatter\n---\nparams:\n- a: 1.0\n  input: numeric\n- data: data.csv\n  input: text\n---\nwhich is useful to group related data. The corresponding R data structure is an unnamed list, e.g.,\n\n\nlist(params = list( list(a = 1.0, input = \"numeric\"), list(data = \"data.csv\", input = \"text\") ) ) %>% yml()\n\n\n---\nparams:\n- a: 1.0\n  input: numeric\n- data: data.csv\n  input: text\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\n---\n\nThere are a few differences with R and YAML that should be recognized from our exercise. The first is that string values do not have to be quoted, unless they contain special characters, e.g.,\n---\ntitle: 'R Markdown: An Introduction'\n---\nThe string value is quoted because of the presence of the special character (a colon).\nAlso observe that whereas the logical values in R are TRUE/FALSE, in YAML they can be yes/no, true/false, or on/off.\nOn the usefulness of parameterized documents\nTHe parameter field in the YAML front matter as it allows for the creation of parameterized reports. Such report generation is especially powerful when used in conjunction with the glue and epoxy packages, which we explore below.\nLets use the BLP data (borrowing from Jonathan and Sheng’s project.)\nFirst import the data\n\n\ncarDat = read_csv(\"../jonathan-sheng-algorithmic-demand-estimation/blp.csv\")\n\n\n\nLets use a dplyr verb to count the number of observations by model_year\n\n\ncarDat %>%\n  count(model_year)\n\n\n# A tibble: 20 x 2\n   model_year     n\n *      <dbl> <int>\n 1         71   131\n 2         72   193\n 3         73    69\n 4         74    81\n 5         75   131\n 6         76    88\n 7         77   101\n 8         78    91\n 9         79    90\n10         80   125\n11         81   130\n12         82    88\n13         83    95\n14         84   211\n15         85   122\n16         86    97\n17         87   120\n18         88   101\n19         89    87\n20         90    66\n\nContrast it with the so called market variable\n\n\ncarDat %>%\n  count(market)\n\n\n# A tibble: 20 x 2\n   market     n\n *  <dbl> <int>\n 1      1    92\n 2      2    89\n 3      3    86\n 4      4    72\n 5      5    93\n 6      6    99\n 7      7    95\n 8      8    95\n 9      9   102\n10     10   103\n11     11   116\n12     12   110\n13     13   115\n14     14   113\n15     15   136\n16     16   130\n17     17   143\n18     18   150\n19     19   147\n20     20   131\n\nWe can use the glue package to weave the data together with text. Effectively we can Lets foreshadow the application.\nThe simplest application of glue is\n\n\na <- \"Amit\"\nglue(\"My name is {a}\")\n\n\nMy name is Amit\n\nwe can paste together distinct strings\n\n\na <- \"Amit\"\nb <- 712\nglue(\"My name is {a}\", \"I teach Econ {b}\")\n\n\nMy name is AmitI teach Econ 712\n\nIt is useful to add a separator\n\n\na <- \"Amit\"\nb <- 712\nglue(\"My name is {a}\", \"I teach Econ {b}\", .sep = \", \")\n\n\nMy name is Amit, I teach Econ 712\n\nThe function naturally vectorizes\n\n\na <- c(\"Amit\", \"Amit\")\nb <- c(712, 712)\nglue(\"My name is {a}\", \"I teach Econ {b}\", .sep = \", \") \n\n\nMy name is Amit, I teach Econ 712\nMy name is Amit, I teach Econ 712\n\nwhich is a character vector of length 2\nIf we want to collapse the vector into text that can be rendered in markdown we must use the results = asis chunk option and collapse the resulting vector.\n\n\nglue(\"My name is {a}\", \"I teach Econ {b}\", .sep = \", \") %>%\n  glue_collapse(\"\\n\")\n\n\nMy name is Amit, I teach Econ 712 My name is Amit, I teach Econ 712\n\nIf we want to use data masking and reference variables directly we can via glue_data()\n\n\ndemoDat <- tribble(\n  ~name, ~course,\n  \"Amit\", 712,\n  \"Amit\", 712\n)\n\ndemoDat %>% \n  glue_data(\"My name is {name}, and I teach Econ {course}\")\n\n\nMy name is Amit, and I teach Econ 712\nMy name is Amit, and I teach Econ 712\n\nWe can use the epoxy package to seamlessly blend text and code with a new engine for knitr.\n\nMy name is Amit and the course I teach is Econ 712\nMy name is Amit and the course I teach is Econ 712\n\nThe combination of epoxy and glue are powerful when connected to parameter meta data. We can thus write\n\nIn the year 1971 there were 131 car models.\nIn the year 1972 there were 193 car models.\nIn the year 1973 there were 69 car models.\nIn the year 1974 there were 81 car models.\nIn the year 1975 there were 131 car models.\nIn the year 1976 there were 88 car models.\nIn the year 1977 there were 101 car models.\nIn the year 1978 there were 91 car models.\nIn the year 1979 there were 90 car models.\nIn the year 1980 there were 125 car models.\nIn the year 1981 there were 130 car models.\nIn the year 1982 there were 88 car models.\nIn the year 1983 there were 95 car models.\nIn the year 1984 there were 211 car models.\nIn the year 1985 there were 122 car models.\nIn the year 1986 there were 97 car models.\nIn the year 1987 there were 120 car models.\nIn the year 1988 there were 101 car models.\nIn the year 1989 there were 87 car models.\nIn the year 1990 there were 66 car models.\n\nBuilding YAML objects from a pipeline\nOne of the powerful features of the Tidyverse is its natural ability to express data pipelines.\nI look at data pipelines rather broadly as the encapsulation of most computations.\nIt is helpful to recall/recognize the two fundamental rules of R:\nEverything that exists in R is an object\nEverything that happens in R is a function call\nThus a natural way to builld or develop a thought process is to start with a simple object and layer complexity by transforming the object via function calls.\nObjects in R are data structures. The interpretation of the data structure is given by the class() of the object. Applying a function to an object to yield another object can thus be seen as a manipulation of a data structure. In this fashion, general programming in R becomes a form of data analysis!\nAn important construct to aid this form of analysis is the pipe operator %>%. It passes an object into a function (in its first argument) and the object resulting from the function call can be passed to another function, and so on, resulting in a data pipeline!\nLets examine this process with the ymlthis package. We have already seen that YAML metadata maps to an R data structure (effectively a named list with nested lists/vectors).\nHow can we conceptually develop the data. Lets start with the creation of a yml object\n\n\nymlDat <-\n  yml()\n\n\n\nObserve the class and underlying base type.\n\n\nclass(ymlDat)\n\n\n[1] \"yml\"\n\ntypeof(ymlDat)\n\n\n[1] \"list\"\n\nWe can see the data structure named ymlDat is of class yml which is underneath the hood a list of data that can be interpreted as YAML metadata by appropriate functions. In particular functions that start with yml_*() take and return yml objects,\n\n\nyml() %>% \n  yml_title(\"Economics and ML\") %>%\n  yml_output(rmarkdown::html_document(toc = TRUE))\n\n\n---\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\ntitle: Economics and ML\noutput:\n  rmarkdown::html_document:\n    toc: true\n---\n\n\n\nyml_empty() %>%\n  yml_author(c(\"Amit GAndhi\", \"coauthor\"), affiliation = \"University of Pennsylvania\", url = \"www.upenn.edu\") %>%\n  yml_title(\"A discussion of Rmarkdown\") %>%\n  yml_description(\"A deeper look into pipelines\") %>%\n  yml_distill_opts(\n    twitter_site = \"xxx\",\n    collection = distill_collection(\n      share = c(\"twitter\", \"linkedin\")\n    )\n  )\n\n\n---\nauthor:\n- name: Amit GAndhi\n  affiliation: University of Pennsylvania\n  url: www.upenn.edu\n- name: coauthor\n  affiliation: University of Pennsylvania\n  url: www.upenn.edu\ntitle: A discussion of Rmarkdown\ndescription: A deeper look into pipelines\ncollection:\n  post:\n    share:\n    - twitter\n    - linkedin\ntwitter:\n  site: xxx\n---\n\nWe can add parameters\n\n\nyml() %>% \n  yml_params(country = \"Turkey\")\n\n\n---\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\nparams:\n  country: Turkey\n---\n\nWe can also add a bibliography\n\n\nyml() %>% \n  yml_citations(bibliography = \"refs.bib\")\n\n\n---\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\nbibliography: refs.bib\n---\n\nWe can instead add references manually instead of throught a .bib file\n\n\nref <- reference(\n  id = \"fenner2012a\",\n  title = \"One-click science marketing\",\n  author = list(\n    family = \"Fenner\",\n    given = \"Martin\"\n  ),\n  `container-title` = \"Nature Materials\",\n  volume = 11L,\n  URL = \"https://doi.org/10.1038/nmat3283\",\n  DOI = \"10.1038/nmat3283\",\n  issue = 4L,\n  publisher = \"Nature Publishing Group\",\n  page = \"261-263\",\n  type = \"article-journal\",\n  issued = list(\n    year = 2012,\n    month = 3\n  )\n)\n\nyml() %>%\n  yml_reference(ref)\n\n\n---\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\nreference:\n- id: fenner2012a\n  title: One-click science marketing\n  author:\n    family: Fenner\n    given: Martin\n  container-title: Nature Materials\n  volume: 11\n  URL: https://doi.org/10.1038/nmat3283\n  DOI: 10.1038/nmat3283\n  issue: 4\n  publisher: Nature Publishing Group\n  page: 261-263\n  type: article-journal\n  issued:\n    year: 2012.0\n    month: 3.0\n---\n\nWe can then reference the entry using @id in Rmarkdown.\nFinally we can create the markdown text that produces the YAML frontmatter via\n\n---\nauthor: Amit Gandhi\ndate: '`r format(Sys.Date())`'\n---\n\nData Frame pipelines\nLets imitate the workflow, but for a data set. A tibble is a class of an object. We act on the tibble with verbs. The major verbs are given by the dplyr package.\nVerbs\nWe are going to cover a set of functions that take a data frame as an input and return a new version of the data frame.\nThese functions are called verbs and come from the dplyr package. If you are familiar with running database queries, note that all of these verbs map onto SQL commands. In fact, R can be set up so that dplyr is called over a database rather than a local data frame in memory.\nThere are over 40 verbs in the dplyr package, though most are a minor variant or specific application of another verb. We start with four of them, all of which are related to selecting and arranging rows and columns:\nselect a subset of rows from the original data set (filter)\nselect a subset of columns from the original data set (select)\nsort the rows of a data set (arrange)\nIn all verb functions, the first argument is the original data frame and the output is a new data frame. Here, we will also see the functions between and %in% to assist with the filtering command and desc to assist with arranging the rows of a data set.\nNote that verbs do not modify the original data; they operate on a copy of the original data. We have to make an explicit name for the new data set if we want to save it for use elsewhere.\nChoosing rows\nIt is often useful to take a subset of the rows of an existing data set, for example if you want to build a model on a certain subpopulation or highlight a particular part of the data in a plot.\nA standard way to take a subset of our data is to select rows based on conditions about the variables in the data set. To do this we use the filter function, which accepts a statement about variable in the data set. Only rows where the statements are true will be returned. For example, here is how we use the filter command to select the foods that have more than 150 calories grams of sugar in each serving:\n\n\nfood %>%\n  filter(calories > 150)\n\n\n# A tibble: 20 x 17\n   item       food_group calories total_fat sat_fat cholesterol sodium\n   <chr>      <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl>\n 1 Avocado    fruit           160      14.6   2.13            0      7\n 2 Chickpea   grains          180       2.9   0.309           0    243\n 3 Beef       meat            288      19.5   7.73           87    384\n 4 Catfish    fish            240      14.5   3.25           69    398\n 5 Cheese     dairy           350      26.9  16.6            83    955\n 6 Chicken    meat            237      13.4   3.76           87    404\n 7 Clam       fish            180       8     1.60           56    400\n 8 Cod        fish            211      10.8   2.22           57    401\n 9 Halibut    fish            239      17.7   3.10           59    103\n10 Lamb       meat            292      20.7   8.76           96    394\n11 Oat        grains          389       6     1.22            0      2\n12 Oyster     fish            160       7.9   1.85           57    595\n13 Penne      grains          157       0.9   0.175           0    233\n14 Pork       meat            271      17     6.17           90    384\n15 Salmon     fish            171       7.5   1.31           62    467\n16 Scallop    fish            217      10.9   2.22           54    487\n17 Sour Cream dairy           214      20.9  13.0            44     53\n18 Swordfish  fish            177       8.2   1.96           47    494\n19 Tuna       fish            153       3.9   0.811          53    366\n20 Turkey     meat            187       7     2.00           77     69\n# … with 10 more variables: carbs <dbl>, fiber <dbl>, sugar <dbl>,\n#   protein <dbl>, iron <dbl>, vitamin_a <dbl>, vitamin_c <dbl>,\n#   wiki <chr>, description <chr>, color <chr>\n\nThe output data set has only 20 rows, compared to the 62 in the original data. Other comparisons can be done with <, >= and <=. There is also a special function called between that is often useful. For example, here are the rows that have between 2 and 3 grams of total fat:\n\n\nfood %>%\n  filter(between(total_fat, 2, 3))\n\n\n# A tibble: 4 x 17\n  item  food_group calories total_fat sat_fat cholesterol sodium carbs\n  <chr> <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl> <dbl>\n1 Chic… grains          180       2.9   0.309           0    243 30.0 \n2 Quin… grains          143       2.2   0.226           0    196 26.4 \n3 Shri… fish            144       2.3   0.446         206    613  1.24\n4 Pota… vegetable       104       2     0.458           0    254 19.4 \n# … with 9 more variables: fiber <dbl>, sugar <dbl>, protein <dbl>,\n#   iron <dbl>, vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>,\n#   description <chr>, color <chr>\n\nIf you want to filter on a categorical variable, you can use the %in% operator to select specific categories. Here is the code to filter only the fish and vegetable variables:\n\n\nfood %>%\n  filter(food_group %in% c(\"fish\", \"vegetable\"))\n\n\n# A tibble: 30 x 17\n   item       food_group calories total_fat sat_fat cholesterol sodium\n   <chr>      <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl>\n 1 Asparagus  vegetable        20       0.1   0.046           0      2\n 2 String Be… vegetable        31       0.1   0.026           0      6\n 3 Bell Pepp… vegetable        26       0     0.059           0      2\n 4 Crab       fish             87       1     0.222          78    293\n 5 Broccoli   vegetable        34       0.3   0.039           0     33\n 6 Cabbage    vegetable        24       0.1   0.016           0     18\n 7 Carrot     vegetable        41       0.2   0.037           0     69\n 8 Catfish    fish            240      14.5   3.25           69    398\n 9 Cauliflow… vegetable        25       0     0.032           0     30\n10 Celery     vegetable        14       0.1   0.043           0     80\n# … with 20 more rows, and 10 more variables: carbs <dbl>,\n#   fiber <dbl>, sugar <dbl>, protein <dbl>, iron <dbl>,\n#   vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>, description <chr>,\n#   color <chr>\n\nAs with the other verbs, we can chain together multiple calls to produce more complex logic. For example, this code selects fruits that have more than 150 calories per serving:\n\n\nfood %>%\n  filter(calories > 150) %>%\n  filter(food_group %in% c(\"fruit\"))\n\n\n# A tibble: 1 x 17\n  item  food_group calories total_fat sat_fat cholesterol sodium carbs\n  <chr> <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl> <dbl>\n1 Avoc… fruit           160      14.6    2.13           0      7  8.53\n# … with 9 more variables: fiber <dbl>, sugar <dbl>, protein <dbl>,\n#   iron <dbl>, vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>,\n#   description <chr>, color <chr>\n\nWhich results in a reduced data set with only 1 row (avocados). You can also use == to test equality (food_group == \"fruit\") or != to test whether a variable is not equal to a specific value.\nIt is also possible to create a chain of calls that then get piped into a call to the ggplot function.\nFor example, here is a plot of the fruits and vegetables with the Avocado outlier removed (by limiting the maximum available total fat).\n\n\nfood %>%\n  filter(food_group %in% c(\"vegetable\", \"fruit\")) %>%\n  filter(total_fat < 10) %>%\n  ggplot() +\n    geom_point(aes(x = calories, y = total_fat, color = food_group)) +\n    geom_text_repel(aes(x = calories, y = total_fat, label = item)) +\n    scale_color_viridis_d()\n\n\n\n\nThe pattern of a starting with a data set, applying a number of transformations, and then creating a visualization of the data will become a common pattern.\nData and Layers\nNow that we know how to create a subset of our data, let’s use this new knowledge to build some interesting data visualizations. To start, create a data set that just consists of the food types that are in the meat food group:\n\n\nfood_meat <- filter(food, food_group %in% c(\"meat\"))\nfood_meat\n\n\n# A tibble: 6 x 17\n  item  food_group calories total_fat sat_fat cholesterol sodium carbs\n  <chr> <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl> <dbl>\n1 Beef  meat            288      19.5    7.73          87    384     0\n2 Chic… meat            237      13.4    3.76          87    404     0\n3 Duck  meat            132       5.9    2.32          77     74     0\n4 Lamb  meat            292      20.7    8.76          96    394     0\n5 Pork  meat            271      17      6.17          90    384     0\n6 Turk… meat            187       7      2.00          77     69     0\n# … with 9 more variables: fiber <dbl>, sugar <dbl>, protein <dbl>,\n#   iron <dbl>, vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>,\n#   description <chr>, color <chr>\n\nOne of the core ideas behind the Grammar of Graphics is that complex visualizations can be constructed by layering relatively simply elements on top of one another.\nWhat if we wanted to put together two layers where one layer uses the food data set and the other uses food_meat? To do this, we can override the default data set in a layer with the option data =. This will use a different data set within a particular layer. For example, here is how we can layer the meat data set on top of the rest of the food items.\n\n\nfood %>%\n  ggplot() +\n    geom_point(aes(x = calories, y = total_fat)) +\n    geom_point(aes(x = calories, y = total_fat), data = food_meat)\n\n\n\n\nThis plot, however, does not look any different than it would if we were just to plot all of the food together. The second layer of points just sits unassumingly on top of the rest of the data. To rectify this, we can color each layer a different color in order to distinguish them from one another. Let’s try to highlight the meat food group in a navy blue, while making the rest of the points a light grey:\n\n\nfood %>%\n  ggplot() +\n    geom_point(aes(x = calories, y = total_fat), color = \"grey85\") +\n    geom_point(aes(x = calories, y = total_fat), color = \"navy\", data = food_meat)\n\n\n\n\nWe now have a plot that shows exactly where the meats are relative to the other food items. We can further build up the plot by showing the names of just these rows of the dataset as well:\n\n\nfood %>%\n  ggplot() +\n    geom_point(aes(x = calories, y = total_fat), color = \"grey85\") +\n    geom_point(aes(x = calories, y = total_fat), color = \"navy\", data = food_meat) +\n    geom_text_repel(\n      aes(x = calories, y = total_fat, label = item),\n      color = \"navy\",\n      data = food_meat\n    )\n\n\n\n\nNotice that the code is starting to get a bit more complicated and some of the graphic layers are becoming a bit long. This is a good place to use the shorthand notation to inherit aesthetics across layers, like this:\n\n\nfood %>%\n  ggplot(aes(calories, total_fat)) +\n    geom_point(color = \"grey85\") +\n    geom_point(color = \"navy\", data = food_meat) +\n    geom_text_repel(aes(label = item), color = \"navy\", data = food_meat)\n\n\n\n\nNotice how a relatively small set of commands can be put together in different ways to build a variety of plots. Already, we are making further progress towards building informative and beautiful graphics in R!\nSelecting Columns\nIt is also possible to take a subset of the columns in a data set. To do this, we make use of the verb select. We pass it the names of the variables we want to keep in the output data set, in the (possibly new) order that we want the columns to be arranged in. Here, for example, is a new version of the foods data set containing only the food item name followed by the amount of Vitamin A and Vitamin C:\n\n\nfood %>%\n  select(item, vitamin_a, vitamin_c)\n\n\n# A tibble: 61 x 3\n   item        vitamin_a vitamin_c\n   <chr>           <dbl>     <dbl>\n 1 Apple               1         8\n 2 Asparagus          15         9\n 3 Avocado             3        17\n 4 Banana              1        15\n 5 Chickpea            0         3\n 6 String Bean        14        27\n 7 Beef                0         0\n 8 Bell Pepper        63       317\n 9 Crab                0         5\n10 Broccoli           12       149\n# … with 51 more rows\n\nWe will not need to use the select verb as often as filter because for the most part having extra variables around does not effect data visualizations or data models. However, it can be useful to displaying results and building tables.\nAs we saw above, the Vitamin A and Vitamin C columns were cut-off in the original output but are not visible in the selected data set version. Removing and reordering unneeded columns are important applied operations.\nArranging Rows\nThe verb filter determined a subset of rows to keep from the original data set. The arrange verb, in contrast, keeps all of the original data but re-orders its rows.\nSpecifically, we give it one or more variable names and it sorts the data by the first variable from smallest to largest (or alphabetically for character variables). In the case of ties, the second variable is used if given. More variables can be given to further break additional ties. Here is an example where we order the data set first by food_group and then by calories:\n\n\nfood %>%\n  arrange(food_group, calories)\n\n\n# A tibble: 61 x 17\n   item       food_group calories total_fat sat_fat cholesterol sodium\n   <chr>      <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl>\n 1 Milk       dairy            60       3.2   1.86           10     40\n 2 Yogurt     dairy            99       1.1   0.742           5     53\n 3 Sour Cream dairy           214      20.9  13.0            44     53\n 4 Cheese     dairy           350      26.9  16.6            83    955\n 5 Crab       fish             87       1     0.222          78    293\n 6 Lobster    fish             97       0.5   0.106          71    700\n 7 Haddock    fish            128       3.7   0.69           66    402\n 8 Flounder   fish            133       4.2   0.867          56    417\n 9 Shrimp     fish            144       2.3   0.446         206    613\n10 Tuna       fish            153       3.9   0.811          53    366\n# … with 51 more rows, and 10 more variables: carbs <dbl>,\n#   fiber <dbl>, sugar <dbl>, protein <dbl>, iron <dbl>,\n#   vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>, description <chr>,\n#   color <chr>\n\nIn the new data set all of the dairy products come up first followed by the fish products. Within each group, the items are sorted from the lowest to highest number of calories.\nThe ordering can be reversed (i.e., from the highest to the lowest value) be wrapping a variable in the function desc(), such as this ordering from the most saturated fat to the least:\n\n\nfood %>%\n  arrange(desc(sat_fat))\n\n\n# A tibble: 61 x 17\n   item       food_group calories total_fat sat_fat cholesterol sodium\n   <chr>      <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl>\n 1 Cheese     dairy           350      26.9   16.6           83    955\n 2 Sour Cream dairy           214      20.9   13.0           44     53\n 3 Lamb       meat            292      20.7    8.76          96    394\n 4 Beef       meat            288      19.5    7.73          87    384\n 5 Pork       meat            271      17      6.17          90    384\n 6 Chicken    meat            237      13.4    3.76          87    404\n 7 Catfish    fish            240      14.5    3.25          69    398\n 8 Halibut    fish            239      17.7    3.10          59    103\n 9 Duck       meat            132       5.9    2.32          77     74\n10 Cod        fish            211      10.8    2.22          57    401\n# … with 51 more rows, and 10 more variables: carbs <dbl>,\n#   fiber <dbl>, sugar <dbl>, protein <dbl>, iron <dbl>,\n#   vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>, description <chr>,\n#   color <chr>\n\nIn the result here, “Cheese” has been placed at the top of the data set, followed by “Sour Cream” and “Lamb”.\nGrouping and Summarizing\nA rather important verb is summarize that collapses a data frame by using summary functions. Using this verb requires that we explain exactly how the data should be summarized. We will introduce several helper functions to make this process slightly easier.\nLet’s start with an example. Here, we summarize our food data set by indicating the mean (average) value of the sugar variable across the entire data set:\n\n\nfood %>%\n  summarize(mean(sugar))\n\n\n# A tibble: 1 x 1\n  `mean(sugar)`\n          <dbl>\n1          3.42\n\nA helper function will format the column a little differently that is more usable for data analysis.\n\n\nfood %>%\n  summarize(sm_mean(sugar))\n\n\n# A tibble: 1 x 1\n  sugar_mean\n       <dbl>\n1       3.42\n\nHere we used the function sm_mean inside of the function summarize to produce the output. We specified which variable to compute the mean of by giving its name inside of the sm_mean function. The results shows us that the average amount of sugar in a 100g portion of all of the foods is 3.419g.\nIn order to compute multiple summaries at once, we can pass multiple functions together are once. For example, here we compute the mean value of three nutritional measurements:\n\n\nfood %>%\n  summarize(sm_mean(sugar), sm_mean(calories), sm_mean(vitamin_a))\n\n\n# A tibble: 1 x 3\n  sugar_mean calories_mean vitamin_a_mean\n       <dbl>         <dbl>          <dbl>\n1       3.42          114.           16.1\n\nNotice that R creates a new data set and intelligently chooses the variable names. There are a number of other useful summary functions that work similarly, such as sm_min, sm_max, sm_sum, and sm_sd (standard deviation).\nMultiple output values\nSome summary functions return multiple columns for a given variable. For example, sm_quartiles gives the five-number summary of a variable: its minimum value, the first quartile (25th percentile), the median (50th percentile), the third quartile (75th percentile), and the maximum value. As with the other summary functions, smart variable names are automatically created in R:\n\n\nfood %>%\n  summarize(sm_quartiles(calories))\n\n\n# A tibble: 1 x 5\n  calories_min calories_q1 calories_median calories_q3 calories_max\n         <dbl>       <dbl>           <dbl>       <dbl>        <dbl>\n1           12          34              87         171          389\n\nFunctions such as sm_deciles and sm_percentiles give a similar output, but with additional cutoff values. These can be useful in trying to describe the distribution of numeric variables in large data sets.\nSummarizing the data set to a single row can be useful for understanding the general trends in a data set or highlighting outliers. However, the real power of the summary function comes when we pair it with grouped manipulations. This will allow us to produce summaries within one or more grouping variables in our data set.\nWhen we use the group_by function, subsequent uses of the summarize function will produce a summary that describes the properties of variables within the variable used for grouping. The variable name(s) placed inside of the group_by function indicate which variable(s) should be used for the groups. For example, here we compute the mean number of calories of each food group:\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_mean(calories))\n\n\n# A tibble: 6 x 2\n  food_group calories_mean\n* <chr>              <dbl>\n1 dairy              181. \n2 fish               167. \n3 fruit               54.9\n4 grains             196. \n5 meat               234. \n6 vegetable           37.4\n\nNotice that the output data set contains a column for the grouping variable (food_group) and the summarized variable (calories_mean). The summarized variable name is exactly the same as the non-grouped version and the final line of code looks exactly the same as before. However, the output data set now contains six rows, one for each food group.\nAny summarization function that can be used for an ungrouped data set can also be used for a grouped data set. Also, as before, we can put multiple summary functions together to obtain different measurements of each group.\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_mean(calories), sm_mean(total_fat))\n\n\n# A tibble: 6 x 3\n  food_group calories_mean total_fat_mean\n* <chr>              <dbl>          <dbl>\n1 dairy              181.          13.0  \n2 fish               167.           7.22 \n3 fruit               54.9          1.04 \n4 grains             196.           2.56 \n5 meat               234.          13.9  \n6 vegetable           37.4          0.281\n\nNotice that the automatically produced variable names should make it clear which column corresponds to each summary function.\nThere are several additional summary functions that will be useful for analyzing data. The function sm_count takes no arguments and returns a variable called count that counts the total number of rows in the data set:\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_count())\n\n\n# A tibble: 6 x 2\n  food_group count\n* <chr>      <int>\n1 dairy          4\n2 fish          14\n3 fruit         16\n4 grains         5\n5 meat           6\n6 vegetable     16\n\nThis tells us how many times each type of food group occurs in the data set. Similarly, the function sm_na_count tells us how many values of a variable are missing:\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_count(), sm_na_count(calories))\n\n\n# A tibble: 6 x 3\n  food_group count calories_na_count\n* <chr>      <int>             <int>\n1 dairy          4                 0\n2 fish          14                 0\n3 fruit         16                 0\n4 grains         5                 0\n5 meat           6                 0\n6 vegetable     16                 0\n\nIn this case there are no missing values for the calories variable.\nThe summary function sm_paste collapses all of the values in a character variable. For example, applying this summary it to the item category after grouping by color, we can see all of the foods in the data set associated with a specific color:\n\n\nfood %>%\n  group_by(color) %>%\n  summarize(sm_paste(item))\n\n\n# A tibble: 8 x 2\n  color  item_paste                                                   \n* <chr>  <chr>                                                        \n1 brown  Chickpea; Mushroom; Oat; Quinoa; Brown Rice                  \n2 green  Asparagus; Avocado; String Bean; Bell Pepper; Broccoli; Cabb…\n3 orange Cantaloupe; Carrot; Orange; Sweet Potato; Tangerine          \n4 pink   Grapefruit; Peach; Salmon; Shrimp                            \n5 purple Grape; Plum                                                  \n6 red    Apple; Beef; Crab; Duck; Lamb; Lobster; Strawberry; Tomato; …\n7 white  Catfish; Cauliflower; Chicken; Clam; Cod; Flounder; Halibut;…\n8 yellow Banana; Cheese; Corn; Lemon; Pineapple                       \n\nFinally, note that it is possible to define your own summary functions using other R functions. To do this, we have to specify the name of the new variable explicitly. For example, here is an alternative way of computing the mean of the amount of Vitamin A within each food color:\n\n\nfood %>%\n  group_by(color) %>%\n  summarize(avg_vitamin_a = mean(vitamin_a)) %>%\n  arrange(desc(avg_vitamin_a))\n\n\n# A tibble: 8 x 2\n  color  avg_vitamin_a\n  <chr>          <dbl>\n1 orange        141.  \n2 green          11.1 \n3 pink            8.75\n4 yellow          4.4 \n5 purple          4   \n6 red             2.78\n7 white           2.63\n8 brown           0   \n\nGeometries for summaries\nWe can use summarized data sets to produce new data visualizations. For example, consider summarizing the average number of calories, average total fat, and number of items in each food groups. We can take this data and construct a scatter plot that shows the average fat and calories of each food group, along with informative labels. Here’s the code to make this visualization:\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_mean(calories), sm_mean(total_fat), sm_count()) %>%\n  ggplot(aes(calories_mean, total_fat_mean)) +\n    geom_point(aes(size = count), color = \"grey85\") +\n    geom_text_repel(aes(label = food_group))\n\n\n\n\nScatterplots are often useful for displaying summarized information. There are two additional geom types that often are useful specifically for the case of summarized data sets.\nIf we want to create a bar plot, where the heights of the bars as given by a column in the data set, we can use the geom_col layer type. For this, assign a categorical variable to the x-aesthetic and the count variable to the y-aesthetic. For example, here is a bar plot showing the number of items in each food group:\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_count()) %>%\n  ggplot() +\n    geom_col(aes(x = food_group, y = count))\n\n\n\n\nThere are two specific things to keep in mind with the geom_col layer. First, there are two color-related aes categories: the border of the bars (color) and the color used to shade the inside of the bars (fill). We can change these exactly as we did with the single color value used with scatter plots. Also, if we want to produce a bar plot with horizontal bars, this can be done by adding the special layer coord_flip() at the end of the plotting command.\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_count()) %>%\n  ggplot(aes(x = food_group, y = count)) +\n    geom_col(color = \"black\", fill = \"white\") +\n    coord_flip()\n\n\n\n\nI find that using a white fill color and a black border is often a good-looking starting point. Also, you will notice that making the bars horizontal will make it easier to read the category names when there are a larger number of categories.\nIt is possible to group a data set by multiple variables. To do this, we can provide additional variables to the group_by function separated by commas. For example, we could group the food data set into food group and color, and summarize each combination of the two:\n\n\nfood %>%\n  group_by(food_group, color) %>%\n  summarize(sm_count(), sm_mean(calories))\n\n\n# A tibble: 21 x 4\n# Groups:   food_group [6]\n   food_group color  count calories_mean\n   <chr>      <chr>  <int>         <dbl>\n 1 dairy      white      3         124. \n 2 dairy      yellow     1         350  \n 3 fish       pink       2         158. \n 4 fish       red        3         112. \n 5 fish       white      9         187. \n 6 fruit      green      4          77.2\n 7 fruit      orange     3          44.7\n 8 fruit      pink       2          35.5\n 9 fruit      purple     2          57.5\n10 fruit      red        2          42  \n# … with 11 more rows\n\nNotice that now there is one row for each combination of the two groups. However, there is no row for combinations that do not exist. So, there is no row for pink dairy products nor for white fruit. Examples of several common uses for multiple groups are given in the exercises.\nMutate verb\nThe final core dplyr verb that we will look at is used to create a new variable in our data set based on other variables that are already present. This verb is called mutate, and works by giving it the name of the variable you want to create followed by the code that describes how to construct the variable in terms of the rest of the data.\nAs an example, consider computing the number of calories in an 200g portion of each food. All of the variables in the data set are currently given as 100g portions, so to compute this we need to multiply the calories variables by 2. To do this, we use the mutate verb to name and describe a new variable calories_200g.\n\n\nfood %>%\n  mutate(calories_200g = calories * 2)\n\n\n# A tibble: 61 x 18\n   item       food_group calories total_fat sat_fat cholesterol sodium\n   <chr>      <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl>\n 1 Apple      fruit            52       0.1   0.028           0      1\n 2 Asparagus  vegetable        20       0.1   0.046           0      2\n 3 Avocado    fruit           160      14.6   2.13            0      7\n 4 Banana     fruit            89       0.3   0.112           0      1\n 5 Chickpea   grains          180       2.9   0.309           0    243\n 6 String Be… vegetable        31       0.1   0.026           0      6\n 7 Beef       meat            288      19.5   7.73           87    384\n 8 Bell Pepp… vegetable        26       0     0.059           0      2\n 9 Crab       fish             87       1     0.222          78    293\n10 Broccoli   vegetable        34       0.3   0.039           0     33\n# … with 51 more rows, and 11 more variables: carbs <dbl>,\n#   fiber <dbl>, sugar <dbl>, protein <dbl>, iron <dbl>,\n#   vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>, description <chr>,\n#   color <chr>, calories_200g <dbl>\n\nNotice that there is a new variable named calories_200g that has been added as the last column in the data set. Because it is added at the end of the data set, it gets hidden in the output shown above. Making use of select allows us to see the new values:\n\n\nfood %>%\n  mutate(calories_200g = calories * 2) %>%\n  select(item, food_group, calories, calories_200g)\n\n\n# A tibble: 61 x 4\n   item        food_group calories calories_200g\n   <chr>       <chr>         <dbl>         <dbl>\n 1 Apple       fruit            52           104\n 2 Asparagus   vegetable        20            40\n 3 Avocado     fruit           160           320\n 4 Banana      fruit            89           178\n 5 Chickpea    grains          180           360\n 6 String Bean vegetable        31            62\n 7 Beef        meat            288           576\n 8 Bell Pepper vegetable        26            52\n 9 Crab        fish             87           174\n10 Broccoli    vegetable        34            68\n# … with 51 more rows\n\nAnd now we can see that the new column has been created by doubling the number given the calories column.\nNote that mutate can also be used to modify any existing column in the data set by using the name of an extant variable. In this case the position of the variable within the tables does not change.\nThe mutate verb itself has a relatively straightforward syntax. The main challenge is knowing how to apply and chain together the various transformations that are useful within an analysis. In the next few sections, we highlight several common types of operations that we will be useful in subsequent applications.\nConditional values\nMany of the uses for the mutate verb involve assigning one value when a set of conditions is true and another if the conditions are false. For example, consider creating a new variable called sugar_level based on the relative amount of sugar in each food item. We might classify a food has having a “high” sugar level if has more than 10g of sugar per 100g serving, and a “normal” amount otherwise. In order to create this variable, we need the function if_else.\nThe if_else function has three parts: a TRUE/FALSE statement, the value to use when the statement is true, and the value to use when it is false. Here is an example to create our new variable:\n\n\nfood %>%\n  mutate(sugar_level = if_else(sugar > 10, \"high\", \"normal\")) %>%\n  select(item, food_group, sugar, sugar_level)\n\n\n# A tibble: 61 x 4\n   item        food_group sugar sugar_level\n   <chr>       <chr>      <dbl> <chr>      \n 1 Apple       fruit      10.4  high       \n 2 Asparagus   vegetable   1.88 normal     \n 3 Avocado     fruit       0.66 normal     \n 4 Banana      fruit      12.2  high       \n 5 Chickpea    grains      5.29 normal     \n 6 String Bean vegetable   1.4  normal     \n 7 Beef        meat        0    normal     \n 8 Bell Pepper vegetable   4.2  normal     \n 9 Crab        fish        0    normal     \n10 Broccoli    vegetable   1.7  normal     \n# … with 51 more rows\n\nLooking at the first rows of data, we see that apples and bananas are classified as high sugar foods, whereas the other sugar levels are given the sugar level category of “normal”.\nThe if_else function can be used to produce any number of categories by using it multiple times. Let’s modify our sugar level variable to now have three categories: “high” (over 10g), “low” (less than 1g), and “normal” (between 1g and 10g). There are several different ways to get to the same result, but I find the easiest is to start by assigning a default value and then changing the value of the new variable in sequence. For example, here some code that produces our new categories:\n\n\nfood %>%\n  mutate(sugar_level = \"default\") %>%\n  mutate(sugar_level = if_else(sugar < 1, \"low\", sugar_level)) %>%\n  mutate(sugar_level = if_else(sugar > 10, \"high\", sugar_level)) %>%\n  mutate(sugar_level = if_else(between(sugar, 1, 10), \"normal\", sugar_level)) %>%\n  select(item, food_group, sugar, sugar_level)\n\n\n# A tibble: 61 x 4\n   item        food_group sugar sugar_level\n   <chr>       <chr>      <dbl> <chr>      \n 1 Apple       fruit      10.4  high       \n 2 Asparagus   vegetable   1.88 normal     \n 3 Avocado     fruit       0.66 low        \n 4 Banana      fruit      12.2  high       \n 5 Chickpea    grains      5.29 normal     \n 6 String Bean vegetable   1.4  normal     \n 7 Beef        meat        0    low        \n 8 Bell Pepper vegetable   4.2  normal     \n 9 Crab        fish        0    low        \n10 Broccoli    vegetable   1.7  normal     \n# … with 51 more rows\n\nIn each if_else step we are telling the mutate function that if the condition is false set sugar_level equal to itself. In other words, if the condition does not hold, do not change the value of the variable.\nIn may wonder why we created a “default” value for the variable sugar_level. It would have been one less line of code to set the default value to “normal” and remove the final mutate function. The reason for the approach above is three-fold. First, it’s easier to understand what the code is doing in it’s current format because each condition (“high”, “normal”, and “low”) is explicitly coded. Secondly, it creates a nice check on our code and data. If we find a row of the output that still has the value “default” we will know that there is a problem somewhere. Finally, the code above will more safely handle the issues with missing values, and issue that we will return to shortly.\nFactors\nR has a special data type called a “factor” (abbreviated “fct”) that is specifically designed to handle categorical variables. It is typically not a good idea to store data as a factor because the resulting variables have some odd, error-producing, behaviors. However, it can be useful to create a factor as part of a mutate function just prior to creating a data visualizations.\nFor us, biggest difference between factors and character vectors is that a factor vector has a default ordered of its unique values, called the factor’s “levels”. Creating and understanding factors is useful because it allows us to change the ordering of categories within visualizations and models (which by default is done alphabetically).\nOne of the easiest ways to produce a factor variable with a given order is through the function fct_inorder. It will order the categories in the same order that they (first) appear in the data set. Combining this with the arrange function provides a lot of control over how categories become ordered. For example, the following code produces a bar plot of the food groups in our data set arranged from the largest category to the smallest category:\n\n\nfood %>%\n  group_by(food_group) %>%\n  summarize(sm_count()) %>%\n  arrange(desc(count)) %>%\n  mutate(food_group = fct_inorder(food_group)) %>%\n  ggplot() +\n    geom_col(aes(food_group, count))\n\n\n\n\nOther useful functions for manipulating categories include fct_relevel for manually putting one category first and fct_lump_n for combining together the smallest categories into a collective “Other” category.\nMutate summaries\nAll of summary functions that were introduced in the previous notebook can also be applied within the mutate version. Instead of reducing the data to a single summary row, summarizing within the mutate verb duplicates the summary statistic in each row of the data set. Here is an example of including the average number of calories across all rows of the data set:\n\n\nfood %>%\n  mutate(sm_mean(calories))\n\n\n# A tibble: 61 x 18\n   item       food_group calories total_fat sat_fat cholesterol sodium\n   <chr>      <chr>         <dbl>     <dbl>   <dbl>       <dbl>  <dbl>\n 1 Apple      fruit            52       0.1   0.028           0      1\n 2 Asparagus  vegetable        20       0.1   0.046           0      2\n 3 Avocado    fruit           160      14.6   2.13            0      7\n 4 Banana     fruit            89       0.3   0.112           0      1\n 5 Chickpea   grains          180       2.9   0.309           0    243\n 6 String Be… vegetable        31       0.1   0.026           0      6\n 7 Beef       meat            288      19.5   7.73           87    384\n 8 Bell Pepp… vegetable        26       0     0.059           0      2\n 9 Crab       fish             87       1     0.222          78    293\n10 Broccoli   vegetable        34       0.3   0.039           0     33\n# … with 51 more rows, and 11 more variables: carbs <dbl>,\n#   fiber <dbl>, sugar <dbl>, protein <dbl>, iron <dbl>,\n#   vitamin_a <dbl>, vitamin_c <dbl>, wiki <chr>, description <chr>,\n#   color <chr>, calories_mean <dbl>\n\nAs with any call to mutate, all of the original variables are kept in the output and the new variable is added at the end. Using select we can verify that the average calories has in fact been added to each row of the table.\n\n\nfood %>%\n  mutate(sm_mean(calories)) %>%\n  select(item, food_group, calories, calories_mean)\n\n\n# A tibble: 61 x 4\n   item        food_group calories calories_mean\n   <chr>       <chr>         <dbl>         <dbl>\n 1 Apple       fruit            52          114.\n 2 Asparagus   vegetable        20          114.\n 3 Avocado     fruit           160          114.\n 4 Banana      fruit            89          114.\n 5 Chickpea    grains          180          114.\n 6 String Bean vegetable        31          114.\n 7 Beef        meat            288          114.\n 8 Bell Pepper vegetable        26          114.\n 9 Crab        fish             87          114.\n10 Broccoli    vegetable        34          114.\n# … with 51 more rows\n\nThe power of mutate summaries becomes particularly clear when grouping the data. If we group the data set by one or more variables and apply a summary function within a mutation, the repeated summaries will be done within each group. Here is an example of adding the average calories of each food group to the data set:\n\n\nfood %>%\n  group_by(food_group) %>%\n  mutate(sm_mean(calories)) %>%\n  select(item, food_group, calories, calories_mean)\n\n\n# A tibble: 61 x 4\n# Groups:   food_group [6]\n   item        food_group calories calories_mean\n   <chr>       <chr>         <dbl>         <dbl>\n 1 Apple       fruit            52          54.9\n 2 Asparagus   vegetable        20          37.4\n 3 Avocado     fruit           160          54.9\n 4 Banana      fruit            89          54.9\n 5 Chickpea    grains          180         196. \n 6 String Bean vegetable        31          37.4\n 7 Beef        meat            288         234. \n 8 Bell Pepper vegetable        26          37.4\n 9 Crab        fish             87         167. \n10 Broccoli    vegetable        34          37.4\n# … with 51 more rows\n\nFollowing this with a filter, for example, would allow us to select all of the foods that have a less than average number of calories within their food group. We will see many examples of grouped mutate summaries throughout our applications.\nLabels and themes\nWe have seen a number of ways to create and modify data visualizations. One thing that we did not cover was how to label our axes.\nWhile many data visualization guides like to stress the importance of labelling axes, while in the exploratory phase of analysis it is often best to simply use the default labels provided by R. These are useful for a number of reasons. First, they require minimal effort and make it easy to tweak axes, variables, and other settings without spending time tweaking with the labels. Secondly, the default labels use the variable names in our dataset. When writing code this is exactly what we need to know about a variable to use it in additional plots, models, and data manipulation tasks.\nOf course, once we want to present our results to others, it is essential to provide more detailed descriptions of the axes and legends in our plot. Fortunately, this is relatively easy using the grammar of graphics.\nIn order to change the labels in a plot, we can use the labs function as an extra part of our plot. Inside the function, we assign labels to the names of aes values that you want to describe. Leaving a value unspecified will keep the default value in place. Labels for the x-axis and y-axis will be go on the sides of the plot. Labels for other aesthetics such as size and color will be placed in the legend. Here is an example of a scatterplot with labels for the three aesthetics:\n\n\nfood %>%\n  ggplot() +\n    geom_point(aes(x = calories, y = sat_fat, color = food_group)) +\n    labs(\n      x = \"Calories per 100g\",\n      y = \"Saturated Fat (grams per 100g)\",\n      color = \"Food Group\"\n    )\n\n\n\n\nNotice that the descriptions inside of the labs function is fairly long. The code here breaks it up by putting each argument on its own line (indented a further two spaces). This is good practice when using functions with a lot of arguments.\nWe can also had a title (and optional subtitle and caption) to the plot by adding these as named arguments to the labs function.\n\n\nfood %>%\n  ggplot() +\n    geom_point(aes(x = calories, y = sat_fat, color = food_group)) +\n    labs(\n      title = \"Main title\",\n      subtitle = \"A little more detail\",\n      caption = \"Perhaps the source of the data?\"\n    )\n\n\n\n\nAnother way to prepare our graphics for publication is to modify the theme of a plot. One useful option is to set the default plot to theme_minimal. As the name implies, it removes most of the clutter of other choices while keeping grid lines and other visual cues to help interpret a dataset.\nWhen presenting information for external publication, I prefer to use the theme called theme_sm based on the work of Edward Tufte. To set the theme, just call the following line of code sometime before making your plot:\n\n\ntheme_set(theme_sm())\n\n\n\nNow, when we construct a plot it will use the newly assigned theme:\n\n\nfood %>%\n  ggplot() +\n    geom_point(aes(x = sugar, y = total_fat))\n\n\n\n\nThe Tufte theme is designed to use as little “ink” as possible, thus focusing the reader on the data. It can be a bit too minimal when first exploring the dataset, but is a great tool for presenting your results.\n\n\n\n",
    "preview": "https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/rmarkdown.png",
    "last_modified": "2021-03-03T03:05:57+00:00",
    "input_file": {}
  },
  {
    "path": "posts/zhongtian-yihao-introduction/",
    "title": "Pricing Strategies of Retailers",
    "description": "Final Project Proposal for ECON-712-008",
    "author": [
      {
        "name": "Zhongtian Chen",
        "url": {}
      },
      {
        "name": "Yihao Yuan",
        "url": "https://github.com/yihao-yuan"
      }
    ],
    "date": "2021-02-28",
    "categories": [
      "Zhongtian and Yihao's project"
    ],
    "contents": "\nResearch Question\nPrice dispersion has long been central to a range of economic questions. For example, DellaVigna and Gentzkow (2019) investigated how uniform pricing within store chains affect store profits and social inequality. However, most papers only focused on price dispersion over stores (e.g., DellaVigna and Gentzkow (2019)) or products (e.g., Hitsch, Hortacsu, and Lin (n.d.)). Though more than 50% of the variations in transaction prices cannot be explained by differences in stores or products (Kaplan and Menzio (2015)), few have looked into price dispersion over time. Important exceptions to the lack of studies on price dispersion over time are literatures on intertemporal price discrimination (e.g., Hendel and Nevo (2013)), where stores use cyclical price changes to discriminate between searchers and non-searchers.\nIn this project, we would like to add to the literatures above by providing patterns of price dispersions over time. Moreover, we want to explain the reasons for a striking pattern presented in our data, that in nearly half of the promotions, the stores discounted prices below their costs. We plan to investigate existing theoretical explanations, including intertemporal price discrimination, loss leader strategy and inventory management, to explain price dispersion over time, especially the negative margins. In the end, we want to optimize the stores’ pricing strategies, and predict profit gains from the new strategies.\nData\nData Source\nA large shopping complex in Middle East operated in 15 countries.\nCarrefour data: 66 stores, data from January 2017 to March 2019.\nAssortment data: product-package-date level; information includes regular price, promotion price, promotion time, quantities sold, quantities in stock, and wholesale price (cost); product-package information only available for some products (e.g., beverages). Data size: 3 billion observations, more than 800 GB.\nConsumer data: 4.44 million consumers were in their loyalty rewards program; information includes basic demographics (gender and age).\nTransaction data: about 29 million transactions made by loyalty program consumers per month across all stores; information includes timestamp, item purchased, price for each item, total spendings. Data size: unknown observations, about 170 GB.\n\nSupplementary data\nCredit card data: transactions used by credit card issued by the owner of the shopping complex.\nWi-Fi data: search history of consumers when shopping within the complex/Carrefour.\n\nDescriptive Analyses\nWe start with assortment data on six categories of products: coconut water, corn, cups and straws, deo men roll-on and stick, greek yogurt, and soda and tonic water. We focus on these six categories because the detailed product information of other products are encrypted by the stores. This reduces the number of product-package-days to 19,750,749. We further exclude observations where prices or costs are zero. It further reduces the number of observations to 18,736,746 (94.87%).\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-42.00000   0.04762   0.09459   0.12104   0.18974   0.99922 \n# A tibble: 6 x 6\n  subfamily_name            mean     Q1 median     Q3       n\n  <chr>                    <dbl>  <dbl>  <dbl>  <dbl>   <int>\n1 Coconut Water           0.0399 0      0.0481 0.0941 2904464\n2 Corn                    0.0820 0.0157 0.07   0.121  2753403\n3 Cups & Straw            0.289  0.237  0.286  0.343  2349432\n4 Deo men roll-on & stick 0.0990 0.0528 0.0930 0.143  3704698\n5 Greek Yogurt            0.129  0.0645 0.121  0.179  4488552\n6 Soda & Tonic Water      0.119  0      0.0588 0.151  2535997\n# A tibble: 6 x 5\n  subfamily_name            mean      Q1 median     Q3\n  <chr>                    <dbl>   <dbl>  <dbl>  <dbl>\n1 Coconut Water           0.0215  0.005  0.0609 0.115 \n2 Corn                    0.0523 -0.0156 0.0495 0.104 \n3 Cups & Straw            0.222   0.179  0.218  0.28  \n4 Deo men roll-on & stick 0.0842  0.0542 0.0812 0.128 \n5 Greek Yogurt            0.0961  0.0574 0.103  0.153 \n6 Soda & Tonic Water      0.0803  0      0.0478 0.0909\n\nThe two tables above show the margins of product-packages by categories. The first table presents the summary at product-package-day-level, while second table weights by the number of quantities sold. It turns out that the margins of product-packages with higher sales tend to be higher, as the means and quantiles in the second table are generally higher than in the first table.\nA discount is defined as the price lower than the regular price for a product-package. Both daily sales price and regular price are provided in the assortment data. 1.66% of the product-packages-days were in discount, and 7.14% of the product-packages were sold at discounted prices, showing evidence that consumers are price sensitive.\nWe compute margins of each product-package-day as \\(Margin = \\frac{P-C}{P}\\). It turns out that 4.69% (10.56%) of them are sold with negative margins (the number in the parentheses shows the result weighted by sales quantity). Strikingly, 49.48% (63.33%) of the discounted product-packages were sold with negative margins. The histograms of margins for all and discounted product-packages are presented below.\n\n\n\nResearch Plan\nRead full data. We have not been able to read the full assortment, which is more than 700 GB in size. We are actively working with HPCC to resolve the problem.\nConduct more detailed descriptive analyses, and nail down the research question.\nExplore the possibilities of some other explanations to negative margins, including but not limited to:\nLoss leader strategy. Stores may want to offer deep promotions on some products to attract consumers to the store to shop for other products, and maximize the overall profit. We may need to investigate transaction data to confirm whether it is true.\nInventory management. Some products are perishable, and stores may want to sell them before they perish. Inventory information is available, but more work is needed to investigate whether inventory management is a reason for deep discounts.\n\n\n\nDellaVigna, Stefano, and Matthew Gentzkow. 2019. “Uniform Pricing in Us Retail Chains.” The Quarterly Journal of Economics 134 (4). Oxford University Press: 2011–84.\n\n\nHendel, Igal, and Aviv Nevo. 2013. “Intertemporal Price Discrimination in Storable Goods Markets.” American Economic Review 103 (7): 2722–51.\n\n\nHitsch, Günter J, Ali Hortacsu, and Xiliang Lin. n.d. “Prices and Promotions in Us Retail Markets: Evidence from Big Data.” Quantitative Marketing and Economics.\n\n\nKaplan, Greg, and Guido Menzio. 2015. “The Morphology of Price Dispersion.” International Economic Review 56 (4). Wiley Online Library: 1165–1206.\n\n\n\n\n",
    "preview": "posts/zhongtian-yihao-introduction/distill-preview.png",
    "last_modified": "2021-03-16T14:23:46+00:00",
    "input_file": {}
  },
  {
    "path": "posts/jonathan-sheng-algorithmic-demand-estimation-introduction/",
    "title": "An Algorithmic Perspective on BLP-Style Demand Estimation",
    "description": "Project Introduction",
    "author": [
      {
        "name": "Jonathan Arnold",
        "url": {}
      },
      {
        "name": "Sheng Chao Ho",
        "url": {}
      }
    ],
    "date": "2021-02-26",
    "categories": [
      "Jonathan and Sheng"
    ],
    "contents": "\n\n\n\nIntroduction\n\n\n\nDemand estimation is a central problem in applied economics, and one to which considerable econometric effort has been dedicated. Indeed, it is one of the most common examples of simultaneity bias, leading to the widespread use of instrumental variables techniques to overcome this issue. Discrete choice techniques, on the other hand, attempt to avoid this issue entirely by looking at the behavior of individual consumers, who face an essentially flat supply curve assuming no buyer-side market power.\nBerry, Levinsohn, and Pakes (1995) introduced a new method to estimate demand in differentiated products markets using this type of discrete choice method, but on a relatively aggregated dataset. It was remarkable for a number of reasons, not least for its use of discrete choice techniques on a dataset which contained no data at the individual consumer level. Their structural approach became quite popular for its usefulness in a wide variety of IO settings, but it came at the cost of considerable computational effort and relatively restrictive functional form assumptions.\nOn the other hand, relatively little attention has been dedicated to solving the demand estimation problem from an algorithmic modeling standpoint. But how could machine learning and algorithmic modeling help with a problem so centered around inference, resolving endogeneity problems, and estimating structural parameters? At first glance, it isn’t quite clear. However, we believe algorithmic modeling does in fact have a place in this data-model-dominated setting, mainly because of counterfactual prediction.\nThe implicit goal of estimating the price coefficient in a demand equation is to be able to predict what demand would be if the price were changed in some counterfactual. But this idea isn’t so far removed from the idea of out-of-sample performance for a predictive algorithm. Perhaps training algorithmic models with good out-of-sample performance like random forests or boosting could provide strong results for this counterfactual prediction problem. While they might not be able to directly estimate structural parameters, we might be able to compare their predictions on a test set or some other counterfactual data to the predictions of more traditional demand estimation models. Such comparisons could allow us to make inferences about the behavior of these algorithmic models, and perhaps even estimate implied elasticities.\nResearch Questions\nIn this project, we will attempt to answer the following questions:\nHow does the out-of-sample performance of algorithmic models compare with their structural counterparts in the demand estimation problem?\nHow can we compare the economic significance of the outputs from the algorithic models with those of structural models?\nData\nWe will be working with the dataset of Berry, Levinsohn, and Pakes (1995). It is a panel data set of car models containing their yearly sales quantities and product characteristics such as prices, miles per gallon etc. In total, there are 2000+ observations with 10 variables, observed over 20 years. Out of the 10, 3 variables are binary, with the remaining 7 being continuous. The dataset also contains identifiers for the year of the observation, the producing firm, and the model name and year. Prices are in thousands of 1983 dollars, so no inflation adjustment is required.\nBelow we provide a summary table of mean values for each variable during the first 10 years of the panel.\n\n\n\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"market\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Number of Models\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Horsepower/Weight\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Space\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AC Dummy\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Miles per Dollar\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Miles per Gallon\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Price, Thousands of 1983 Dollars\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Quantity\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Produced in Japan\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Produced in Europe\"],\"name\":[11],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"92\",\"3\":\"0.5100598\",\"4\":\"1.442405\",\"5\":\"0.00000000\",\"6\":\"1.913676\",\"7\":\"1.719946\",\"8\":\"8.856334\",\"9\":\"86.89166\",\"10\":\"0.09782609\",\"11\":\"0.2173913\",\"_rn_\":\"1\"},{\"1\":\"2\",\"2\":\"89\",\"3\":\"0.4070556\",\"4\":\"1.457953\",\"5\":\"0.04494382\",\"6\":\"1.891037\",\"7\":\"1.633169\",\"8\":\"9.042820\",\"9\":\"98.62260\",\"10\":\"0.07865169\",\"11\":\"0.2247191\",\"_rn_\":\"2\"},{\"1\":\"3\",\"2\":\"86\",\"3\":\"0.3850296\",\"4\":\"1.466291\",\"5\":\"0.06976744\",\"6\":\"1.859603\",\"7\":\"1.625058\",\"8\":\"9.045202\",\"9\":\"92.78543\",\"10\":\"0.10465116\",\"11\":\"0.1860465\",\"_rn_\":\"3\"},{\"1\":\"4\",\"2\":\"72\",\"3\":\"0.3680138\",\"4\":\"1.426287\",\"5\":\"0.12500000\",\"6\":\"1.513558\",\"7\":\"1.633292\",\"8\":\"9.254733\",\"9\":\"105.11904\",\"10\":\"0.11111111\",\"11\":\"0.2361111\",\"_rn_\":\"4\"},{\"1\":\"5\",\"2\":\"93\",\"3\":\"0.3544013\",\"4\":\"1.416277\",\"5\":\"0.10752688\",\"6\":\"1.543673\",\"7\":\"1.626882\",\"8\":\"9.641844\",\"9\":\"84.77453\",\"10\":\"0.10752688\",\"11\":\"0.2473118\",\"_rn_\":\"5\"},{\"1\":\"6\",\"2\":\"99\",\"3\":\"0.3544917\",\"4\":\"1.379183\",\"5\":\"0.10101010\",\"6\":\"1.789510\",\"7\":\"1.855556\",\"8\":\"9.490068\",\"9\":\"93.38158\",\"10\":\"0.12121212\",\"11\":\"0.2626263\",\"_rn_\":\"6\"},{\"1\":\"7\",\"2\":\"95\",\"3\":\"0.3558219\",\"4\":\"1.357584\",\"5\":\"0.08421053\",\"6\":\"1.864081\",\"7\":\"1.977895\",\"8\":\"9.864287\",\"9\":\"97.72722\",\"10\":\"0.10526316\",\"11\":\"0.2842105\",\"_rn_\":\"7\"},{\"1\":\"8\",\"2\":\"95\",\"3\":\"0.3631762\",\"4\":\"1.344196\",\"5\":\"0.09473684\",\"6\":\"1.939098\",\"7\":\"1.992632\",\"8\":\"10.602147\",\"9\":\"99.44447\",\"10\":\"0.12631579\",\"11\":\"0.2315789\",\"_rn_\":\"8\"},{\"1\":\"9\",\"2\":\"102\",\"3\":\"0.3657630\",\"4\":\"1.306745\",\"5\":\"0.08823529\",\"6\":\"1.616644\",\"7\":\"2.010784\",\"8\":\"10.451291\",\"9\":\"82.74237\",\"10\":\"0.14705882\",\"11\":\"0.2549020\",\"_rn_\":\"9\"},{\"1\":\"10\",\"2\":\"103\",\"3\":\"0.3631302\",\"4\":\"1.296387\",\"5\":\"0.17475728\",\"6\":\"1.434217\",\"7\":\"2.166990\",\"8\":\"10.726895\",\"9\":\"71.56709\",\"10\":\"0.16504854\",\"11\":\"0.2427184\",\"_rn_\":\"10\"},{\"1\":\"11\",\"2\":\"116\",\"3\":\"0.3623611\",\"4\":\"1.301022\",\"5\":\"0.24137931\",\"6\":\"1.484216\",\"7\":\"2.250000\",\"8\":\"13.035213\",\"9\":\"62.03032\",\"10\":\"0.16379310\",\"11\":\"0.3275862\",\"_rn_\":\"11\"},{\"1\":\"12\",\"2\":\"110\",\"3\":\"0.3583319\",\"4\":\"1.282553\",\"5\":\"0.23636364\",\"6\":\"1.770114\",\"7\":\"2.377273\",\"8\":\"11.591314\",\"9\":\"61.89282\",\"10\":\"0.17272727\",\"11\":\"0.2363636\",\"_rn_\":\"12\"},{\"1\":\"13\",\"2\":\"115\",\"3\":\"0.3577957\",\"4\":\"1.272503\",\"5\":\"0.20000000\",\"6\":\"2.018311\",\"7\":\"2.514783\",\"8\":\"11.140824\",\"9\":\"67.87751\",\"10\":\"0.17391304\",\"11\":\"0.2173913\",\"_rn_\":\"13\"},{\"1\":\"14\",\"2\":\"113\",\"3\":\"0.3867672\",\"4\":\"1.264015\",\"5\":\"0.28318584\",\"6\":\"2.070323\",\"7\":\"2.415044\",\"8\":\"11.647704\",\"9\":\"85.93321\",\"10\":\"0.19469027\",\"11\":\"0.2123894\",\"_rn_\":\"14\"},{\"1\":\"15\",\"2\":\"136\",\"3\":\"0.3895406\",\"4\":\"1.246166\",\"5\":\"0.33088235\",\"6\":\"2.004007\",\"7\":\"2.238676\",\"8\":\"12.476369\",\"9\":\"78.14318\",\"10\":\"0.21323529\",\"11\":\"0.2426471\",\"_rn_\":\"15\"},{\"1\":\"16\",\"2\":\"130\",\"3\":\"0.3981565\",\"4\":\"1.232586\",\"5\":\"0.32307692\",\"6\":\"2.784882\",\"7\":\"2.355462\",\"8\":\"11.782615\",\"9\":\"83.75581\",\"10\":\"0.24615385\",\"11\":\"0.1923077\",\"_rn_\":\"16\"},{\"1\":\"17\",\"2\":\"143\",\"3\":\"0.4138790\",\"4\":\"1.231498\",\"5\":\"0.39160839\",\"6\":\"2.714219\",\"7\":\"2.265035\",\"8\":\"13.436337\",\"9\":\"67.66724\",\"10\":\"0.24475524\",\"11\":\"0.2237762\",\"_rn_\":\"17\"},{\"1\":\"18\",\"2\":\"150\",\"3\":\"0.4318013\",\"4\":\"1.245698\",\"5\":\"0.44666667\",\"6\":\"2.736156\",\"7\":\"2.188000\",\"8\":\"14.885709\",\"9\":\"67.07782\",\"10\":\"0.22666667\",\"11\":\"0.2400000\",\"_rn_\":\"18\"},{\"1\":\"19\",\"2\":\"147\",\"3\":\"0.4532713\",\"4\":\"1.247325\",\"5\":\"0.50340136\",\"6\":\"2.646279\",\"7\":\"2.178912\",\"8\":\"16.690493\",\"9\":\"62.91361\",\"10\":\"0.22448980\",\"11\":\"0.2721088\",\"_rn_\":\"19\"},{\"1\":\"20\",\"2\":\"131\",\"3\":\"0.4494098\",\"4\":\"1.255190\",\"5\":\"0.45801527\",\"6\":\"2.741784\",\"7\":\"2.181679\",\"8\":\"14.038384\",\"9\":\"66.37731\",\"10\":\"0.22900763\",\"11\":\"0.2061069\",\"_rn_\":\"20\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nOverall, we see an upward trend in the real list price of automobiles during the sample period. Space shows a decreasing trend, reflecting observable market trends towards smaller vehicles post-1970.\nHere is a summary table showing the ranges of observations for variables over all years:\n\n\n\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Horsepower/Weight\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Space\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AC Dummy\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Miles per Dollar\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Price\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Miles per Gallon\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Quantity\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Market Share\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Produced in Japan\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Produced in Europe\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.1704550\",\"2\":\"0.756000\",\"3\":\"0.0000000\",\"4\":\"0.846070\",\"5\":\"3.393267\",\"6\":\"0.913000\",\"7\":\"0.04900\",\"8\":\"0.0000010000\",\"9\":\"0.0000000\",\"10\":\"0.0000000\",\"_rn_\":\"Min.\"},{\"1\":\"0.3365850\",\"2\":\"1.131279\",\"3\":\"0.0000000\",\"4\":\"1.557015\",\"5\":\"6.713755\",\"6\":\"1.700000\",\"7\":\"15.60300\",\"8\":\"0.0001860000\",\"9\":\"0.0000000\",\"10\":\"0.0000000\",\"_rn_\":\"1st Qu.\"},{\"1\":\"0.3750490\",\"2\":\"1.269827\",\"3\":\"0.0000000\",\"4\":\"2.010417\",\"5\":\"8.728650\",\"6\":\"2.000000\",\"7\":\"47.35000\",\"8\":\"0.0005700000\",\"9\":\"0.0000000\",\"10\":\"0.0000000\",\"_rn_\":\"Median\"},{\"1\":\"0.3943753\",\"2\":\"1.310159\",\"3\":\"0.2417682\",\"4\":\"2.084870\",\"5\":\"11.761420\",\"6\":\"2.099643\",\"7\":\"78.80399\",\"8\":\"0.0009732463\",\"9\":\"0.1723049\",\"10\":\"0.2381597\",\"_rn_\":\"Mean\"},{\"1\":\"0.4275090\",\"2\":\"1.452700\",\"3\":\"0.0000000\",\"4\":\"2.482848\",\"5\":\"13.074074\",\"6\":\"2.500000\",\"7\":\"109.00200\",\"8\":\"0.0012860000\",\"9\":\"0.0000000\",\"10\":\"0.0000000\",\"_rn_\":\"3rd Qu.\"},{\"1\":\"0.9475810\",\"2\":\"1.888000\",\"3\":\"1.0000000\",\"4\":\"6.436827\",\"5\":\"68.596774\",\"6\":\"5.300000\",\"7\":\"646.52600\",\"8\":\"0.0094730000\",\"9\":\"1.0000000\",\"10\":\"1.0000000\",\"_rn_\":\"Max.\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nCharacteristics and prices generally show significant variability throughout the dataset. This assists with the identification of the BLP model, and we would hope it will also increase predictive accuracy for the algorithmic models we will use.\nIn addition to this dataset, we also have access to demographic data, which contains the mean of log income for each year, and the standard deviation of log income across all years.\nProposed Methods\nTo answer question 1, we will take a straightforward approach: compare the out-of-sample predictive performance of several algorithmic models and various versions of the BLP model. Specifically, we will be predicting market shares from price and product characteristics. We will estimate the models on a random portion of the dataset, and then evaluate them on the remaining test set.\nMethods we may use on the algorithmic side include:\nCART\nBagging\nBoosting\nRandom Forest\nMethods we may use on the structural side include:\nOLS Logit\nIV Logit\nRandom Coefficients Logit\nQuestion 2 may require a more creative approach. Some algorithmic models, like CART, are fairly interpretable, and we may be able to compare their results with those of structural models. Others, like random forest, may not be so interpretable. A first approach will be to use variable importance plots to get an idea of what’s happening inside the algorithmic black box, and compare these results to those of the structural models.\nAnother, more ambitious, approach is to look for specific automobile models which appear multiple times in the dataset with different prices. Train the models on some observations and then predict the market shares after a price change. We would then scale these predicted demand changes appropriately to compare with the estimated BLP own-price elasticities. We’re not sure yet whether such a comparison is possible or valid, but it is something we would like to examine.\n\n\n\nBerry, Steven, James Levinsohn, and Ariel Pakes. 1995. “Automobile Prices in Market Equilibrium.” Econometrica 63 (4): 841–90.\n\n\n\n\n",
    "preview": "posts/jonathan-sheng-algorithmic-demand-estimation-introduction/demand_example.png",
    "last_modified": "2021-03-09T03:27:18+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-25-predicting-take-up-rate/",
    "title": "Predicting Take-Up Rate",
    "description": "Understanding the predictors of social programs application",
    "author": [
      {
        "name": "Ornella Darova",
        "url": {}
      },
      {
        "name": "Ozgur Seker",
        "url": {}
      }
    ],
    "date": "2021-02-25",
    "categories": [
      "Ornella and Ozgur"
    ],
    "contents": "\nOne of the central issues of policy design is targeting. Targeting may not be completely under the control of the policy maker, as the population actually participating to a public policy may self-select into it: in that case, we would have an  endogenous take-up rate. Understanding what are the predicting factors of take-up rate, given eligibility, is of fundamental importance to improve not only policy design but also policy evaluations, as the take-up rate and the characteristics of the self-selected population can heavily affect the impact and the success of policies themselves.\nWe employ Current Population Survey (CPS) microdata harmonized by IPUMS that we are going to integrate with other datasets with pertinent variables. The CPS data sample we have has more than 3.5 million observations and 57 variables. You can see and download a sample data from this link. We are going to employ Machine Learning techniques to forecast our outcome of interest and compare different policies take-up, such as public housing, government subsidies for the rent payment, energy subsidies, food stamp recipiency, and government school lunch subsidies, reflecting on the differences and similarities between these policies and the most important predictors.\nPossible outcomes to explore:\n\nVariable name\n\n\nExplanation\n\n\nOutcomes\n\n\nEligibility\n\n\nPubhous\n\n\nLiving in public housing\n\n\n1-No; 2-Yes\n\n\nIncome standards. A public housing unit can be occupied by a family of 2+ or 1 handicapped, elderly, or displaced by urban renewal or natural disaster\n\nRentsub\n\n\nPaying lower rent due to government subsidy\n\n\n1-No; 2-Yes\n\n\nCombined income 80% of the local area median income. Family of 2+ or 1 handicapped, elderly, or displaced by urban renewal or natural disaster\n\n\nHeatsub\n\n\nReceived energy subsidy\n\n\n1-No; 2-Yes\n\n\nIncome standards. Automatically eligible: recipients of Aid to Families with Dependent Children, Food Stamps, Supplemental Security Income or certain Veterans’ benefits.\n\n\nFoodstmp\n\n\nFood stamp recipiency\n\n\n1-No; 2-Yes\n\n\nAll low-income and low-resource households, regardless of the person’s characteristics (e.g., sex, age, disability, etc.)\n\n\nLunchsub\n\n\nGovernment school lunch food subsidy\n\n\n1-No; 2-Yes\n\n\nFree: students living in households with incomes <125% of the poverty level; Reduced: in households with incomes between 125% and 195%\n\n\n\n\n",
    "preview": "https://dt2sdf0db8zob.cloudfront.net/wp-content/uploads/2020/02/form-builders-11-850x435.png",
    "last_modified": "2021-03-09T03:35:05+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-18-boosting/",
    "title": "Boosting",
    "description": "Building ensembles one vote at a time",
    "author": [
      {
        "name": "Amit Gandhi",
        "url": {}
      }
    ],
    "date": "2021-02-18",
    "categories": [
      "lecture"
    ],
    "contents": "\n\n\n\nIntroduction\nA nice quote from Hands-on Machine Learning with R:\n\nBagging and random forests, on the other hand, work by combining multiple models together into an overall ensemble. New predictions are made by combining the predictions from the individual base models that make up the ensemble (e.g., by averaging in regression). Since averaging reduces variance, bagging (and hence, random forests) are most effectively applied to models with low bias and high variance (e.g., an overgrown decision tree). While boosting is a general algorithm for building an ensemble out of simpler models (typically decision trees), it is more effectively applied to models with high bias and low variance! Although boosting, like bagging, can be applied to any type of model, it is often most effectively applied to decision trees (which we’ll assume from this point on).\n\nThe process can be illustrated as a sequential ensemble:\n\n\nknitr::include_graphics(\"boosted-trees-process.png\")\n\n\n\n\nFigure 1: Sequential ensemble approach.\n\n\n\nThe algorithm\nBoosting is a greedy algorithm to learn additive basis function models of the form \\[f(x) = \\alpha_{0} + \\sum_{m=1}^{M}\\alpha_{m}\\varphi(x;\\theta_{m}),\\]\nwhere \\(\\varphi_{m}\\) are generated by a simple algorithm called a weak learner or base learner. The weak learner can be any classification or regression algorithm, such as a regression tree, a random forest, a simple single-layer neural network, etc. One could boost the performance (on the training set) of any weak learner arbitrarily high, provided the weak learner performs slightly better than chance.\nThe “beating chance” consideration is relevant when applied to classification problems. For regression problems any simple method such as least squares regression, regression stump, or one or two-layered neural network will work.\nIt is a very nice feature, since the only thing we need to make a stance on is the form of the weak learner, which is much less restrictive than choosing a sieve in the case of standard non-parametrics.\nThe goal of boosting is to solve the following optimization problem\n\\[\n\\begin{equation} \\label{eq:boosting_problem}\n    \\min_{f} \\sum_{i=1}^{N} L(y_{i},f(x_{i})),\n\\end{equation}\n\\] where \\(L(y,y')\\) is a loss function and \\(f\\) is defined above.\nSince the boosting estimator depends on the choice of the loss function, the algorithm that solves the optimization problem should be adjusted for a particular choice. A general approachcalled  works for an arbitrary loss function.\nBriemand et al in 1998 showed that boosting can be interpreted as a form of the gradient descent algorithm in function space. This idea then was further extended by Friedman in 2001 who presented the following functional gradient descent or gradient boosting algorithm:\nGiven data \\(\\{(y_{i},\\,x_{i})\\}_{i=1}^{n}\\), initialize the algorithm with some starting value. Common choices are \\[f_{0}(x) \\equiv \\argmin_{c} \\sum_{i=1}^{N} L(y_{i},c)\\], which is simply \\(\\bar{y}\\) under the squared loss, or \\(f_{0}(x) \\equiv 0\\). Set \\(m = 0\\).\nIncrease \\(m\\) by 1. Compute the negative gradient vector and evaluate it at \\(f_{m-1}(x_{i})\\): \\[r_{im} = - \\left.\\frac{\\partial L(y_{i},\\,f)}{\\partial f}\\right\\vert_{f = f_{m-1}(x_{i})}, \\quad i = 1,\\dots,\\,n.\\]\nUse the weak learner to compute \\((\\alpha_{m},\\,\\theta_{m})\\) which minimize \\(\\sum_{i=1}^{N} (r_{im} - \\alpha \\phi(x_{i};\\theta))^{2}\\).\nUpdate \\[f_{m}(x) = f_{m-1}(x) + \\alpha_{m} \\phi(x;\\theta_{m})\\], that is, proceed along an estimate of the negative gradient vector. In practice, better (test set) performance can be obtained by performing ``partial updates’’ of the form \\[f_{m}(x) = f_{m-1}(x) + \\nu \\alpha_{m} \\phi(x;\\theta_{m})\\],where \\(0 \\leq \\nu \\leq 1\\) is a shrinkage parameter, usually set close to zero (discussed in Friedman 2001).\nIterate steps 2 to 4 until \\(m = M\\) for some stopping iteration \\(M\\).\nThe key point is that we do not go back and adjust earlier parameters. The resulting basis functions learnt from the data are \\(\\phi(x) = (\\phi(x;\\theta_{1}),\\dots,\\phi(x;\\theta_{M}))\\). The number of iterations \\(M\\) is a tuning parameter, which can be optimally tuned via cross-validation or some model selection criterion.\nGradient Descent\nBasic gradient descent\n\n\n# create data to plot\nx <- seq(-5, 5, by = .05)\ny <- x^2 + 3\ndf <- data.frame(x, y)\nstep <- 5\nstep_size <- .2\nfor(i in seq_len(18)) {\n  next_step <- max(step) + round(diff(range(max(step), which.min(df$y))) * step_size, 0)\n  step <- c(step, next_step)\n  next\n}\nsteps <- df[step, ] %>%\n  mutate(x2 = lag(x), y2 = lag(y)) %>%\n  dplyr::slice(1:18)\n# plot\nggplot(df, aes(x, y)) +\n  geom_line(size = 1.5, alpha = .5) +\n  theme_classic() +\n  scale_y_continuous(\"Loss function\", limits = c(0, 30)) +\n  xlab(expression(theta)) +\n  geom_segment(data = df[c(5, which.min(df$y)), ], aes(x = x, y = y, xend = x, yend = -Inf), lty = \"dashed\") +\n  geom_point(data = filter(df, y == min(y)), aes(x, y), size = 4, shape = 21, fill = \"yellow\") +\n  geom_point(data = steps, aes(x, y), size = 3, shape = 21, fill = \"blue\", alpha = .5) +\n  geom_curve(data = steps, aes(x = x, y = y, xend = x2, yend = y2), curvature = 1, lty = \"dotted\") +\n  theme(\n    axis.ticks = element_blank(),\n    axis.text = element_blank()\n  ) +\n  annotate(\"text\", x = df[5, \"x\"], y = 1, label = \"Initial value\", hjust = -0.1, vjust = .8) +\n  annotate(\"text\", x = df[which.min(df$y), \"x\"], y = 1, label = \"Minimium\", hjust = -0.1, vjust = .8) +\n  annotate(\"text\", x = df[5, \"x\"], y = df[5, \"y\"], label = \"Learning step\", hjust = -.8, vjust = 0)\n\n\n\n\nFigure 2: Gradient descent is the process of gradually decreasing the cost function (i.e. MSE) by tweaking parameter(s) iteratively until you have reached a minimum.\n\n\n\nAdding a learning rate\n\n\n# create too small of a learning rate\nstep <- 5\nstep_size <- .05\nfor(i in seq_len(10)) {\n  next_step <- max(step) + round(diff(range(max(step), which.min(df$y))) * step_size, 0)\n  step <- c(step, next_step)\n  next\n}\ntoo_small <- df[step, ] %>%\n  mutate(x2 = lag(x), y2 = lag(y))\n# plot\np1 <- ggplot(df, aes(x, y)) +\n  geom_line(size = 1.5, alpha = .5) +\n  theme_classic() +\n  scale_y_continuous(\"Loss function\", limits = c(0, 30)) +\n  xlab(expression(theta)) +\n  geom_segment(data = too_small[1, ], aes(x = x, y = y, xend = x, yend = -Inf), lty = \"dashed\") +\n  geom_point(data = too_small, aes(x, y), size = 3, shape = 21, fill = \"blue\", alpha = .5) +\n  geom_curve(data = too_small, aes(x = x, y = y, xend = x2, yend = y2), curvature = 1, lty = \"dotted\") +\n  theme(\n    axis.ticks = element_blank(),\n    axis.text = element_blank()\n  ) +\n  annotate(\"text\", x = df[5, \"x\"], y = 1, label = \"Start\", hjust = -0.1, vjust = .8) +\n  ggtitle(\"b) too small\")\n# create too large of a learning rate\ntoo_large <- df[round(which.min(df$y) * (1 + c(-.9, -.6, -.2, .3)), 0), ] %>%\n  mutate(x2 = lag(x), y2 = lag(y))\n# plot\np2 <- ggplot(df, aes(x, y)) +\n  geom_line(size = 1.5, alpha = .5) +\n  theme_classic() +\n  scale_y_continuous(\"Loss function\", limits = c(0, 30)) +\n  xlab(expression(theta)) +\n  geom_segment(data = too_large[1, ], aes(x = x, y = y, xend = x, yend = -Inf), lty = \"dashed\") +\n  geom_point(data = too_large, aes(x, y), size = 3, shape = 21, fill = \"blue\", alpha = .5) +\n  geom_curve(data = too_large, aes(x = x, y = y, xend = x2, yend = y2), curvature = 1, lty = \"dotted\") +\n  theme(\n    axis.ticks = element_blank(),\n    axis.text = element_blank()\n  ) +\n  annotate(\"text\", x = too_large[1, \"x\"], y = 1, label = \"Start\", hjust = -0.1, vjust = .8) +\n  ggtitle(\"a) too big\")\ngridExtra::grid.arrange(p2, p1, nrow = 1)\n\n\n\n\nFigure 3: A learning rate that is too small will require many iterations to find the minimum. A learning rate too big may jump over the minimum.\n\n\n\nStochastic Gradient Descent\n\n\n# create random walk data\nset.seed(123)\nx <- sample(seq(3, 5, by = .05), 10, replace = TRUE)\nset.seed(123)\ny <- seq(2, 28, length.out = 10)\n\nrandom_walk <- data.frame(\n  x = x,\n  y = y[order(y, decreasing = TRUE)]\n)\n\noptimal <- data.frame(x = 0, y = 0)\n\n# plot\nggplot(df, aes(x, y)) + \n  coord_polar() +\n  theme_minimal() +\n  theme(\n    axis.ticks = element_blank(),\n    axis.text = element_blank()\n  ) +\n  xlab(expression(theta[1])) +\n  ylab(expression(theta[2])) +\n  geom_point(data = random_walk, aes(x, y), size = 3, shape = 21, fill = \"blue\", alpha = .5) + \n  geom_point(data = optimal, aes(x, y), size = 2, shape = 21, fill = \"yellow\") + \n  geom_path(data = random_walk, aes(x, y), lty = \"dotted\") +\n  annotate(\"text\", x = random_walk[1, \"x\"], y = random_walk[1, \"y\"], label = \"Start\", hjust = 1, vjust = -1) +\n  annotate(\"text\", x = optimal[1, \"x\"], y = optimal[1, \"y\"], label = \"Minimum\", hjust = -.2, vjust = 1) +\n  ylim(c(0, 28)) + \n  xlim(-5, 5)\n\n\n\n\nFigure 4: Stochastic gradient descent will often find a near-optimal solution by jumping out of local minimas and off plateaus.\n\n\n\nIllustration\nLoad packages\n\n\n\nLets observe how a sequential ensemble is built up from weak learners.\n\n\n# Simulate sine wave data\nset.seed(1112)  # for reproducibility\ndf <- tibble::tibble(\n  x = seq(from = 0, to = 2 * pi, length = 1000),\n  y = sin(x) + rnorm(length(x), sd = 0.5),\n  truth = sin(x)\n)\n\n# Function to boost `rpart::rpart()` trees\nrpartBoost <- function(x, y, data, num_trees = 100, learn_rate = 0.1, tree_depth = 6) {\n  x <- data[[deparse(substitute(x))]]\n  y <- data[[deparse(substitute(y))]]\n  G_b_hat <- matrix(0, nrow = length(y), ncol = num_trees + 1)\n  r <- y\n  for(tree in seq_len(num_trees)) {\n    g_b_tilde <- rpart(r ~ x, control = list(cp = 0, maxdepth = tree_depth))\n    g_b_hat <- learn_rate * predict(g_b_tilde)\n    G_b_hat[, tree + 1] <- G_b_hat[, tree] + matrix(g_b_hat)\n    r <- r - g_b_hat\n    colnames(G_b_hat) <- paste0(\"tree_\", c(0, seq_len(num_trees)))\n  }\n  cbind(df, as.data.frame(G_b_hat)) %>%\n    gather(tree, prediction, starts_with(\"tree\")) %>%\n    mutate(tree = stringr::str_extract(tree, \"\\\\d+\") %>% as.numeric())\n}\n\n# Plot boosted tree sequence\nrpartBoost(x, y, data = df, num_trees = 2^10, learn_rate = 0.05, tree_depth = 1) %>%\n  filter(tree %in% c(0, 2^c(0:10))) %>%\n  ggplot(aes(x, prediction)) +\n    ylab(\"y\") +\n    geom_point(data = df, aes(x, y), alpha = .1) +\n    geom_line(data = df, aes(x, truth), color = \"blue\") +\n    geom_line(colour = \"red\", size = 1) +\n    facet_wrap(~ tree, nrow = 3)\n\n\n\n\nFigure 5: Boosted regression decision stumps as 0-1024 successive trees are added.\n\n\n\nNow consider the Ames, IA housing data\n\n\nlibrary(rsample)\n# create Ames training data\nset.seed(123)\names <- AmesHousing::make_ames()\nsplit  <- initial_split(ames, prop = 0.7, strata = \"Sale_Price\")\names_train  <- training(split)\n\n\n\nThere are several hyperparameter tuning options available in stochastic gradient boosting (some control the gradient descent and others control the tree growing process). If properly tuned (e.g., with k-fold CV) GBMs can lead to some of the most flexible and accurate predictive models you can build.\nBasic GBM\nImplementation\n# run a basic GBM model\nset.seed(123)  # for reproducibility\names_gbm1 <- gbm(\n  formula = Sale_Price ~ .,\n  data = ames_train,\n  distribution = \"gaussian\",  # SSE loss function\n  n.trees = 5000,\n  shrinkage = 0.1,\n  interaction.depth = 3,\n  n.minobsinnode = 10,\n  cv.folds = 10\n)\n\n# find index for number trees with minimum CV error\nbest <- which.min(ames_gbm1$cv.error)\n\n# get MSE and compute RMSE\nsqrt(ames_gbm1$cv.error[best])\n# plot error curve\ngbm.perf(ames_gbm1, method = \"cv\")\n\nGeneral tuning strategy\nAs HOMR notes - simple GBM model contains two categories of hyperparameters: boosting hyperparameters and tree-specific hyperparameters. The two main boosting hyper-parameters include:\nNumber of trees: The total number of trees in the sequence or ensemble. The averaging of independently grown trees in bagging and random forests makes it very difficult to overfit with too many trees. However, GBMs function differently as each tree is grown in sequence to fix up the past tree’s mistakes. For example, in regression, GBMs will chase residuals as long as you allow them to. Also, depending on the values of the other hyperparameters, GBMs often require many trees (it is not uncommon to have many thousands of trees) but since they can easily overfit we must find the optimal number of trees that minimize the loss function of interest with cross validation.\nLearning rate: Determines the contribution of each tree on the final outcome and controls how quickly the algorithm proceeds down the gradient descent (learns); see Figure 12.3. Values range from 0–1 with typical values between 0.001–0.3. Smaller values make the model robust to the specific characteristics of each individual tree, thus allowing it to generalize well. Smaller values also make it easier to stop prior to overfitting; however, they increase the risk of not reaching the optimum with a fixed number of trees and are more computationally demanding. This hyperparameter is also called shrinkage. Generally, the smaller this value, the more accurate the model can be but also will require more trees in the sequence.\nThe two main tree hyperparameters in a simple GBM model include:\nTree depth: Controls the depth of the individual trees. Typical values range from a depth of 3–8 but it is not uncommon to see a tree depth of 1 (J. Friedman, Hastie, and Tibshirani 2001). Smaller depth trees such as decision stumps are computationally efficient (but require more trees); however, higher depth trees allow the algorithm to capture unique interactions but also increase the risk of over-fitting.\nMinimum number of observations in terminal nodes: Also, controls the complexity of each tree. Since we tend to use shorter trees this rarely has a large impact on performance. Typical values range from 5–15 where higher values help prevent a model from learning relationships which might be highly specific to the particular sample selected for a tree (overfitting) but smaller values can help with imbalanced target classes in classification problems.\n# create grid search\nhyper_grid <- expand.grid(\n  learning_rate = c(0.3, 0.1, 0.05, 0.01, 0.005),\n  RMSE = NA,\n  trees = NA,\n  time = NA\n)\n\n# execute grid search\nfor(i in seq_len(nrow(hyper_grid))) {\n\n  # fit gbm\n  set.seed(123)  # for reproducibility\n  train_time <- system.time({\n    m <- gbm(\n      formula = Sale_Price ~ .,\n      data = ames_train,\n      distribution = \"gaussian\",\n      n.trees = 5000, \n      shrinkage = hyper_grid$learning_rate[i], \n      interaction.depth = 3, \n      n.minobsinnode = 10,\n      cv.folds = 10 \n   )\n  })\n  \n  # add SSE, trees, and training time to results\n  hyper_grid$RMSE[i]  <- sqrt(min(m$cv.error))\n  hyper_grid$trees[i] <- which.min(m$cv.error)\n  hyper_grid$Time[i]  <- train_time[[\"elapsed\"]]\n\n}\n\n# results\narrange(hyper_grid, RMSE)\nThe code yields\n\n\n\n\n",
    "preview": "https://www.edureka.co/blog/wp-content/uploads/2019/06/What-Is-Ensemble-Learning-Boosting-Machine-Learning-Edureka.png",
    "last_modified": "2021-02-18T15:50:04+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-11-random-forests/",
    "title": "Random Forests",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Amit Gandhi",
        "url": {}
      }
    ],
    "date": "2021-02-11",
    "categories": [],
    "contents": "\n\n\n\nPrerequisite Packages\nThis chapter leverages the following packages:\n\n\n# Helper packages\nlibrary(dplyr)    # for data wrangling\nlibrary(ggplot2)  # for awesome graphics\n\n# Modeling packages\nlibrary(ranger)   # a c++ implementation of random forest \nlibrary(h2o)      # a java-based implementation of random forest\n\n\n\nAmes, IA Data\nWe’ll continue working with the ames_train data set:\n\n\n# create Ames training data\nset.seed(123)\names <- AmesHousing::make_ames()\nsplit  <- initial_split(ames, prop = 0.7, strata = \"Sale_Price\")\names_train  <- training(split)\n\n\n\nWhat is the problem?\nBagged trees are correlated and thus full variance reduction effects are not realized:\n\n\nlibrary(caret)\nlibrary(randomForest)\niter = 6\npar(mfrow = c(3, 3))\nfor(i in 1:iter){\n  set.seed(i+30)\n  # create train/test sets\n  train_index <- caret::createDataPartition(pdp::boston$cmedv, p = .6333,\n                                     list = FALSE,\n                                     times = 1)\n  \n  train_DF <- pdp::boston[train_index,]\n  validate_DF <- pdp::boston[-train_index,]\n  \n  train_y <- train_DF$cmedv\n  train_x <- train_DF[, setdiff(names(train_DF), \"cmedv\")]\n  \n  validate_y <- validate_DF$cmedv\n  validate_x <- validate_DF[, setdiff(names(validate_DF), \"cmedv\")]\n  \n  d_tree <- rpart::rpart(cmedv ~ ., train_DF)\n  \n  # graphs\n  \n  rpart.plot::rpart.plot(d_tree, main = paste0(\"Decision Tree \", i), type = 0, extra = 0) \n  \n}\n\n\n\n\nFigure 1: Six decision trees based on different bootstrap samples.\n\n\n\nSuppose that there is one very strong predictor in the data set, along with a number of other moderately strong predictors.\nThen in the collection of bagged trees, most or all of the trees will use this strong predictor in the top split.\nAll of the bagged trees will look quite similar to each other and the predictions from the bagged trees will be highly correlated.\nAveraging many highly correlated quantities does not lead to as large of a reduction in variance as averaging many uncorrelated quantities.\nIn particular, this means that bagging will not lead to a substantial reduction in variance over a single tree in this setting.\nRandom Forests\nRandom forests provide an improvement over bagged trees by way of a small tweak that decorrelates the trees.\nRandom forests overcome this problem by forcing each split to consider only a subset of the predictors.\nTherefore, on average \\((p - m)/p\\) of the splits will not even consider the strong predictor, and so other predictors will have more of a chance.\nWe can think of this process as decorrelating the trees, thereby making the average of the resulting trees less variable and hence more reliable.\nAs in bagging, we build a number of decision trees on bootstrapped training samples.\nBut when building these decision trees, each time a split in a tree is considered, a random sample of \\(m\\) predictors is chosen as split candidates from the full set of \\(p\\) predictors.\nThe split is allowed to use only one of those \\(m\\) predictors.\nA fresh sample of \\(m\\) predictors is taken at each split, and typically we choose \\(m \\approx \\sqrt{p}\\).\nIf a random forest is built where \\(m =p\\), then bagging is a special case of random forests.\nOut-of-the-box performance\n\n\n# number of features\nn_features <- length(setdiff(names(ames_train), \"Sale_Price\"))\n\n# train a default random forest model\names_rf1 <- ranger(\n  Sale_Price ~ ., \n  data = ames_train,\n  mtry = floor(n_features / 3),\n  respect.unordered.factors = \"order\",\n  seed = 123\n)\n\n# get OOB RMSE\n(default_rmse <- sqrt(ames_rf1$prediction.error))\n\n\n[1] 25896.47\n\nHyperparameters\nThe main hyperparameters to consider include:\nThe number of trees in the forest\nThe number of features to consider at any given split: \\(m\\)\nThe complexity of each tree\nThe sampling scheme\nThe splitting rule to use during tree construction\nAs Hands on Machine Learning with R Explains\n\nand (2) typically have the largest impact on predictive accuracy and should always be tuned. (3) and (4) tend to have marginal impact on predictive accuracy but are still worth exploring. They also have the ability to influence computational efficiency. (5) tends to have the smallest impact on predictive accuracy and is used primarily to increase computational efficiency.\n\nLets try grid search:\n\n\n# create hyperparameter grid\nhyper_grid <- expand.grid(\n  mtry = floor(n_features * c(.05, .15, .25, .333, .4)),\n  min.node.size = c(1, 3, 5, 10), \n  replace = c(TRUE, FALSE),                               \n  sample.fraction = c(.5, .63, .8),                       \n  rmse = NA                                               \n)\n\n# execute full cartesian grid search\nfor(i in seq_len(nrow(hyper_grid))) {\n  # fit model for ith hyperparameter combination\n  fit <- ranger(\n    formula         = Sale_Price ~ ., \n    data            = ames_train, \n    num.trees       = n_features * 10,\n    mtry            = hyper_grid$mtry[i],\n    min.node.size   = hyper_grid$min.node.size[i],\n    replace         = hyper_grid$replace[i],\n    sample.fraction = hyper_grid$sample.fraction[i],\n    verbose         = FALSE,\n    seed            = 123,\n    respect.unordered.factors = 'order',\n  )\n  # export OOB error \n  hyper_grid$rmse[i] <- sqrt(fit$prediction.error)\n}\n\n# assess top 10 models\nhyper_grid %>%\n  arrange(rmse) %>%\n  mutate(perc_gain = (default_rmse - rmse) / default_rmse * 100) %>%\n  head(10)\n\n\n   mtry min.node.size replace sample.fraction     rmse  perc_gain\n1    12             1   FALSE            0.80 25647.89 0.95992513\n2    20             3   FALSE            0.80 25674.68 0.85647489\n3    20             1   FALSE            0.80 25714.82 0.70147122\n4    20             5   FALSE            0.80 25720.21 0.68062832\n5    12             3   FALSE            0.80 25764.50 0.50960286\n6    12             5   FALSE            0.80 25772.13 0.48016777\n7    26             3   FALSE            0.63 25847.12 0.19059784\n8    26             1   FALSE            0.50 25862.91 0.12961969\n9    12            10   FALSE            0.80 25873.58 0.08839306\n10   12             1   FALSE            0.63 25877.26 0.07420710\n\nFeature interpretation\nInterpretability of Bagged Trees and RF’s is an important issue.\nRecall that bagging typically results in improved accuracy over prediction using a single tree.\nUnfortunately, however, it can be difficult to interpret the resulting model.\nBut one main attraction of decision trees is their intrepretability!\nHowever, when we bag a large number of trees, it is no longer possible to represent the resulting statistical learning procedure using a single tree, and it is no longer clear which variables are most important to the procedure.\nThus, bagging improves prediction accuracy at the expense of interpretability.\nVariable Importance Measures\nAlthough the collection of bagged trees is much more difficult to interpret than a single tree, one can obtain an overall summary of the importance of each predictor using the impurity gains at each node.\nthe RSS (for bagging regression trees) or\nthe Gini index (for bagging classification trees).\nIn the case of bagging regression trees, we can record the total amount that the RSS is decreased due to splits over a given predictor, averaged over all \\(B\\) trees.\nA large value indicates an important predictor.\nSimilarly, in the context of bagging classification trees, we can add up the total amount that the Gini index is decreased by splits over a given predictor, averaged over all \\(B\\) trees.\n\n\n# re-run model with impurity-based variable importance\nrf_impurity <- ranger(\n  formula = Sale_Price ~ ., \n  data = ames_train, \n  num.trees = 2000,\n  mtry = 32,\n  min.node.size = 1,\n  sample.fraction = .80,\n  replace = FALSE,\n  importance = \"impurity\",\n  respect.unordered.factors = \"order\",\n  verbose = FALSE,\n  seed  = 123\n)\n\n# re-run model with permutation-based variable importance\nrf_permutation <- ranger(\n  formula = Sale_Price ~ ., \n  data = ames_train, \n  num.trees = 2000,\n  mtry = 32,\n  min.node.size = 1,\n  sample.fraction = .80,\n  replace = FALSE,\n  importance = \"permutation\",\n  respect.unordered.factors = \"order\",\n  verbose = FALSE,\n  seed  = 123\n)\n\n\n\n\n\np1 <- vip::vip(rf_impurity, num_features = 25, bar = FALSE)\np2 <- vip::vip(rf_permutation, num_features = 25, bar = FALSE)\n\ngridExtra::grid.arrange(p1, p2, nrow = 1)\n\n\n\n\nFigure 2: Top 25 most important variables based on impurity (left) and permutation (right).\n\n\n\n\n\n\n",
    "preview": "https://www.frontiersin.org/files/Articles/284242/fnagi-09-00329-HTML/image_m/fnagi-09-00329-g001.jpg",
    "last_modified": "2021-02-11T15:59:21+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-08-bagging-trees/",
    "title": "Bagging and Trees",
    "description": "For learners with low bias and high variance",
    "author": [
      {
        "name": "Amit Gandhi",
        "url": {}
      }
    ],
    "date": "2021-02-08",
    "categories": [],
    "contents": "\n\n\n\nIntroduction\nWe can think about an algorithmic model as being defined by a learner - an algorithm that fits training data given hyper-parameters that are subject to tuning.\nDecision trees are a class of learners. As a class they are generally characterized as high variance and low bias, e.g., they are very expressive and flexible (e.g., low bias) but as a result risk over-fitting the training data.\nPruning is one approach to managing the high variance of decision trees. Unfortunately pruning destroys much of the expressiveness of the tree by forcing it to be coarse. Is there a better way to manage a low bias + high variance learner.\nIn what follows below we borrow code and examples from the excellent book Hands on Machine Learning with R\nVisualizing the behavior of trees\nLets simulate some bivariate data\n\n\n# create data\nset.seed(1112)  # for reproducibility\ndf <- tibble::tibble(\n  x = seq(from = 0, to = 2 * pi, length = 500),\n  y = sin(x) + rnorm(length(x), sd = 0.5),\n  truth = sin(x)\n)\n\n\n\nLets consider a single stump decision tree model that is fit by appropriately setting the control parameters in rpart\n\n\nctrl <- list(cp = 0, minbucket = 5, maxdepth = 1)\nfit <- rpart(y ~ x, data = df, control = ctrl)\n\n\n\nLets plot the tree\n\n\npar(mar = c(1, 1, 1, 1))\nrpart.plot(fit)\n\n\n\n\nWe can add the fitted values to the data\n\n\ndf <- \n  df %>%\n  mutate(pred = predict(fit, df))\n\n\n\n\n\nplot1 <-\n  df %>%\n  ggplot(aes(x, y)) +\n  geom_point(alpha = .2, size = 1) +\n  geom_line(aes(x, y = truth), color = \"blue\", size = .75)\n\nplot1\n\n\n\n\nPlot the fitted tree against the data\n\n\n  plot1 + \n  \n  geom_line(aes(y = pred), color = \"red\", size = .75) +\n  geom_segment(x = 3.1, xend = 3.1, y = -Inf, yend = -.95,\n               arrow = arrow(length = unit(0.25,\"cm\")), size = .25) +\n  annotate(\"text\", x = 3.1, y = -Inf, label = \"split\", hjust = 1.2, vjust = -1, size = 3) +\n  geom_segment(x = 5.5, xend = 6, y = 2, yend = 2, size = .75, color = \"blue\") +\n  geom_segment(x = 5.5, xend = 6, y = 1.7, yend = 1.7, size = .75, color = \"red\") +\n  annotate(\"text\", x = 5.3, y = 2, label = \"truth\", hjust = 1, size = 3, color = \"blue\") +\n  annotate(\"text\", x = 5.3, y = 1.7, label = \"decision boundary\", hjust = 1, size = 3, color = \"red\")\n\n\n\n\nA less regularized (higher variance) tree is a learner that is allowed to grow large.\n\n\nctrl <- list(cp = 0, minbucket = 1, maxdepth = 50)\nfit <- rpart(y ~ x, data = df, control = ctrl)\nrpart.plot(fit)\n\n\n\n\n\n\np1<- \n  df %>%\n  mutate(pred = predict(fit, df)) %>%\n  ggplot(aes(x, y)) +\n  geom_point(alpha = .2, size = 1) +\n  geom_line(aes(x, y = truth), color = \"blue\", size = 0.75) +\n  geom_line(aes(y = pred), color = \"red\", size = 0.75)\n\np1\n\n\n\n\nThe CART strategy is to grow large and prune.\n\n\nfit2 <- rpart(y ~ x, data = df)\n\np2 <- df %>%\n  mutate(pred2 = predict(fit2, df)) %>%\n  ggplot(aes(x, y)) +\n  geom_point(alpha = .3, size = 2) +\n  geom_line(aes(x, y = truth), color = \"blue\", size = 1) +\n  geom_line(aes(y = pred2), color = \"red\", size = 1)\n\ngridExtra::grid.arrange(p1, p2, nrow = 1)\n\n\n\n\nFigure 1: To prune a tree, we grow an overly complex tree (left) and then use a cost complexity parameter to identify the optimal subtree (right).\n\n\n\nHow does bagging work and what does it acheive?\nBootstrapping\nThe basis for bagging is resampling the training data via bootstrap sampling.\n\n\nknitr::include_graphics(\"bootstrap-scheme.png\")\n\n\n\n\nFigure 2: Illustration of the bootstrapping process.\n\n\n\nWe are not bootstrapping for the usual reason - to assess the uncertainty of a parameter estimate \\(\\hat{\\theta}\\).\nInstead we are bootstrapping for the purposes of averaging across bootstrap samples, and hence the name baggging where bag = bootstrap aggregation.\nHow does this work:\nWe can take repeated samples from the (single) training data set.\nWe will generate \\(B\\) different bootstrapped training data sets.\nWe then train our method on the \\(b\\)th bootstrapped training set in order to get \\(\\hat{f}^{*b}(x).\\)\nFinally, we average all the predictions, to obtain \\[\\hat{f}_\\text{bag}(x) = \\frac{1}{B}\n\\sum_{b=1}^B \\hat{f}^{*b}(x).\\]\nWhy does this work?\nConsider a training sample \\((x_1, y_1), \\dots , (x_n, y_n)\\) drawn from an underlying distribution \\(P\\) that describes the joint distribution of \\(Y,X\\).\nLet us define a theoretical bagged quantity\n\\[\nf_{bag} = E_{P} \\hat{f}(x)\n\\]\nHere the expectation considers redrawing the training data from the population distribution \\(P\\), and bootstrap sampling is a sample analogue of this experiment.\nThen we can express the prediction error\n\\[\\begin{align}\nE_{P}[(Y - \\hat{f}(x)] &= E_{P}\\left[ \\left(Y - f_{agg}(x)\\right)^2 \\right] +  E_{P}\\left[ \\left(\\hat{f}(x) - f_{agg}(x)\\right)^2 \\right] \\\\\n&\\geq E_{P}\\left[ \\left(Y - f_{agg}(x)\\right)^2 \\right]\n\\end{align}\\]\nThus we can see bagging directly benefit from the variance reduction associated with elimination of the second term in the prediction error.\nThe bootstrap has significant effects for high variance learners and hence payoff for low bias + high variance learners.\nBagging for Regression Trees\nTo apply bagging to regression trees do the following:\nconstruct \\(B\\) regression trees using \\(B\\) bootstrapped training sets\naverage the resulting predictions.\nRegression trees are grown deep, and are not pruned.\nHence each individual tree has high variance, but low bias. Thus, averaging these \\(B\\) trees reduces the variance.\nBagging has been demonstrated to give impressive improvements in accuracy by combining together hundreds or even thousands of trees into a single procedure.\nBagging for Classification Trees\nBagging for Classification Trees\nThere are many ways to apply bagging for classification trees.\nWe explain the simplest way.\nFor a given test observation, we can record the class predicted by each of the \\(B\\) trees.\nTake a majority vote.\nA majority vote is simply the overall prediction is the most commonly occurring class among the \\(B\\) predictions.\nThis is the so-called wisdom of crowd effects. It requires starting with a weak learner.\nBagging a bad learner for 0-1 classification loss can make prediction worse. See the example at the top of page 286 in ESL.\nOOB Error Estimation\nFirst consider visually how bootstrap sampling differs from cross validation\n\n\nboots <- rsample::bootstraps(mtcars, 10)\nboots_plot <- boots$splits %>%\n  purrr::map2_dfr(seq_along(boots$splits), ~ mtcars %>% \n             mutate(\n               Resample = paste0(\"Bootstrap_\", stringr::str_pad(.y, 2, pad = 0)),\n               ID = row_number()\n             ) %>%\n             group_by(ID) %>%\n             mutate(Replicates = factor(sum(ID == .x$in_id)))) %>%\n  ggplot(aes(Resample, ID, fill = Replicates)) +\n  geom_tile() +\n  scale_fill_manual(values = c(\"#FFFFFF\", \"#F5F5F5\", \"#C8C8C8\", \"#A0A0A0\", \"#707070\", \"#505050\", \"#000000\")) +\n  scale_y_reverse(\"Observation ID\", breaks = 1:nrow(mtcars), expand = c(0, 0)) +\n  scale_x_discrete(NULL, expand = c(0, 0)) +\n  theme_classic() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  ggtitle(\"Bootstrap sampling\") \n\ncv <- vfold_cv(mtcars, 10)\ncv_plot <- cv$splits %>%\n  purrr::map2_dfr(seq_along(cv$splits), ~ mtcars %>% mutate(\n    Resample = paste0(\"Fold_\", stringr::str_pad(.y, 2, pad = 0)),\n    ID = row_number(),\n    Data = ifelse(ID %in% .x$in_id, \"Training\", \"Validation\"))\n    ) %>%\n  ggplot(aes(Resample, ID, fill = Data)) +\n  geom_tile() +\n  scale_fill_manual(values = c(\"#f2f2f2\", \"#AAAAAA\")) +\n  scale_y_reverse(\"Observation ID\", breaks = 1:nrow(mtcars), expand = c(0, 0)) +\n  scale_x_discrete(NULL, expand = c(0, 0)) +\n  theme_classic() +\n  theme(legend.title=element_blank())\n\n\n\ncv_plot <- cv_plot + \n  ggtitle(\"10-fold cross validation\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\ncowplot::plot_grid(boots_plot, cv_plot, align = \"h\", nrow = 1)\n\n\n\n\nFigure 3: Bootstrap sampling (left) versus 10-fold cross validation (right) on 32 observations. For bootstrap sampling, warning=FALSE, the observations that have zero replications (white) are the out-of-bag observations used for validation.\n\n\n\n# clean up\nrm(boots, boots_plot, cv_plot)\n\n\n\nThe sampling scheme reveals an important insight - the OOB (Out-of-Bag) experiment.\nOne can show that on average, each bagged tree makes use of around two-thirds of the observations (this is evident from the white cells across any row in the bootstrap graph above)\nThe remaining one-third of the observations not used to fit a given bagged tree are referred to as the out-of-bag (OOB) observations.\nWe can predict the response for the \\(i\\)th observation using each of the trees in which that observation was OOB.\nThus in order to obtain a single prediction for the \\(i\\)th observation, we can average these predicted responses (if regression is the goal) or can take a majority vote (if classification is the goal).\nThis leads to a single OOB prediction for the ith observation.\nAn OOB prediction can be obtained in this way for each of the \\(n\\) observations, from which the overall OOB MSE (for a regression problem) or classification error (for a classification problem) can be computed.\nThe resulting OOB error is a valid estimate of the test error for the bagged model, since the response for each observation is predicted using only the trees that were not fit using that observation.\nIt can be shown that with B sufficiently large, OOB error is virtually equivalent to leave-one-out cross-validation error.\nThe OOB approach for estimating the test error is particularly convenient when performing bagging on large data sets for which cross-validation would be computationally onerous.\nA simulated bagging experiment\n\n\n# Simulate some nonlinear monotonic data\nset.seed(123)  # for reproducibility\nx <- seq(from = 0, to = 2 * pi, length = 500)\ny <- sin(x) + rnorm(length(x), sd = 0.3)\ndf <- data.frame(x, y) %>%\n  filter(x < 4.5)\n\n# bootstrapped polynomial model fit\nbootstrap_n <- 100\nbootstrap_results <- NULL\nfor(i in seq_len(bootstrap_n)) {\n  # reproducible sampled data frames\n  set.seed(i)\n  index <- sample(seq_len(nrow(df)), nrow(df), replace = TRUE)\n  df_sim <- df[index, ]\n  \n  # fit model and add predictions to results data frame\n  fit <- lm(y ~ I(x^3), data = df_sim)\n  df_sim$predictions <- predict(fit, df_sim)\n  df_sim$model <- paste0(\"model\", i)\n  df_sim$ob <- index\n  bootstrap_results <- rbind(bootstrap_results, df_sim)\n}\n\np1 <- ggplot(bootstrap_results, aes(x, predictions)) +\n  geom_point(data = df, aes(x, y), alpha = .25) +\n  geom_line(aes(group = model), show.legend = FALSE, size = .5, alpha = .2) +\n  stat_summary(fun.y = \"mean\", colour = \"red\", size = 1, geom = \"line\") +\n  scale_y_continuous(\"Response\", limits = c(-2, 2), expand = c(0, 0)) +\n  scale_x_continuous(limits = c(0, 5), expand = c(0, 0)) +\n  ggtitle(\"A) Polynomial regression\")\n\n\n\n# bootstrapped decision trees fit\nbootstrap_n <- 100\nbootstrap_results <- NULL\nfor(i in seq_len(bootstrap_n)) {\n  # reproducible sampled data frames\n  set.seed(i)\n  index <- sample(seq_len(nrow(df)), nrow(df), replace = TRUE)\n  df_sim <- df[index, ]\n  \n  # fit model and add predictions to results data frame\n  fit <- rpart::rpart(y ~ x, data = df_sim)\n  df_sim$predictions <- predict(fit, df_sim)\n  df_sim$model <- paste0(\"model\", i)\n  df_sim$ob <- index\n  bootstrap_results <- rbind(bootstrap_results, df_sim)\n}\n\np3 <- ggplot(bootstrap_results, aes(x, predictions)) +\n  geom_point(data = df, aes(x, y), alpha = .25) +\n  geom_line(aes(group = model), show.legend = FALSE, size = .5, alpha = .2) +\n  stat_summary(fun.y = \"mean\", colour = \"red\", size = 1, geom = \"line\") +\n  scale_y_continuous(NULL, limits = c(-2, 2), expand = c(0, 0)) +\n  scale_x_continuous(limits = c(0, 5), expand = c(0, 0)) +\n  ggtitle(\"B) Decision trees\")\n\ngridExtra::grid.arrange(p1, p3, nrow = 1)\n\n\n\n\nFigure 4: The effect of bagging 100 base learners. High variance models such as decision trees (B) benefit the most from the aggregation effect in bagging, whereas low variance models such as polynomial regression (A) show little improvement.\n\n\n\nRevisiting the Ames, IA data\nLets try bagging on the Ames, IA data. First we setup the data as we did in prior posts.\n\n\n# create Ames training data\nset.seed(123)\names <- AmesHousing::make_ames()\nsplit  <- initial_split(ames, prop = 0.7, strata = \"Sale_Price\")\names_train  <- training(split)\names_test  <- testing(split)\n\n\n\nWe will use the bagging() function from the ipred package.\n\n\n# make bootstrapping reproducible\nset.seed(123)\n\n# train bagged model\names_bag1 <- bagging(\n  formula = Sale_Price ~ .,\n  data = ames_train,\n  nbagg = 100,  \n  coob = TRUE,\n  control = rpart.control(minsplit = 2, cp = 0)\n)\n\names_bag1\n\n\n\nBagging regression trees with 100 bootstrap replications \n\nCall: bagging.data.frame(formula = Sale_Price ~ ., data = ames_train, \n    nbagg = 100, coob = TRUE, control = rpart.control(minsplit = 2, \n        cp = 0))\n\nOut-of-bag estimate of root mean squared error:  27767.13 \n\nHow does this compare to pruning a decision tree. With enough trees, the performance of bagging exceeds that of pruning.\n\n\n# # assess 10-200 bagged trees\n# ntree <- seq(10, 200, by = 2)\n# \n# # create empty vector to store OOB RMSE values\n# rmse <- vector(mode = \"numeric\", length = length(ntree))\n# \n# for (i in seq_along(ntree)) {\n#   # reproducibility\n#   set.seed(123)\n#   # perform bagged model\n#   model <- bagging(\n#   formula = Sale_Price ~ .,\n#   data    = ames_train,\n#   coob    = TRUE,\n#   control = rpart.control(minsplit = 2, cp = 0),\n#   nbagg   = ntree[i]\n# )\n#   # get OOB error\n#   rmse[i] <- model$err\n# }\n# \n# bagging_errors <- data.frame(ntree, rmse)\n\n# using ranger to do the same as above.  Will allow for bagging under 10 trees\n# and is much faster!\nntree <- seq(1, 200, by = 2)\n# create empty vector to store OOB RMSE values\nrmse <- vector(mode = \"numeric\", length = length(ntree))\n\nfor (i in seq_along(ntree)) {\n  # reproducibility\n  set.seed(123)\n  # perform bagged model\n  model <- ranger::ranger(\n  formula = Sale_Price ~ .,\n  data    = ames_train,\n  num.trees = ntree[i],\n  mtry = ncol(ames_train) - 1,\n  min.node.size = 1\n)\n  # get OOB error\n  rmse[i] <- sqrt(model$prediction.error)\n}\n\nbagging_errors <- data.frame(ntree, rmse)\n\nggplot(bagging_errors, aes(ntree, rmse)) +\n  geom_line() +\n  geom_hline(yintercept = 41019, lty = \"dashed\", color = \"grey50\") +\n  annotate(\"text\", x = 100, y = 41385, label = \"Best individual pruned tree\", vjust = 0, hjust = 0, color = \"grey50\") +\n  annotate(\"text\", x = 100, y = 26750, label = \"Bagged trees\", vjust = 0, hjust = 0) +\n  ylab(\"RMSE\") +\n  xlab(\"Number of trees\")\n\n\n\n\nFigure 5: Error curve for bagging 1-200 deep, unpruned decision trees. The benefit of bagging is optimized at 187 trees although the majority of error reduction occurred within the first 100 trees.\n\n\n\n\n\n\n",
    "preview": "https://upload.wikimedia.org/wikipedia/commons/d/de/Ozone.png",
    "last_modified": "2021-02-09T14:41:01+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-06-post-model-selection-inference/",
    "title": "Post Model Selection Inference",
    "description": "Or the near impossibility of frequentist inference with algorithmic models",
    "author": [
      {
        "name": "Amit Gandhi",
        "url": {}
      }
    ],
    "date": "2021-02-06",
    "categories": [],
    "contents": "\n\n\n\nSuppose we have tuned our model on training data using a re-sampling procedure such as cross validation. We now have a model we can use for prediction, as well as an estimate of its predictive performance in the form of its expected test error \\(Err\\).\nUnfortunately the selected model \\(\\hat{f}(x; \\hat{\\eta})\\) which is fit to the training data \\(D\\) on the basis of the tuned parameters \\(\\hat{\\eta}\\) is invalidates inference in the traditional sense using the training data \\(D\\).\nAnother way to state the situation is that with algorithmic model combined with cross validation, you have been handed a bazooka - quite powerful at automatically deconstructing large and complex data. However before firing the trigger, it is critical to read the user manual as to the appropriate way to apply for data you might have in hand.\nLet us observe how this happens. First let us build a list of design matrices for the linear model, where the length of the list corresponds to the number of simulation runs nSim. Each design matrix will correspond to a data set of nData observations, and consist of p predictors. We will use the map function to build the list (and thus availing ourselves of the purr package and its functional programming capabilities.)\n\n\nset.seed(1234)\nnSim <- 500\np <- 50\nnData <- 100\n\n# Generate design matrices for each simulation run\nxDat <- map(1:nSim, ~mvrnorm(nData, rnorm(p), Sigma = diag(p) ) )\ntypeof(xDat)\n\n\n[1] \"list\"\n\nlength(xDat)\n\n\n[1] 500\n\nWe now build a data frame (in the form of a tibble) that contains a list column corresponding to the design matrix from each simulation run.\n\n\nsimData <- tibble(run = 1:nSim, xDat = xDat)\npaged_table(simData)\n\n\n\n\n{\"columns\":[{\"label\":[\"run\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"xDat\"],\"name\":[2],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"2\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"3\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"4\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"5\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"6\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"7\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"8\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"9\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"10\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"11\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"12\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"13\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"14\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"15\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"16\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"17\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"18\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"19\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"20\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"21\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"22\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"23\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"24\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"25\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"26\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"27\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"28\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"29\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"30\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"31\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"32\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"33\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"34\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"35\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"36\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"37\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"38\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"39\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"40\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"41\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"42\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"43\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"44\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"45\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"46\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"47\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"48\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"49\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"50\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"51\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"52\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"53\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"54\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"55\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"56\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"57\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"58\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"59\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"60\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"61\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"62\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"63\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"64\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"65\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"66\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"67\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"68\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"69\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"70\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"71\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"72\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"73\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"74\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"75\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"76\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"77\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"78\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"79\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"80\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"81\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"82\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"83\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"84\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"85\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"86\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"87\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"88\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"89\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"90\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"91\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"92\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"93\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"94\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"95\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"96\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"97\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"98\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"99\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"100\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"101\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"102\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"103\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"104\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"105\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"106\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"107\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"108\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"109\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"110\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"111\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"112\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"113\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"114\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"115\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"116\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"117\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"118\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"119\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"120\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"121\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"122\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"123\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"124\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"125\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"126\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"127\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"128\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"129\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"130\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"131\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"132\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"133\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"134\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"135\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"136\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"137\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"138\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"139\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"140\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"141\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"142\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"143\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"144\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"145\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"146\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"147\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"148\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"149\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"150\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"151\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"152\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"153\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"154\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"155\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"156\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"157\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"158\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"159\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"160\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"161\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"162\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"163\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"164\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"165\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"166\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"167\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"168\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"169\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"170\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"171\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"172\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"173\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"174\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"175\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"176\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"177\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"178\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"179\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"180\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"181\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"182\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"183\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"184\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"185\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"186\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"187\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"188\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"189\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"190\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"191\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"192\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"193\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"194\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"195\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"196\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"197\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"198\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"199\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"200\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"201\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"202\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"203\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"204\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"205\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"206\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"207\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"208\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"209\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"210\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"211\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"212\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"213\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"214\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"215\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"216\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"217\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"218\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"219\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"220\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"221\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"222\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"223\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"224\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"225\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"226\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"227\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"228\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"229\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"230\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"231\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"232\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"233\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"234\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"235\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"236\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"237\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"238\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"239\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"240\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"241\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"242\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"243\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"244\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"245\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"246\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"247\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"248\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"249\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"250\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"251\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"252\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"253\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"254\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"255\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"256\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"257\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"258\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"259\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"260\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"261\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"262\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"263\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"264\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"265\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"266\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"267\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"268\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"269\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"270\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"271\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"272\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"273\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"274\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"275\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"276\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"277\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"278\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"279\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"280\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"281\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"282\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"283\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"284\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"285\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"286\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"287\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"288\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"289\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"290\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"291\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"292\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"293\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"294\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"295\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"296\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"297\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"298\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"299\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"300\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"301\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"302\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"303\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"304\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"305\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"306\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"307\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"308\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"309\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"310\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"311\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"312\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"313\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"314\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"315\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"316\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"317\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"318\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"319\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"320\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"321\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"322\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"323\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"324\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"325\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"326\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"327\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"328\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"329\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"330\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"331\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"332\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"333\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"334\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"335\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"336\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"337\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"338\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"339\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"340\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"341\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"342\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"343\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"344\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"345\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"346\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"347\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"348\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"349\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"350\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"351\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"352\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"353\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"354\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"355\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"356\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"357\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"358\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"359\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"360\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"361\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"362\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"363\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"364\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"365\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"366\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"367\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"368\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"369\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"370\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"371\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"372\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"373\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"374\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"375\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"376\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"377\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"378\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"379\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"380\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"381\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"382\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"383\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"384\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"385\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"386\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"387\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"388\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"389\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"390\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"391\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"392\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"393\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"394\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"395\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"396\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"397\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"398\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"399\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"400\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"401\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"402\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"403\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"404\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"405\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"406\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"407\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"408\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"409\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"410\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"411\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"412\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"413\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"414\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"415\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"416\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"417\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"418\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"419\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"420\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"421\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"422\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"423\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"424\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"425\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"426\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"427\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"428\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"429\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"430\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"431\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"432\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"433\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"434\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"435\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"436\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"437\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"438\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"439\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"440\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"441\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"442\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"443\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"444\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"445\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"446\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"447\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"448\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"449\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"450\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"451\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"452\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"453\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"454\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"455\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"456\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"457\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"458\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"459\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"460\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"461\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"462\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"463\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"464\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"465\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"466\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"467\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"468\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"469\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"470\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"471\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"472\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"473\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"474\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"475\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"476\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"477\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"478\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"479\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"480\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"481\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"482\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"483\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"484\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"485\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"486\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"487\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"488\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"489\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"490\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"491\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"492\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"493\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"494\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"495\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"496\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"497\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"498\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"499\",\"2\":\"<dbl[,50] [100 × 50]>\"},{\"1\":\"500\",\"2\":\"<dbl[,50] [100 × 50]>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nNow we add the \\(Y\\) outcome associated to each design matrix, where we assume the null hypothesis is true.\n\n\nsimData <- \n  simData %>% \n  mutate(yDat = map(xDat, ~(.x %*% rep(0,p)) + rnorm(nData)  %>% drop() ) )\n\npaged_table(simData)\n\n\n\n\n{\"columns\":[{\"label\":[\"run\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"xDat\"],\"name\":[2],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"yDat\"],\"name\":[3],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"2\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"3\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"4\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"5\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"6\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"7\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"8\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"9\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"10\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"11\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"12\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"13\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"14\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"15\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"16\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"17\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"18\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"19\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"20\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"21\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"22\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"23\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"24\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"25\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"26\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"27\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"28\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"29\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"30\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"31\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"32\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"33\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"34\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"35\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"36\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"37\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"38\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"39\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"40\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"41\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"42\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"43\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"44\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"45\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"46\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"47\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"48\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"49\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"50\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"51\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"52\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"53\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"54\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"55\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"56\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"57\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"58\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"59\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"60\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"61\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"62\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"63\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"64\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"65\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"66\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"67\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"68\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"69\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"70\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"71\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"72\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"73\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"74\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"75\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"76\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"77\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"78\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"79\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"80\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"81\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"82\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"83\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"84\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"85\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"86\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"87\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"88\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"89\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"90\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"91\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"92\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"93\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"94\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"95\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"96\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"97\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"98\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"99\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"100\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"101\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"102\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"103\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"104\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"105\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"106\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"107\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"108\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"109\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"110\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"111\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"112\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"113\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"114\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"115\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"116\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"117\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"118\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"119\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"120\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"121\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"122\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"123\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"124\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"125\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"126\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"127\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"128\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"129\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"130\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"131\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"132\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"133\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"134\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"135\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"136\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"137\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"138\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"139\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"140\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"141\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"142\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"143\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"144\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"145\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"146\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"147\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"148\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"149\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"150\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"151\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"152\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"153\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"154\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"155\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"156\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"157\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"158\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"159\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"160\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"161\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"162\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"163\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"164\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"165\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"166\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"167\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"168\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"169\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"170\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"171\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"172\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"173\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"174\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"175\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"176\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"177\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"178\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"179\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"180\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"181\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"182\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"183\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"184\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"185\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"186\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"187\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"188\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"189\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"190\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"191\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"192\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"193\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"194\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"195\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"196\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"197\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"198\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"199\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"200\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"201\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"202\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"203\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"204\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"205\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"206\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"207\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"208\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"209\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"210\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"211\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"212\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"213\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"214\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"215\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"216\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"217\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"218\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"219\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"220\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"221\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"222\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"223\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"224\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"225\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"226\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"227\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"228\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"229\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"230\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"231\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"232\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"233\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"234\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"235\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"236\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"237\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"238\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"239\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"240\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"241\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"242\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"243\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"244\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"245\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"246\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"247\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"248\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"249\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"250\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"251\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"252\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"253\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"254\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"255\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"256\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"257\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"258\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"259\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"260\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"261\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"262\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"263\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"264\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"265\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"266\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"267\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"268\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"269\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"270\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"271\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"272\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"273\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"274\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"275\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"276\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"277\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"278\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"279\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"280\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"281\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"282\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"283\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"284\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"285\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"286\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"287\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"288\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"289\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"290\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"291\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"292\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"293\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"294\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"295\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"296\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"297\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"298\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"299\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"300\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"301\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"302\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"303\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"304\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"305\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"306\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"307\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"308\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"309\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"310\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"311\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"312\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"313\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"314\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"315\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"316\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"317\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"318\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"319\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"320\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"321\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"322\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"323\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"324\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"325\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"326\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"327\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"328\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"329\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"330\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"331\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"332\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"333\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"334\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"335\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"336\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"337\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"338\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"339\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"340\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"341\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"342\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"343\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"344\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"345\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"346\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"347\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"348\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"349\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"350\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"351\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"352\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"353\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"354\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"355\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"356\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"357\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"358\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"359\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"360\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"361\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"362\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"363\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"364\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"365\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"366\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"367\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"368\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"369\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"370\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"371\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"372\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"373\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"374\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"375\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"376\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"377\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"378\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"379\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"380\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"381\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"382\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"383\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"384\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"385\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"386\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"387\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"388\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"389\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"390\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"391\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"392\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"393\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"394\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"395\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"396\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"397\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"398\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"399\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"400\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"401\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"402\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"403\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"404\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"405\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"406\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"407\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"408\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"409\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"410\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"411\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"412\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"413\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"414\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"415\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"416\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"417\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"418\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"419\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"420\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"421\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"422\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"423\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"424\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"425\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"426\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"427\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"428\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"429\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"430\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"431\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"432\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"433\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"434\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"435\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"436\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"437\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"438\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"439\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"440\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"441\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"442\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"443\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"444\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"445\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"446\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"447\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"448\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"449\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"450\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"451\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"452\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"453\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"454\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"455\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"456\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"457\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"458\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"459\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"460\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"461\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"462\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"463\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"464\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"465\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"466\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"467\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"468\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"469\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"470\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"471\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"472\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"473\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"474\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"475\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"476\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"477\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"478\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"479\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"480\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"481\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"482\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"483\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"484\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"485\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"486\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"487\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"488\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"489\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"490\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"491\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"492\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"493\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"494\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"495\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"496\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"497\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"498\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"499\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"},{\"1\":\"500\",\"2\":\"<dbl[,50] [100 × 50]>\",\"3\":\"<dbl[,1] [100 × 1]>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nNow suppose we want to isolate the best subset regression based on an estimate of its (expected) predictive accuracy. We can use the regsubsets() function from the leaps package.\nWe want to create a data set of predictors and outcome for each run in the form of its own tibble\n\n\nsimData <- \n  simData %>% \n  mutate(xyDat = map2(xDat, yDat, \n                      ~bind_cols( tibble(y =.y), as_tibble(.x))),\n         .keep = \"unused\" )\n\npaged_table(simData)\n\n\n\n\n{\"columns\":[{\"label\":[\"run\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"xyDat\"],\"name\":[2],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"2\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"3\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"4\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"5\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"6\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"7\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"8\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"9\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"10\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"11\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"12\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"13\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"14\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"15\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"16\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"17\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"18\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"19\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"20\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"21\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"22\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"23\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"24\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"25\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"26\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"27\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"28\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"29\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"30\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"31\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"32\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"33\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"34\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"35\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"36\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"37\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"38\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"39\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"40\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"41\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"42\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"43\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"44\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"45\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"46\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"47\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"48\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"49\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"50\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"51\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"52\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"53\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"54\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"55\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"56\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"57\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"58\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"59\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"60\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"61\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"62\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"63\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"64\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"65\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"66\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"67\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"68\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"69\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"70\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"71\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"72\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"73\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"74\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"75\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"76\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"77\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"78\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"79\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"80\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"81\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"82\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"83\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"84\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"85\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"86\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"87\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"88\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"89\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"90\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"91\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"92\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"93\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"94\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"95\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"96\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"97\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"98\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"99\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"100\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"101\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"102\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"103\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"104\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"105\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"106\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"107\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"108\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"109\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"110\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"111\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"112\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"113\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"114\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"115\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"116\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"117\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"118\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"119\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"120\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"121\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"122\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"123\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"124\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"125\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"126\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"127\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"128\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"129\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"130\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"131\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"132\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"133\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"134\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"135\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"136\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"137\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"138\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"139\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"140\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"141\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"142\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"143\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"144\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"145\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"146\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"147\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"148\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"149\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"150\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"151\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"152\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"153\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"154\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"155\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"156\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"157\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"158\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"159\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"160\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"161\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"162\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"163\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"164\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"165\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"166\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"167\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"168\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"169\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"170\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"171\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"172\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"173\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"174\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"175\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"176\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"177\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"178\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"179\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"180\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"181\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"182\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"183\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"184\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"185\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"186\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"187\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"188\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"189\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"190\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"191\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"192\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"193\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"194\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"195\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"196\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"197\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"198\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"199\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"200\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"201\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"202\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"203\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"204\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"205\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"206\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"207\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"208\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"209\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"210\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"211\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"212\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"213\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"214\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"215\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"216\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"217\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"218\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"219\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"220\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"221\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"222\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"223\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"224\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"225\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"226\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"227\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"228\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"229\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"230\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"231\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"232\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"233\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"234\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"235\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"236\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"237\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"238\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"239\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"240\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"241\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"242\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"243\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"244\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"245\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"246\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"247\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"248\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"249\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"250\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"251\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"252\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"253\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"254\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"255\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"256\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"257\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"258\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"259\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"260\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"261\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"262\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"263\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"264\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"265\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"266\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"267\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"268\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"269\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"270\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"271\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"272\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"273\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"274\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"275\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"276\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"277\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"278\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"279\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"280\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"281\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"282\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"283\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"284\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"285\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"286\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"287\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"288\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"289\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"290\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"291\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"292\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"293\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"294\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"295\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"296\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"297\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"298\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"299\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"300\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"301\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"302\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"303\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"304\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"305\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"306\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"307\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"308\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"309\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"310\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"311\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"312\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"313\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"314\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"315\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"316\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"317\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"318\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"319\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"320\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"321\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"322\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"323\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"324\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"325\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"326\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"327\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"328\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"329\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"330\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"331\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"332\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"333\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"334\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"335\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"336\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"337\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"338\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"339\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"340\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"341\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"342\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"343\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"344\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"345\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"346\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"347\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"348\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"349\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"350\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"351\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"352\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"353\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"354\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"355\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"356\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"357\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"358\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"359\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"360\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"361\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"362\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"363\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"364\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"365\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"366\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"367\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"368\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"369\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"370\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"371\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"372\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"373\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"374\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"375\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"376\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"377\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"378\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"379\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"380\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"381\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"382\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"383\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"384\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"385\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"386\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"387\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"388\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"389\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"390\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"391\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"392\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"393\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"394\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"395\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"396\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"397\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"398\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"399\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"400\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"401\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"402\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"403\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"404\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"405\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"406\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"407\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"408\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"409\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"410\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"411\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"412\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"413\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"414\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"415\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"416\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"417\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"418\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"419\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"420\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"421\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"422\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"423\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"424\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"425\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"426\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"427\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"428\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"429\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"430\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"431\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"432\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"433\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"434\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"435\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"436\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"437\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"438\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"439\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"440\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"441\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"442\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"443\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"444\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"445\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"446\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"447\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"448\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"449\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"450\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"451\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"452\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"453\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"454\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"455\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"456\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"457\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"458\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"459\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"460\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"461\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"462\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"463\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"464\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"465\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"466\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"467\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"468\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"469\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"470\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"471\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"472\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"473\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"474\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"475\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"476\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"477\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"478\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"479\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"480\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"481\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"482\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"483\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"484\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"485\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"486\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"487\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"488\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"489\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"490\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"491\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"492\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"493\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"494\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"495\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"496\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"497\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"498\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"499\",\"2\":\"<tbl_df[,51]>\"},{\"1\":\"500\",\"2\":\"<tbl_df[,51]>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nWe can examine a single dataset to expose its structure\n\n\ndat <- simData$xyDat[[1]]\npaged_table(dat)\n\n\n\n\n{\"columns\":[{\"label\":[\"y\"],\"name\":[1],\"type\":[\"dbl[,1]\"],\"align\":[\"right\"]},{\"label\":[\"V1\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V2\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V3\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V4\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V5\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V6\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V7\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V8\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V9\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V10\"],\"name\":[11],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V11\"],\"name\":[12],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V12\"],\"name\":[13],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V13\"],\"name\":[14],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V14\"],\"name\":[15],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V15\"],\"name\":[16],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V16\"],\"name\":[17],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V17\"],\"name\":[18],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V18\"],\"name\":[19],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V19\"],\"name\":[20],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V20\"],\"name\":[21],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V21\"],\"name\":[22],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V22\"],\"name\":[23],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V23\"],\"name\":[24],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V24\"],\"name\":[25],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V25\"],\"name\":[26],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V26\"],\"name\":[27],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V27\"],\"name\":[28],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V28\"],\"name\":[29],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V29\"],\"name\":[30],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V30\"],\"name\":[31],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V31\"],\"name\":[32],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V32\"],\"name\":[33],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V33\"],\"name\":[34],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V34\"],\"name\":[35],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V35\"],\"name\":[36],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V36\"],\"name\":[37],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V37\"],\"name\":[38],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V38\"],\"name\":[39],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V39\"],\"name\":[40],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V40\"],\"name\":[41],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V41\"],\"name\":[42],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V42\"],\"name\":[43],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V43\"],\"name\":[44],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V44\"],\"name\":[45],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V45\"],\"name\":[46],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V46\"],\"name\":[47],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V47\"],\"name\":[48],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V48\"],\"name\":[49],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V49\"],\"name\":[50],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"V50\"],\"name\":[51],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.7546760583\",\"2\":\"0.39641068\",\"3\":\"0.71285854\",\"4\":\"0.09210351\",\"5\":\"-1.6280431\",\"6\":\"0.822509702\",\"7\":\"0.33086689\",\"8\":\"-1.95835723\",\"9\":\"-0.51914050\",\"10\":\"0.07174520\",\"11\":\"0.23096740\",\"12\":\"0.36850713\",\"13\":\"0.946463498\",\"14\":\"-2.40984715\",\"15\":\"0.66889889\",\"16\":\"3.11020240\",\"17\":\"-0.189590687\",\"18\":\"1.84244228\",\"19\":\"-0.45150299\",\"20\":\"1.33286547\",\"21\":\"1.9399165\",\"22\":\"1.56697236\",\"23\":\"0.59019870\",\"24\":\"-0.03131336\",\"25\":\"1.373075996\",\"26\":\"-1.784054940\",\"27\":\"0.45104763\",\"28\":\"-0.56249843\",\"29\":\"0.29965408\",\"30\":\"-0.290299314\",\"31\":\"-0.844824595\",\"32\":\"-1.168138153\",\"33\":\"-0.02506182\",\"34\":\"1.19430718\",\"35\":\"-0.806588200\",\"36\":\"-3.63650849\",\"37\":\"-0.30866714\",\"38\":\"-1.9847186\",\"39\":\"0.34436343\",\"40\":\"-0.670483513\",\"41\":\"-0.68131141\",\"42\":\"0.70279646\",\"43\":\"-1.210519668\",\"44\":\"-0.95433784\",\"45\":\"-0.92939135\",\"46\":\"-2.38433289\",\"47\":\"-0.60584736\",\"48\":\"-3.423354344\",\"49\":\"-0.81505531\",\"50\":\"-0.90106577\",\"51\":\"-2.302881214\"},{\"1\":\"0.1175242040\",\"2\":\"-0.37176487\",\"3\":\"-0.25670865\",\"4\":\"2.12380924\",\"5\":\"-2.7443584\",\"6\":\"0.267417358\",\"7\":\"-1.14109191\",\"8\":\"-0.33793165\",\"9\":\"-0.13157503\",\"10\":\"-1.23189703\",\"11\":\"-0.66273585\",\"12\":\"0.12421791\",\"13\":\"-2.195129614\",\"14\":\"-0.16638768\",\"15\":\"-1.13563850\",\"16\":\"0.70592241\",\"17\":\"0.573506463\",\"18\":\"-2.55970988\",\"19\":\"-0.20280745\",\"20\":\"-0.55239290\",\"21\":\"1.2196385\",\"22\":\"0.55240560\",\"23\":\"-0.49641753\",\"24\":\"-2.21387127\",\"25\":\"0.401553421\",\"26\":\"-1.361309584\",\"27\":\"-0.62421900\",\"28\":\"-0.11763510\",\"29\":\"0.45821782\",\"30\":\"0.336634258\",\"31\":\"0.810896705\",\"32\":\"0.128844877\",\"33\":\"-0.20079940\",\"34\":\"-0.77806157\",\"35\":\"-0.764124898\",\"36\":\"-0.86109134\",\"37\":\"-1.58953173\",\"38\":\"-2.1085770\",\"39\":\"-1.48081930\",\"40\":\"-1.277703273\",\"41\":\"0.02430913\",\"42\":\"1.66027768\",\"43\":\"-0.610660946\",\"44\":\"-0.75166809\",\"45\":\"-0.92463086\",\"46\":\"-2.12401793\",\"47\":\"0.44289033\",\"48\":\"-0.544846436\",\"49\":\"-0.19186198\",\"50\":\"-0.42620866\",\"51\":\"-1.078925882\"},{\"1\":\"-0.3580003262\",\"2\":\"-1.31070913\",\"3\":\"1.22066860\",\"4\":\"1.14428390\",\"5\":\"-1.3176917\",\"6\":\"-0.441464375\",\"7\":\"-0.82601701\",\"8\":\"0.53806404\",\"9\":\"0.63087461\",\"10\":\"-1.18665589\",\"11\":\"-0.58769486\",\"12\":\"-1.12701271\",\"13\":\"-0.339215602\",\"14\":\"-0.13735418\",\"15\":\"1.12284496\",\"16\":\"-0.50154278\",\"17\":\"0.659673195\",\"18\":\"-1.41458250\",\"19\":\"-1.14600502\",\"20\":\"-0.91438792\",\"21\":\"-0.4800919\",\"22\":\"0.40209736\",\"23\":\"-0.03689184\",\"24\":\"-1.10520303\",\"25\":\"1.339087543\",\"26\":\"0.600983040\",\"27\":\"0.12492728\",\"28\":\"1.06821311\",\"29\":\"-1.52013456\",\"30\":\"-1.679991412\",\"31\":\"-0.903496418\",\"32\":\"1.723487805\",\"33\":\"0.58078334\",\"34\":\"-1.52329918\",\"35\":\"-0.552726705\",\"36\":\"-1.22333216\",\"37\":\"-1.47310815\",\"38\":\"-0.5451064\",\"39\":\"-1.21985444\",\"40\":\"0.095601242\",\"41\":\"-0.40650412\",\"42\":\"0.60098646\",\"43\":\"-2.588260237\",\"44\":\"0.35312024\",\"45\":\"-0.48506183\",\"46\":\"-2.13549427\",\"47\":\"0.39903000\",\"48\":\"-1.891093332\",\"49\":\"-0.79979549\",\"50\":\"1.11491653\",\"51\":\"-1.605739582\"},{\"1\":\"1.5284714118\",\"2\":\"-1.29430708\",\"3\":\"0.57926470\",\"4\":\"-0.06489788\",\"5\":\"-1.8121685\",\"6\":\"-0.937661715\",\"7\":\"-0.50362466\",\"8\":\"-0.70763840\",\"9\":\"-0.68016392\",\"10\":\"-0.15870644\",\"11\":\"0.42623451\",\"12\":\"0.65796627\",\"13\":\"-1.775245421\",\"14\":\"0.92678281\",\"15\":\"0.36602113\",\"16\":\"0.05785950\",\"17\":\"-0.466673719\",\"18\":\"0.30598336\",\"19\":\"-0.56144420\",\"20\":\"-1.34531494\",\"21\":\"3.3487699\",\"22\":\"0.51814049\",\"23\":\"0.23793681\",\"24\":\"-0.34897642\",\"25\":\"0.544831041\",\"26\":\"-0.785059695\",\"27\":\"-2.76213695\",\"28\":\"1.41975729\",\"29\":\"0.11429811\",\"30\":\"0.171793852\",\"31\":\"-1.447381317\",\"32\":\"1.764859218\",\"33\":\"1.31646120\",\"34\":\"-1.38269535\",\"35\":\"-2.473921420\",\"36\":\"-2.46080935\",\"37\":\"-1.22680728\",\"38\":\"-1.8470326\",\"39\":\"-1.44667237\",\"40\":\"-0.312244573\",\"41\":\"-0.40758549\",\"42\":\"2.24176103\",\"43\":\"0.330412591\",\"44\":\"-0.76161861\",\"45\":\"0.21021792\",\"46\":\"-1.68301158\",\"47\":\"-1.37569046\",\"48\":\"-1.333372179\",\"49\":\"-0.58878727\",\"50\":\"-1.39942059\",\"51\":\"-1.511811967\"},{\"1\":\"0.0617263985\",\"2\":\"-3.02949629\",\"3\":\"0.33487473\",\"4\":\"-0.78611023\",\"5\":\"-0.3623193\",\"6\":\"0.829693222\",\"7\":\"0.73356873\",\"8\":\"-0.56389060\",\"9\":\"1.82899687\",\"10\":\"0.39457327\",\"11\":\"-1.55649662\",\"12\":\"-0.63739783\",\"13\":\"-1.209533728\",\"14\":\"-2.45721112\",\"15\":\"0.14227088\",\"16\":\"0.66899116\",\"17\":\"-1.379473529\",\"18\":\"-0.61387797\",\"19\":\"-0.32213964\",\"20\":\"-0.72844395\",\"21\":\"2.5967988\",\"22\":\"-1.69307126\",\"23\":\"0.58179042\",\"24\":\"-1.13596737\",\"25\":\"1.613752916\",\"26\":\"-0.023777041\",\"27\":\"-0.33352777\",\"28\":\"3.42258077\",\"29\":\"-0.98254884\",\"30\":\"1.887689196\",\"31\":\"0.228856637\",\"32\":\"0.451307297\",\"33\":\"1.23522614\",\"34\":\"0.69259043\",\"35\":\"-0.490029810\",\"36\":\"-0.67101770\",\"37\":\"-3.16949145\",\"38\":\"-0.7782270\",\"39\":\"-0.49468830\",\"40\":\"0.497430746\",\"41\":\"1.37246557\",\"42\":\"1.47868370\",\"43\":\"-1.953981915\",\"44\":\"-1.60756115\",\"45\":\"-0.48595999\",\"46\":\"-0.82414226\",\"47\":\"-0.20597259\",\"48\":\"-2.694421180\",\"49\":\"-2.38835944\",\"50\":\"-0.40206812\",\"51\":\"-0.659159481\"},{\"1\":\"-0.5987337036\",\"2\":\"-0.68646358\",\"3\":\"1.45566264\",\"4\":\"1.54656579\",\"5\":\"-3.5464348\",\"6\":\"-0.935724803\",\"7\":\"-0.28383568\",\"8\":\"-1.72257515\",\"9\":\"-1.50102408\",\"10\":\"-1.51740895\",\"11\":\"-1.58317067\",\"12\":\"-0.73354035\",\"13\":\"-2.315577417\",\"14\":\"-0.47041006\",\"15\":\"0.62676789\",\"16\":\"1.50954147\",\"17\":\"-1.286749028\",\"18\":\"0.37876796\",\"19\":\"-0.84761621\",\"20\":\"-0.41507797\",\"21\":\"2.7918702\",\"22\":\"-0.84565143\",\"23\":\"1.14845248\",\"24\":\"-1.66046993\",\"25\":\"1.276234616\",\"26\":\"-0.782552317\",\"27\":\"-2.05619336\",\"28\":\"1.07715176\",\"29\":\"0.78872927\",\"30\":\"-1.533914025\",\"31\":\"-1.401225943\",\"32\":\"0.893560478\",\"33\":\"-0.90702201\",\"34\":\"-0.16942343\",\"35\":\"-0.265913203\",\"36\":\"0.18162578\",\"37\":\"-1.01218284\",\"38\":\"-1.7290226\",\"39\":\"-2.10944222\",\"40\":\"1.498104017\",\"41\":\"-0.07824664\",\"42\":\"2.05288428\",\"43\":\"-1.574973015\",\"44\":\"-0.46044041\",\"45\":\"-0.08993168\",\"46\":\"-0.39985665\",\"47\":\"-1.61971514\",\"48\":\"-0.559793991\",\"49\":\"-1.62248340\",\"50\":\"0.83830254\",\"51\":\"0.066205862\"},{\"1\":\"-1.2989686716\",\"2\":\"-0.54861521\",\"3\":\"0.57188616\",\"4\":\"1.37096264\",\"5\":\"-2.7601718\",\"6\":\"2.924648421\",\"7\":\"1.44970396\",\"8\":\"0.70385544\",\"9\":\"0.04584542\",\"10\":\"0.61381223\",\"11\":\"-1.42478416\",\"12\":\"-0.87757557\",\"13\":\"-0.951531121\",\"14\":\"-0.89771794\",\"15\":\"0.31100772\",\"16\":\"0.72875405\",\"17\":\"-0.943599967\",\"18\":\"-1.60262506\",\"19\":\"-2.25219504\",\"20\":\"0.70505206\",\"21\":\"2.5893149\",\"22\":\"-0.52325189\",\"23\":\"-0.35846960\",\"24\":\"1.44031206\",\"25\":\"0.975958219\",\"26\":\"0.257507721\",\"27\":\"-0.58129386\",\"28\":\"0.28014579\",\"29\":\"-0.68889838\",\"30\":\"1.315388332\",\"31\":\"-1.166578650\",\"32\":\"2.899209193\",\"33\":\"-0.55486994\",\"34\":\"-0.06716587\",\"35\":\"-1.451627914\",\"36\":\"-4.17910795\",\"37\":\"-1.12505703\",\"38\":\"-1.6927161\",\"39\":\"-1.13953079\",\"40\":\"0.742423026\",\"41\":\"-0.74644827\",\"42\":\"0.45455616\",\"43\":\"-0.905310618\",\"44\":\"-1.94688507\",\"45\":\"0.68940119\",\"46\":\"-1.80937273\",\"47\":\"-2.44217010\",\"48\":\"0.783908825\",\"49\":\"0.22498370\",\"50\":\"-0.75844921\",\"51\":\"1.150967516\"},{\"1\":\"0.6758499238\",\"2\":\"0.32768130\",\"3\":\"1.42269228\",\"4\":\"2.16632561\",\"5\":\"-1.8945612\",\"6\":\"-0.410568186\",\"7\":\"0.85231686\",\"8\":\"-0.08549619\",\"9\":\"0.66357674\",\"10\":\"-0.57995524\",\"11\":\"-0.76022524\",\"12\":\"-0.35754136\",\"13\":\"-2.386616976\",\"14\":\"0.46605771\",\"15\":\"-0.47004318\",\"16\":\"0.07147300\",\"17\":\"0.124484877\",\"18\":\"-0.04667044\",\"19\":\"-0.39530283\",\"20\":\"-0.26198994\",\"21\":\"2.3374746\",\"22\":\"-0.04871546\",\"23\":\"-0.46186717\",\"24\":\"-0.22527462\",\"25\":\"1.178893693\",\"26\":\"-2.509879884\",\"27\":\"-3.39165525\",\"28\":\"-0.42990294\",\"29\":\"-0.33777204\",\"30\":\"1.036462187\",\"31\":\"-0.080139449\",\"32\":\"0.003519131\",\"33\":\"-0.83881812\",\"34\":\"-0.72215980\",\"35\":\"-2.258406036\",\"36\":\"-0.47883839\",\"37\":\"-1.42965846\",\"38\":\"-2.7197771\",\"39\":\"-0.76642359\",\"40\":\"-0.989979474\",\"41\":\"-0.89441528\",\"42\":\"1.23816381\",\"43\":\"-1.405786580\",\"44\":\"-2.31365706\",\"45\":\"-0.56588408\",\"46\":\"-3.85868691\",\"47\":\"-2.17018011\",\"48\":\"-1.985395303\",\"49\":\"-2.47588964\",\"50\":\"-1.57721093\",\"51\":\"-1.270203381\"},{\"1\":\"0.6247379672\",\"2\":\"-1.81591884\",\"3\":\"0.12324656\",\"4\":\"2.17578958\",\"5\":\"-2.6081483\",\"6\":\"1.383346871\",\"7\":\"1.86982229\",\"8\":\"-1.45634893\",\"9\":\"-1.79551550\",\"10\":\"1.12591709\",\"11\":\"-0.67815858\",\"12\":\"-1.05606449\",\"13\":\"-1.692370637\",\"14\":\"-0.59613614\",\"15\":\"-1.10559973\",\"16\":\"-0.12657098\",\"17\":\"-0.858182447\",\"18\":\"-0.37732341\",\"19\":\"-1.49295021\",\"20\":\"-2.17796462\",\"21\":\"3.5024798\",\"22\":\"0.49859665\",\"23\":\"-2.49132026\",\"24\":\"1.55107749\",\"25\":\"-1.374121918\",\"26\":\"-1.161735382\",\"27\":\"-0.46403901\",\"28\":\"0.97991363\",\"29\":\"-0.64011627\",\"30\":\"1.039983372\",\"31\":\"0.843195731\",\"32\":\"2.880039638\",\"33\":\"-0.67658355\",\"34\":\"-0.52656048\",\"35\":\"-0.861218712\",\"36\":\"-0.40119981\",\"37\":\"-2.18881252\",\"38\":\"0.5108678\",\"39\":\"-2.58623308\",\"40\":\"-0.154671194\",\"41\":\"-0.37057260\",\"42\":\"1.79351735\",\"43\":\"-2.104594256\",\"44\":\"-0.97807692\",\"45\":\"-0.38424227\",\"46\":\"-0.04051659\",\"47\":\"-1.11723480\",\"48\":\"-1.219877104\",\"49\":\"-0.99391750\",\"50\":\"-1.39361172\",\"51\":\"1.109059672\"},{\"1\":\"-0.7278296023\",\"2\":\"-2.45709153\",\"3\":\"0.91390543\",\"4\":\"3.34213958\",\"5\":\"-1.3252710\",\"6\":\"1.679818124\",\"7\":\"1.61088035\",\"8\":\"0.18630401\",\"9\":\"-1.99971815\",\"10\":\"1.64408530\",\"11\":\"-0.77058462\",\"12\":\"-2.42140642\",\"13\":\"-1.007235257\",\"14\":\"-2.01108663\",\"15\":\"0.20331659\",\"16\":\"1.63832410\",\"17\":\"-0.008171054\",\"18\":\"-0.39098571\",\"19\":\"-2.22738798\",\"20\":\"-2.03323685\",\"21\":\"2.8579357\",\"22\":\"1.36888476\",\"23\":\"0.28978376\",\"24\":\"-1.11314344\",\"25\":\"0.351943171\",\"26\":\"-0.779104822\",\"27\":\"-1.75039086\",\"28\":\"1.50247141\",\"29\":\"-0.20597014\",\"30\":\"1.416268664\",\"31\":\"-1.761291317\",\"32\":\"1.419241954\",\"33\":\"-0.02431115\",\"34\":\"-1.19795462\",\"35\":\"-3.622847619\",\"36\":\"-1.47699031\",\"37\":\"-0.10226216\",\"38\":\"-2.2398557\",\"39\":\"-1.11327438\",\"40\":\"1.118951635\",\"41\":\"-1.27922895\",\"42\":\"1.36011774\",\"43\":\"-0.659304795\",\"44\":\"-1.95629383\",\"45\":\"0.23063154\",\"46\":\"-0.37905531\",\"47\":\"0.82854811\",\"48\":\"0.841394872\",\"49\":\"-0.84698308\",\"50\":\"-0.91395515\",\"51\":\"-1.654658505\"},{\"1\":\"1.2103163924\",\"2\":\"-1.15663196\",\"3\":\"1.18820311\",\"4\":\"-0.20258544\",\"5\":\"-2.7797302\",\"6\":\"1.494873642\",\"7\":\"0.60793824\",\"8\":\"-1.17410131\",\"9\":\"-1.48774625\",\"10\":\"0.61824581\",\"11\":\"0.63240284\",\"12\":\"-1.49023064\",\"13\":\"-1.729176199\",\"14\":\"-1.47190012\",\"15\":\"-0.44361776\",\"16\":\"0.83587433\",\"17\":\"1.072055366\",\"18\":\"0.76041904\",\"19\":\"-0.25282789\",\"20\":\"-2.39876989\",\"21\":\"3.1635474\",\"22\":\"1.70612644\",\"23\":\"-0.62654022\",\"24\":\"-0.93167716\",\"25\":\"0.075156134\",\"26\":\"-0.316800748\",\"27\":\"-1.63453669\",\"28\":\"0.14673819\",\"29\":\"-0.63951471\",\"30\":\"0.005508705\",\"31\":\"-1.164828554\",\"32\":\"2.151873968\",\"33\":\"-0.95553506\",\"34\":\"0.42579670\",\"35\":\"1.171289052\",\"36\":\"-2.15217728\",\"37\":\"-1.62521010\",\"38\":\"-2.6775155\",\"39\":\"-1.93479525\",\"40\":\"0.880143738\",\"41\":\"0.90229254\",\"42\":\"3.10353373\",\"43\":\"-1.592866182\",\"44\":\"-0.27444156\",\"45\":\"-1.53878545\",\"46\":\"-1.69521078\",\"47\":\"-0.86370560\",\"48\":\"-0.173501860\",\"49\":\"-0.27618256\",\"50\":\"-1.37117819\",\"51\":\"0.159738507\"},{\"1\":\"0.3815026169\",\"2\":\"-2.02408327\",\"3\":\"-0.38537701\",\"4\":\"-0.13636186\",\"5\":\"-2.6816386\",\"6\":\"1.588567056\",\"7\":\"0.20447026\",\"8\":\"0.69802964\",\"9\":\"-1.96805270\",\"10\":\"-0.38112852\",\"11\":\"-0.88399459\",\"12\":\"-0.32180301\",\"13\":\"-0.992179835\",\"14\":\"-0.21723634\",\"15\":\"0.68132806\",\"16\":\"1.24811187\",\"17\":\"-0.585686600\",\"18\":\"-1.03796504\",\"19\":\"0.56335538\",\"20\":\"0.22562205\",\"21\":\"2.4180528\",\"22\":\"0.17106162\",\"23\":\"-1.89169324\",\"24\":\"1.50646653\",\"25\":\"-1.095527439\",\"26\":\"-0.924227278\",\"27\":\"-0.12369172\",\"28\":\"0.84207001\",\"29\":\"-1.47206008\",\"30\":\"0.186196588\",\"31\":\"-1.004985919\",\"32\":\"0.576016761\",\"33\":\"-1.64111826\",\"34\":\"-1.03549106\",\"35\":\"0.189291756\",\"36\":\"-2.73068683\",\"37\":\"-1.03231535\",\"38\":\"-1.7976225\",\"39\":\"0.08781759\",\"40\":\"-1.879075441\",\"41\":\"-0.75343357\",\"42\":\"-0.51341245\",\"43\":\"-0.562142350\",\"44\":\"-1.00231212\",\"45\":\"0.26320297\",\"46\":\"-2.06800142\",\"47\":\"-1.77135229\",\"48\":\"0.805741229\",\"49\":\"-1.60086262\",\"50\":\"-0.78446751\",\"51\":\"2.052141113\"},{\"1\":\"-0.2215212161\",\"2\":\"-2.41222666\",\"3\":\"-0.01320111\",\"4\":\"-0.41603839\",\"5\":\"-2.5637901\",\"6\":\"1.701111956\",\"7\":\"-1.00458350\",\"8\":\"0.83278215\",\"9\":\"-0.30409851\",\"10\":\"-0.17937091\",\"11\":\"-0.45249609\",\"12\":\"1.08333206\",\"13\":\"-0.001737684\",\"14\":\"-1.64998595\",\"15\":\"-1.03976248\",\"16\":\"0.79132093\",\"17\":\"0.555027924\",\"18\":\"-0.15934181\",\"19\":\"-0.80667114\",\"20\":\"-2.24550908\",\"21\":\"3.1804735\",\"22\":\"0.78244500\",\"23\":\"-0.36981007\",\"24\":\"-0.38681414\",\"25\":\"0.639787413\",\"26\":\"-0.901371324\",\"27\":\"-1.08455669\",\"28\":\"0.81927920\",\"29\":\"-0.91575907\",\"30\":\"-1.004931054\",\"31\":\"-0.041817544\",\"32\":\"-0.017914990\",\"33\":\"-0.71453705\",\"34\":\"1.28242250\",\"35\":\"-1.477928381\",\"36\":\"-2.50882375\",\"37\":\"0.94516833\",\"38\":\"-1.7708595\",\"39\":\"-0.63609512\",\"40\":\"0.652136062\",\"41\":\"-0.99444996\",\"42\":\"2.20562178\",\"43\":\"-1.573365586\",\"44\":\"-1.62169925\",\"45\":\"-0.81558659\",\"46\":\"-1.29433127\",\"47\":\"-0.73813935\",\"48\":\"-1.112552251\",\"49\":\"-1.09336045\",\"50\":\"-0.93824783\",\"51\":\"-0.531610347\"},{\"1\":\"1.6255324978\",\"2\":\"-2.01927447\",\"3\":\"-1.18639652\",\"4\":\"0.49371412\",\"5\":\"-2.4604045\",\"6\":\"1.356466105\",\"7\":\"1.03506297\",\"8\":\"0.55738850\",\"9\":\"0.12648127\",\"10\":\"-1.69742399\",\"11\":\"-0.56281308\",\"12\":\"0.25437531\",\"13\":\"-1.473102611\",\"14\":\"-3.04113487\",\"15\":\"-1.55721272\",\"16\":\"-0.52004735\",\"17\":\"-0.307089266\",\"18\":\"-1.78178100\",\"19\":\"-0.13172994\",\"20\":\"-1.41360222\",\"21\":\"2.7580252\",\"22\":\"-0.13713066\",\"23\":\"-0.04372736\",\"24\":\"-0.47304882\",\"25\":\"1.075811311\",\"26\":\"0.436433748\",\"27\":\"-1.34746794\",\"28\":\"0.17427658\",\"29\":\"1.91616544\",\"30\":\"0.503341314\",\"31\":\"0.604457569\",\"32\":\"1.500557040\",\"33\":\"0.97424157\",\"34\":\"-0.12266714\",\"35\":\"-0.486123885\",\"36\":\"-2.26579373\",\"37\":\"-1.75945296\",\"38\":\"-1.4562937\",\"39\":\"-3.06612710\",\"40\":\"-0.634807944\",\"41\":\"-1.33891046\",\"42\":\"1.46391492\",\"43\":\"-2.025893053\",\"44\":\"0.76753294\",\"45\":\"-1.41866903\",\"46\":\"-0.88623351\",\"47\":\"-0.27053912\",\"48\":\"-1.259578242\",\"49\":\"-3.01524095\",\"50\":\"-0.70687892\",\"51\":\"-1.166483537\"},{\"1\":\"-0.1552486527\",\"2\":\"-1.33400615\",\"3\":\"0.16839604\",\"4\":\"1.85240083\",\"5\":\"-2.2553237\",\"6\":\"0.530734110\",\"7\":\"0.37630999\",\"8\":\"0.56286355\",\"9\":\"-1.60198397\",\"10\":\"0.65531758\",\"11\":\"-0.92412884\",\"12\":\"0.45956091\",\"13\":\"-0.609440019\",\"14\":\"1.08499453\",\"15\":\"0.51349429\",\"16\":\"1.95702746\",\"17\":\"-0.473755734\",\"18\":\"-0.66828778\",\"19\":\"-1.33946759\",\"20\":\"-2.04351529\",\"21\":\"2.6208463\",\"22\":\"0.29254974\",\"23\":\"-1.81324441\",\"24\":\"0.76049663\",\"25\":\"1.030646778\",\"26\":\"-0.069293774\",\"27\":\"-0.62477936\",\"28\":\"1.35486262\",\"29\":\"-2.10095367\",\"30\":\"1.259117576\",\"31\":\"0.755157899\",\"32\":\"1.523604349\",\"33\":\"1.37728079\",\"34\":\"0.27889319\",\"35\":\"-0.666712236\",\"36\":\"-3.73502490\",\"37\":\"-1.83635716\",\"38\":\"-3.0949642\",\"39\":\"-0.42170841\",\"40\":\"-0.919656549\",\"41\":\"0.46999553\",\"42\":\"2.39521007\",\"43\":\"-1.163277082\",\"44\":\"-0.96530518\",\"45\":\"-2.04862677\",\"46\":\"-0.27113931\",\"47\":\"-2.26371605\",\"48\":\"-1.616949850\",\"49\":\"-0.91338984\",\"50\":\"-0.11677202\",\"51\":\"-0.504454713\"},{\"1\":\"-0.0191941593\",\"2\":\"-0.78108300\",\"3\":\"-0.44094068\",\"4\":\"1.49422112\",\"5\":\"-3.6359696\",\"6\":\"0.986893526\",\"7\":\"0.83200127\",\"8\":\"0.50157100\",\"9\":\"-0.82229270\",\"10\":\"1.21332986\",\"11\":\"-0.21040736\",\"12\":\"-0.01157057\",\"13\":\"-1.289450245\",\"14\":\"-0.43259828\",\"15\":\"1.40292667\",\"16\":\"1.07287831\",\"17\":\"-0.579699300\",\"18\":\"-2.17543113\",\"19\":\"-1.16500416\",\"20\":\"0.36666156\",\"21\":\"2.7761766\",\"22\":\"1.02980868\",\"23\":\"-1.02378773\",\"24\":\"-1.07947438\",\"25\":\"-0.234137599\",\"26\":\"-1.020721553\",\"27\":\"-2.33712264\",\"28\":\"-0.85507363\",\"29\":\"-0.51834767\",\"30\":\"0.177041029\",\"31\":\"-1.163165517\",\"32\":\"0.677143897\",\"33\":\"-0.87882458\",\"34\":\"0.76618390\",\"35\":\"-2.161471429\",\"36\":\"-2.27535183\",\"37\":\"-1.01374052\",\"38\":\"-2.3172247\",\"39\":\"-1.12325227\",\"40\":\"-1.395496088\",\"41\":\"-1.74316486\",\"42\":\"1.35068777\",\"43\":\"-0.419203406\",\"44\":\"0.56634022\",\"45\":\"-0.99560120\",\"46\":\"0.39575502\",\"47\":\"-2.02319454\",\"48\":\"0.327255511\",\"49\":\"-1.91855092\",\"50\":\"0.10080501\",\"51\":\"1.280234491\"},{\"1\":\"1.5104124646\",\"2\":\"-0.68076910\",\"3\":\"-0.02075162\",\"4\":\"2.05784212\",\"5\":\"-2.7910001\",\"6\":\"0.892539101\",\"7\":\"0.29027516\",\"8\":\"-0.55615686\",\"9\":\"-1.46065160\",\"10\":\"-0.79555704\",\"11\":\"-0.87974044\",\"12\":\"0.36905134\",\"13\":\"-0.745948037\",\"14\":\"0.01017922\",\"15\":\"0.33409429\",\"16\":\"2.49038494\",\"17\":\"-0.059050048\",\"18\":\"-1.17281335\",\"19\":\"0.22366422\",\"20\":\"0.69736460\",\"21\":\"3.2242624\",\"22\":\"0.60657623\",\"23\":\"-0.34892689\",\"24\":\"-1.76688865\",\"25\":\"0.816037033\",\"26\":\"-0.758145555\",\"27\":\"-2.77970664\",\"28\":\"2.59855912\",\"29\":\"-0.60425269\",\"30\":\"1.160031264\",\"31\":\"-0.004737638\",\"32\":\"0.225306540\",\"33\":\"0.35137524\",\"34\":\"-0.75639342\",\"35\":\"-1.379692441\",\"36\":\"-0.64230004\",\"37\":\"-1.45301087\",\"38\":\"-0.6057464\",\"39\":\"-1.90231795\",\"40\":\"-0.606089319\",\"41\":\"-0.93463738\",\"42\":\"-1.29025798\",\"43\":\"-0.826320924\",\"44\":\"-0.96878568\",\"45\":\"-1.45082527\",\"46\":\"-1.84322347\",\"47\":\"-2.91012181\",\"48\":\"-2.393156725\",\"49\":\"-1.49063251\",\"50\":\"1.15437762\",\"51\":\"-1.635457694\"},{\"1\":\"-1.2531190959\",\"2\":\"-0.36642966\",\"3\":\"-0.32786631\",\"4\":\"-0.27948121\",\"5\":\"-1.2861016\",\"6\":\"-0.231569801\",\"7\":\"2.02205958\",\"8\":\"-2.39370371\",\"9\":\"-1.51638446\",\"10\":\"-0.40708322\",\"11\":\"0.86381153\",\"12\":\"0.96320590\",\"13\":\"-0.744954674\",\"14\":\"-1.54793674\",\"15\":\"-0.22950074\",\"16\":\"2.69351899\",\"17\":\"-0.597613417\",\"18\":\"-0.42967919\",\"19\":\"-1.22589059\",\"20\":\"-0.06873826\",\"21\":\"1.2727543\",\"22\":\"-0.35640208\",\"23\":\"-1.67050919\",\"24\":\"-0.07954322\",\"25\":\"0.855558046\",\"26\":\"-0.002836953\",\"27\":\"-0.36459732\",\"28\":\"0.62884034\",\"29\":\"-0.01568283\",\"30\":\"1.227254631\",\"31\":\"-1.809551230\",\"32\":\"2.402294151\",\"33\":\"-0.60472798\",\"34\":\"-2.47697114\",\"35\":\"0.464557778\",\"36\":\"-2.38399362\",\"37\":\"-1.66031570\",\"38\":\"-2.6629574\",\"39\":\"-1.69657882\",\"40\":\"0.394362647\",\"41\":\"-0.15338127\",\"42\":\"1.86980211\",\"43\":\"-1.127576814\",\"44\":\"-1.18464558\",\"45\":\"-1.45907115\",\"46\":\"-0.70361723\",\"47\":\"-2.23807491\",\"48\":\"-0.800003977\",\"49\":\"-2.43975117\",\"50\":\"-0.59252177\",\"51\":\"0.870977222\"},{\"1\":\"2.3472409947\",\"2\":\"-1.33014942\",\"3\":\"-0.10055471\",\"4\":\"1.07286156\",\"5\":\"-0.7439338\",\"6\":\"0.828085941\",\"7\":\"1.19731209\",\"8\":\"-1.30880309\",\"9\":\"-1.30253235\",\"10\":\"-1.02773522\",\"11\":\"-1.56576647\",\"12\":\"-1.51464533\",\"13\":\"-0.323107861\",\"14\":\"-1.10236142\",\"15\":\"0.04474276\",\"16\":\"1.10418335\",\"17\":\"0.948487590\",\"18\":\"0.42309295\",\"19\":\"-0.22113375\",\"20\":\"-1.77690544\",\"21\":\"0.5048281\",\"22\":\"0.78962354\",\"23\":\"-0.46274750\",\"24\":\"-0.89321589\",\"25\":\"2.288648423\",\"26\":\"-2.313677582\",\"27\":\"-0.02478709\",\"28\":\"1.00137336\",\"29\":\"-3.34322305\",\"30\":\"-1.306528244\",\"31\":\"-1.473769975\",\"32\":\"-0.234489210\",\"33\":\"-0.59711997\",\"34\":\"-1.31907401\",\"35\":\"-1.657079367\",\"36\":\"-0.06388861\",\"37\":\"-0.75784772\",\"38\":\"-2.5362302\",\"39\":\"-2.61313536\",\"40\":\"1.140978019\",\"41\":\"-0.57421984\",\"42\":\"1.23111700\",\"43\":\"-3.016436795\",\"44\":\"-0.48190365\",\"45\":\"1.34666834\",\"46\":\"0.33983596\",\"47\":\"-1.85595313\",\"48\":\"-1.153636726\",\"49\":\"-0.86705056\",\"50\":\"-0.84466803\",\"51\":\"0.832714834\"},{\"1\":\"0.8909212011\",\"2\":\"-2.40228317\",\"3\":\"-0.24431568\",\"4\":\"1.56734955\",\"5\":\"-2.0549927\",\"6\":\"-0.876702328\",\"7\":\"1.16224305\",\"8\":\"0.47625712\",\"9\":\"-1.20990583\",\"10\":\"-1.42792457\",\"11\":\"-0.28953033\",\"12\":\"-2.10784428\",\"13\":\"-0.714212741\",\"14\":\"-2.88763660\",\"15\":\"1.24682456\",\"16\":\"0.71636874\",\"17\":\"-0.136298638\",\"18\":\"-0.81127838\",\"19\":\"-1.49869945\",\"20\":\"-1.13622501\",\"21\":\"3.0066273\",\"22\":\"0.98378588\",\"23\":\"-0.42204901\",\"24\":\"-0.58438972\",\"25\":\"-0.658711624\",\"26\":\"0.153971780\",\"27\":\"-0.94856385\",\"28\":\"0.68220836\",\"29\":\"-2.28512971\",\"30\":\"0.322832789\",\"31\":\"-2.132892792\",\"32\":\"2.531539976\",\"33\":\"-1.14986636\",\"34\":\"-0.11618313\",\"35\":\"-1.252653772\",\"36\":\"-1.67914273\",\"37\":\"-0.93826281\",\"38\":\"-1.5698174\",\"39\":\"-0.95479634\",\"40\":\"-0.155386761\",\"41\":\"-0.21510712\",\"42\":\"0.46014094\",\"43\":\"0.382800908\",\"44\":\"0.17452350\",\"45\":\"-1.49276967\",\"46\":\"-1.89568223\",\"47\":\"-1.26043008\",\"48\":\"1.144523607\",\"49\":\"-0.58540637\",\"50\":\"0.94717760\",\"51\":\"-0.160377160\"},{\"1\":\"0.2145934302\",\"2\":\"-0.90916684\",\"3\":\"-0.34077678\",\"4\":\"1.23944130\",\"5\":\"-3.8855380\",\"6\":\"-0.014076395\",\"7\":\"-0.34917066\",\"8\":\"-1.41171703\",\"9\":\"-0.78317782\",\"10\":\"0.71551772\",\"11\":\"0.16654287\",\"12\":\"-0.53300981\",\"13\":\"-2.619561335\",\"14\":\"0.88564658\",\"15\":\"-0.49811637\",\"16\":\"-1.57046798\",\"17\":\"0.539669004\",\"18\":\"-0.45226504\",\"19\":\"-0.70434528\",\"20\":\"-0.58842656\",\"21\":\"2.0918003\",\"22\":\"-0.50224682\",\"23\":\"1.08377408\",\"24\":\"0.07975126\",\"25\":\"1.148794240\",\"26\":\"0.675750681\",\"27\":\"-1.45603945\",\"28\":\"-0.75081320\",\"29\":\"-0.89541078\",\"30\":\"-0.490290980\",\"31\":\"-2.036364419\",\"32\":\"0.507604426\",\"33\":\"-2.05402688\",\"34\":\"0.49394718\",\"35\":\"-1.246342416\",\"36\":\"-1.51806476\",\"37\":\"-2.24224490\",\"38\":\"-2.7860748\",\"39\":\"-2.97951633\",\"40\":\"-0.367346245\",\"41\":\"-1.78209093\",\"42\":\"0.79302737\",\"43\":\"-1.108582401\",\"44\":\"1.85041041\",\"45\":\"0.71688692\",\"46\":\"-1.21710349\",\"47\":\"0.44157974\",\"48\":\"-1.715351921\",\"49\":\"-1.55659978\",\"50\":\"1.18050128\",\"51\":\"-0.489957119\"},{\"1\":\"0.8957610822\",\"2\":\"-0.93709272\",\"3\":\"-0.15897874\",\"4\":\"2.29953093\",\"5\":\"-0.9141758\",\"6\":\"-0.788275834\",\"7\":\"0.22699562\",\"8\":\"-1.23343855\",\"9\":\"-1.23226003\",\"10\":\"-1.96829544\",\"11\":\"-1.47937059\",\"12\":\"-1.46233086\",\"13\":\"-2.325585068\",\"14\":\"-0.02781437\",\"15\":\"0.12312989\",\"16\":\"0.94391075\",\"17\":\"1.491022752\",\"18\":\"0.56746208\",\"19\":\"1.40770391\",\"20\":\"-0.64392036\",\"21\":\"0.6334851\",\"22\":\"0.64738063\",\"23\":\"0.82272353\",\"24\":\"-2.02288731\",\"25\":\"0.118351436\",\"26\":\"-1.287318078\",\"27\":\"-0.02840185\",\"28\":\"1.16534604\",\"29\":\"-1.95128393\",\"30\":\"-0.181092696\",\"31\":\"-0.344728671\",\"32\":\"-0.780388912\",\"33\":\"1.32648332\",\"34\":\"-0.50118321\",\"35\":\"0.725794425\",\"36\":\"-1.15362242\",\"37\":\"-2.54837012\",\"38\":\"-1.0455276\",\"39\":\"-1.48125597\",\"40\":\"-0.496629797\",\"41\":\"-0.89597299\",\"42\":\"1.50515981\",\"43\":\"-1.932640415\",\"44\":\"-1.89031050\",\"45\":\"0.26462264\",\"46\":\"-2.76580810\",\"47\":\"-0.07987289\",\"48\":\"-2.616606362\",\"49\":\"0.57302518\",\"50\":\"-0.48058408\",\"51\":\"-0.952318695\"},{\"1\":\"-0.1099063699\",\"2\":\"-1.69439166\",\"3\":\"1.64153842\",\"4\":\"0.24665533\",\"5\":\"-1.1981087\",\"6\":\"-0.410705148\",\"7\":\"-0.23631648\",\"8\":\"0.97888119\",\"9\":\"0.66510061\",\"10\":\"0.55120882\",\"11\":\"-1.41029236\",\"12\":\"-2.18988264\",\"13\":\"0.196780737\",\"14\":\"-1.73859656\",\"15\":\"0.01804619\",\"16\":\"0.80802459\",\"17\":\"0.398453952\",\"18\":\"-2.09792246\",\"19\":\"0.11955999\",\"20\":\"-2.00504024\",\"21\":\"2.9714754\",\"22\":\"1.09074470\",\"23\":\"-1.23664628\",\"24\":\"-2.00903960\",\"25\":\"0.706798908\",\"26\":\"-0.639534912\",\"27\":\"-1.29930158\",\"28\":\"0.46002714\",\"29\":\"-1.45352411\",\"30\":\"-0.181526930\",\"31\":\"-0.202236033\",\"32\":\"3.282608778\",\"33\":\"0.32552373\",\"34\":\"0.12969932\",\"35\":\"-0.692116054\",\"36\":\"-2.56809737\",\"37\":\"-0.56938602\",\"38\":\"-1.7575714\",\"39\":\"-0.88581758\",\"40\":\"0.659505477\",\"41\":\"-2.17000724\",\"42\":\"3.90155971\",\"43\":\"-1.270332963\",\"44\":\"-1.03879449\",\"45\":\"-1.16541212\",\"46\":\"-0.70691783\",\"47\":\"-0.69554000\",\"48\":\"-0.874686423\",\"49\":\"-0.58142652\",\"50\":\"-0.85648544\",\"51\":\"-0.863373890\"},{\"1\":\"-0.5801191453\",\"2\":\"-1.42466828\",\"3\":\"-0.67081702\",\"4\":\"1.70603602\",\"5\":\"-2.3826297\",\"6\":\"-0.248193715\",\"7\":\"1.28354873\",\"8\":\"-1.31690991\",\"9\":\"-1.83933614\",\"10\":\"-1.86715822\",\"11\":\"-0.18497494\",\"12\":\"-0.11776561\",\"13\":\"-1.743732515\",\"14\":\"-0.53087283\",\"15\":\"0.15223080\",\"16\":\"2.40630690\",\"17\":\"-1.669062003\",\"18\":\"-0.52657876\",\"19\":\"1.08497324\",\"20\":\"-1.06972690\",\"21\":\"1.7674167\",\"22\":\"0.94379851\",\"23\":\"1.24000536\",\"24\":\"0.73067183\",\"25\":\"-0.672954261\",\"26\":\"-2.232407427\",\"27\":\"-1.05875871\",\"28\":\"-0.44737775\",\"29\":\"-0.34462909\",\"30\":\"-1.138298836\",\"31\":\"-0.718671039\",\"32\":\"1.481074825\",\"33\":\"-2.26785781\",\"34\":\"0.23360140\",\"35\":\"0.053052685\",\"36\":\"-2.40313909\",\"37\":\"-2.00708790\",\"38\":\"-2.0904899\",\"39\":\"-1.25760983\",\"40\":\"-1.375487306\",\"41\":\"-1.30803491\",\"42\":\"1.63766984\",\"43\":\"-0.807387161\",\"44\":\"0.22240667\",\"45\":\"-0.89185370\",\"46\":\"-1.63553184\",\"47\":\"-1.53515578\",\"48\":\"-1.146966889\",\"49\":\"-0.30335331\",\"50\":\"-2.34606354\",\"51\":\"0.151436610\"},{\"1\":\"-0.0430613766\",\"2\":\"-1.38243084\",\"3\":\"1.17885838\",\"4\":\"1.23996608\",\"5\":\"-1.9550090\",\"6\":\"2.625179337\",\"7\":\"0.21681554\",\"8\":\"0.12854928\",\"9\":\"-0.78114496\",\"10\":\"-0.79229755\",\"11\":\"-0.98967757\",\"12\":\"-1.79156966\",\"13\":\"-0.728783504\",\"14\":\"-0.20022372\",\"15\":\"1.14977988\",\"16\":\"0.34512662\",\"17\":\"-1.390521097\",\"18\":\"-0.54071620\",\"19\":\"0.72984633\",\"20\":\"0.43731617\",\"21\":\"3.1811002\",\"22\":\"-0.04236694\",\"23\":\"0.19675419\",\"24\":\"-0.42508991\",\"25\":\"-0.419596923\",\"26\":\"-0.813613280\",\"27\":\"-1.33005456\",\"28\":\"0.95765934\",\"29\":\"-1.05595833\",\"30\":\"0.925808424\",\"31\":\"-1.698162645\",\"32\":\"0.032984717\",\"33\":\"-0.82301181\",\"34\":\"0.31865308\",\"35\":\"0.270175067\",\"36\":\"-2.05265194\",\"37\":\"-2.12304432\",\"38\":\"-3.7717536\",\"39\":\"-0.48181987\",\"40\":\"-0.044275154\",\"41\":\"0.68235305\",\"42\":\"0.46979990\",\"43\":\"-2.586994107\",\"44\":\"-0.51374441\",\"45\":\"-0.69082251\",\"46\":\"-1.91927772\",\"47\":\"-1.00872126\",\"48\":\"-1.946443260\",\"49\":\"0.79741712\",\"50\":\"0.88743428\",\"51\":\"1.573420904\"},{\"1\":\"0.9884156119\",\"2\":\"-0.87844336\",\"3\":\"-0.52323589\",\"4\":\"1.49342397\",\"5\":\"-1.2336103\",\"6\":\"-0.725547289\",\"7\":\"1.17230188\",\"8\":\"1.15773898\",\"9\":\"-0.62888522\",\"10\":\"-0.98478447\",\"11\":\"-1.65856823\",\"12\":\"2.64271067\",\"13\":\"-1.103283114\",\"14\":\"-1.76754622\",\"15\":\"0.50485004\",\"16\":\"2.06459755\",\"17\":\"-0.487724686\",\"18\":\"0.60264233\",\"19\":\"-0.26121140\",\"20\":\"-1.88872221\",\"21\":\"2.7877856\",\"22\":\"0.96072136\",\"23\":\"-2.25321124\",\"24\":\"0.57974409\",\"25\":\"-1.085655727\",\"26\":\"-0.430089904\",\"27\":\"-0.69575480\",\"28\":\"-1.37458266\",\"29\":\"-1.80506020\",\"30\":\"-0.928414992\",\"31\":\"-0.639045470\",\"32\":\"0.727152565\",\"33\":\"1.07872285\",\"34\":\"0.03812381\",\"35\":\"-0.881324860\",\"36\":\"0.14378603\",\"37\":\"0.06859881\",\"38\":\"-2.5272067\",\"39\":\"-1.29044509\",\"40\":\"0.727328122\",\"41\":\"-0.21306600\",\"42\":\"3.35310673\",\"43\":\"-0.351334091\",\"44\":\"-1.04270826\",\"45\":\"-0.09021363\",\"46\":\"-1.77431755\",\"47\":\"-0.42090207\",\"48\":\"-0.975027104\",\"49\":\"-1.90309949\",\"50\":\"-1.36141055\",\"51\":\"-0.650248370\"},{\"1\":\"-0.3500752349\",\"2\":\"-2.46693208\",\"3\":\"0.58531930\",\"4\":\"-0.49311331\",\"5\":\"-1.4933445\",\"6\":\"0.195724985\",\"7\":\"-1.42040725\",\"8\":\"-0.19187640\",\"9\":\"0.20783800\",\"10\":\"-1.21644953\",\"11\":\"0.40010179\",\"12\":\"-0.41943739\",\"13\":\"-0.857335817\",\"14\":\"-1.74108704\",\"15\":\"0.20947103\",\"16\":\"0.24021177\",\"17\":\"0.770937719\",\"18\":\"-0.55349918\",\"19\":\"-2.05624342\",\"20\":\"-0.05195534\",\"21\":\"3.2051407\",\"22\":\"1.47468488\",\"23\":\"-1.50296981\",\"24\":\"-0.59434784\",\"25\":\"0.368831797\",\"26\":\"-1.451845062\",\"27\":\"-2.62014005\",\"28\":\"2.11049595\",\"29\":\"-1.31452911\",\"30\":\"0.470733821\",\"31\":\"-2.140942385\",\"32\":\"0.307499828\",\"33\":\"-0.36910029\",\"34\":\"-0.90086710\",\"35\":\"-1.629809449\",\"36\":\"-1.20254281\",\"37\":\"-1.09163511\",\"38\":\"-0.1457437\",\"39\":\"0.96795091\",\"40\":\"0.767557652\",\"41\":\"-0.38061035\",\"42\":\"1.01097648\",\"43\":\"-0.821809996\",\"44\":\"-2.15822374\",\"45\":\"-0.62894793\",\"46\":\"-0.54983670\",\"47\":\"-1.47254764\",\"48\":\"-1.382842939\",\"49\":\"-0.44336661\",\"50\":\"-1.64759091\",\"51\":\"-1.887550904\"},{\"1\":\"0.9932027799\",\"2\":\"-1.08861734\",\"3\":\"-0.63356953\",\"4\":\"1.92127727\",\"5\":\"-1.1963681\",\"6\":\"0.039380245\",\"7\":\"0.68280491\",\"8\":\"0.41999904\",\"9\":\"-0.94216972\",\"10\":\"-0.31668146\",\"11\":\"-2.24613825\",\"12\":\"0.25500831\",\"13\":\"0.944294861\",\"14\":\"-0.16530699\",\"15\":\"-1.51647754\",\"16\":\"0.56067380\",\"17\":\"-0.428588193\",\"18\":\"-1.39011317\",\"19\":\"-0.39909490\",\"20\":\"-1.21495920\",\"21\":\"0.5664128\",\"22\":\"-0.86212873\",\"23\":\"-1.31056184\",\"24\":\"0.10366548\",\"25\":\"0.668357707\",\"26\":\"-0.794503125\",\"27\":\"-1.91131932\",\"28\":\"-0.32576537\",\"29\":\"0.70804508\",\"30\":\"-1.810335279\",\"31\":\"-2.691712685\",\"32\":\"1.417420415\",\"33\":\"-0.28308416\",\"34\":\"0.31525013\",\"35\":\"-0.331156284\",\"36\":\"-1.72356364\",\"37\":\"-1.70719217\",\"38\":\"-2.4659448\",\"39\":\"-2.20045637\",\"40\":\"0.122776351\",\"41\":\"-1.39952367\",\"42\":\"0.61977017\",\"43\":\"0.134124323\",\"44\":\"-1.13402290\",\"45\":\"0.54622453\",\"46\":\"-3.15680908\",\"47\":\"0.09055581\",\"48\":\"-1.786076834\",\"49\":\"-0.26540527\",\"50\":\"2.51993777\",\"51\":\"-1.220431734\"},{\"1\":\"-1.1513069156\",\"2\":\"0.08264261\",\"3\":\"-0.79849133\",\"4\":\"1.80795574\",\"5\":\"-3.7191083\",\"6\":\"0.457860134\",\"7\":\"-0.58862882\",\"8\":\"-0.46622943\",\"9\":\"-1.54225403\",\"10\":\"-0.81495923\",\"11\":\"-1.23458630\",\"12\":\"0.28214335\",\"13\":\"-2.380307228\",\"14\":\"-0.33249918\",\"15\":\"0.01433417\",\"16\":\"1.24243340\",\"17\":\"-0.406900226\",\"18\":\"-2.40115667\",\"19\":\"-0.87336283\",\"20\":\"-0.61970804\",\"21\":\"1.2271539\",\"22\":\"-2.04345544\",\"23\":\"-0.64910550\",\"24\":\"0.01181180\",\"25\":\"0.203330003\",\"26\":\"-1.625557685\",\"27\":\"-1.64855767\",\"28\":\"0.45130855\",\"29\":\"0.57769026\",\"30\":\"-0.384939770\",\"31\":\"-1.438691207\",\"32\":\"1.236236932\",\"33\":\"0.37363489\",\"34\":\"-1.21366201\",\"35\":\"-0.859800393\",\"36\":\"-2.74568890\",\"37\":\"-0.39408114\",\"38\":\"-1.5256609\",\"39\":\"0.19812298\",\"40\":\"-1.456660010\",\"41\":\"-1.02271715\",\"42\":\"0.20226495\",\"43\":\"-0.082603453\",\"44\":\"-1.04011854\",\"45\":\"-0.57330990\",\"46\":\"-1.41985098\",\"47\":\"0.12893925\",\"48\":\"-0.606482261\",\"49\":\"-1.25815668\",\"50\":\"-0.28880681\",\"51\":\"-0.238588195\"},{\"1\":\"1.2129094621\",\"2\":\"-2.83159071\",\"3\":\"0.72296832\",\"4\":\"1.21591992\",\"5\":\"-3.6804820\",\"6\":\"-1.279245019\",\"7\":\"0.64545358\",\"8\":\"-0.34704071\",\"9\":\"-0.14449997\",\"10\":\"0.39154470\",\"11\":\"-0.65113968\",\"12\":\"-1.46230447\",\"13\":\"0.316314408\",\"14\":\"0.03038328\",\"15\":\"0.65623641\",\"16\":\"1.75935691\",\"17\":\"0.335713729\",\"18\":\"-1.15079236\",\"19\":\"-1.81121139\",\"20\":\"-0.23907656\",\"21\":\"3.4012565\",\"22\":\"1.04659414\",\"23\":\"-1.03925307\",\"24\":\"-1.24356168\",\"25\":\"-0.391619372\",\"26\":\"-0.786036307\",\"27\":\"-3.06809897\",\"28\":\"2.42691728\",\"29\":\"-1.47399609\",\"30\":\"-0.223818871\",\"31\":\"-1.348076461\",\"32\":\"-0.138254029\",\"33\":\"0.51492153\",\"34\":\"-0.36089118\",\"35\":\"0.941680430\",\"36\":\"-1.71652862\",\"37\":\"0.13668126\",\"38\":\"-3.1047873\",\"39\":\"-2.95545937\",\"40\":\"-1.115378589\",\"41\":\"-1.48226786\",\"42\":\"0.77568710\",\"43\":\"-1.606583323\",\"44\":\"-0.93714213\",\"45\":\"-2.44596921\",\"46\":\"-2.00805774\",\"47\":\"-2.13501895\",\"48\":\"-1.438980505\",\"49\":\"-0.93293353\",\"50\":\"-0.55708673\",\"51\":\"-0.813909072\"},{\"1\":\"-0.6129716632\",\"2\":\"-1.83219422\",\"3\":\"0.07908707\",\"4\":\"0.73718599\",\"5\":\"-2.6704456\",\"6\":\"-0.132280421\",\"7\":\"1.21392153\",\"8\":\"2.01803730\",\"9\":\"-0.85495207\",\"10\":\"0.31273257\",\"11\":\"-2.95693137\",\"12\":\"-0.53595199\",\"13\":\"-0.600309720\",\"14\":\"-1.02682623\",\"15\":\"0.37568729\",\"16\":\"0.79959778\",\"17\":\"-0.064433292\",\"18\":\"0.67250371\",\"19\":\"-2.73139527\",\"20\":\"-0.70110514\",\"21\":\"2.2015337\",\"22\":\"-0.65092895\",\"23\":\"-1.70778470\",\"24\":\"0.78499794\",\"25\":\"1.069542619\",\"26\":\"-0.933105769\",\"27\":\"-0.67607979\",\"28\":\"-0.87345353\",\"29\":\"0.52263501\",\"30\":\"-0.676250063\",\"31\":\"-1.885696487\",\"32\":\"1.358778083\",\"33\":\"0.15198913\",\"34\":\"-1.21881391\",\"35\":\"-1.021204924\",\"36\":\"-1.23656738\",\"37\":\"-0.18250929\",\"38\":\"-3.7707427\",\"39\":\"-2.41830965\",\"40\":\"-1.014782116\",\"41\":\"-0.41237229\",\"42\":\"3.38466353\",\"43\":\"-1.558925465\",\"44\":\"0.75687716\",\"45\":\"-0.37683978\",\"46\":\"-1.95645910\",\"47\":\"-1.71542563\",\"48\":\"-2.942298443\",\"49\":\"-2.26380779\",\"50\":\"-3.25604764\",\"51\":\"-0.674639915\"},{\"1\":\"-0.8493727591\",\"2\":\"-0.30858518\",\"3\":\"-1.22904745\",\"4\":\"2.66126284\",\"5\":\"-3.2679859\",\"6\":\"-0.710218274\",\"7\":\"-0.05469016\",\"8\":\"-2.02179092\",\"9\":\"0.66875805\",\"10\":\"1.15569319\",\"11\":\"-0.15802773\",\"12\":\"-1.55680490\",\"13\":\"-0.827883563\",\"14\":\"-1.25152322\",\"15\":\"-0.88367018\",\"16\":\"2.03359898\",\"17\":\"-0.091506259\",\"18\":\"1.44602699\",\"19\":\"-2.54482811\",\"20\":\"0.70881053\",\"21\":\"4.3821550\",\"22\":\"-0.59752132\",\"23\":\"-1.74193614\",\"24\":\"0.41994991\",\"25\":\"1.381255079\",\"26\":\"-0.196492070\",\"27\":\"-1.23211109\",\"28\":\"2.25269950\",\"29\":\"-0.41299308\",\"30\":\"-0.191734585\",\"31\":\"-2.940090771\",\"32\":\"0.428227339\",\"33\":\"-0.06037759\",\"34\":\"-0.23161558\",\"35\":\"-0.811900155\",\"36\":\"-1.98971564\",\"37\":\"-2.17934077\",\"38\":\"-1.4706412\",\"39\":\"-2.24235374\",\"40\":\"-1.737565827\",\"41\":\"0.29923607\",\"42\":\"2.35605770\",\"43\":\"-2.064158896\",\"44\":\"-1.31730447\",\"45\":\"-2.13257985\",\"46\":\"-0.51970545\",\"47\":\"0.23822442\",\"48\":\"-3.759059441\",\"49\":\"-0.78181834\",\"50\":\"-0.62361871\",\"51\":\"-0.666844034\"},{\"1\":\"-1.6513255056\",\"2\":\"1.49157461\",\"3\":\"1.00316865\",\"4\":\"0.88760478\",\"5\":\"-1.4169580\",\"6\":\"1.524181697\",\"7\":\"0.50086883\",\"8\":\"-0.23138190\",\"9\":\"-1.82033093\",\"10\":\"0.60980012\",\"11\":\"-0.23481844\",\"12\":\"-0.07794240\",\"13\":\"-1.709312728\",\"14\":\"0.21712529\",\"15\":\"-0.58520849\",\"16\":\"2.56734173\",\"17\":\"-0.328487011\",\"18\":\"0.90922417\",\"19\":\"-1.16402591\",\"20\":\"-2.28921858\",\"21\":\"2.2366543\",\"22\":\"0.91209663\",\"23\":\"0.83230715\",\"24\":\"-0.26897769\",\"25\":\"0.183164440\",\"26\":\"0.055727170\",\"27\":\"-2.15782622\",\"28\":\"1.38188200\",\"29\":\"-0.13068143\",\"30\":\"1.020673272\",\"31\":\"-1.360613980\",\"32\":\"1.735524900\",\"33\":\"0.99934599\",\"34\":\"-0.20845464\",\"35\":\"0.181479404\",\"36\":\"-2.51707783\",\"37\":\"-1.77364829\",\"38\":\"-0.7307129\",\"39\":\"-2.86210555\",\"40\":\"-0.254273524\",\"41\":\"-0.16670273\",\"42\":\"2.18602304\",\"43\":\"-1.430345652\",\"44\":\"-2.43141493\",\"45\":\"0.65718813\",\"46\":\"-0.64258581\",\"47\":\"-2.65573420\",\"48\":\"-1.687900365\",\"49\":\"-1.95295622\",\"50\":\"0.45220362\",\"51\":\"-1.869151843\"},{\"1\":\"-1.0164166940\",\"2\":\"-1.68307702\",\"3\":\"-0.30599995\",\"4\":\"1.49536446\",\"5\":\"-1.6406114\",\"6\":\"0.595911629\",\"7\":\"-0.75367728\",\"8\":\"-1.93773655\",\"9\":\"-0.38242139\",\"10\":\"-0.82518614\",\"11\":\"-0.38074974\",\"12\":\"0.31821119\",\"13\":\"-0.060648215\",\"14\":\"-0.29256357\",\"15\":\"-0.64008323\",\"16\":\"0.71607883\",\"17\":\"0.989410122\",\"18\":\"-1.34775666\",\"19\":\"-0.01654304\",\"20\":\"-0.55818560\",\"21\":\"0.3416597\",\"22\":\"-1.27975128\",\"23\":\"-0.31790791\",\"24\":\"-0.45938450\",\"25\":\"1.871998880\",\"26\":\"0.960726453\",\"27\":\"-1.09720009\",\"28\":\"1.29117244\",\"29\":\"-1.98789139\",\"30\":\"0.570214430\",\"31\":\"-0.403244541\",\"32\":\"1.704662419\",\"33\":\"1.23387900\",\"34\":\"-0.81502055\",\"35\":\"-1.164836481\",\"36\":\"-2.57551002\",\"37\":\"-0.85089321\",\"38\":\"-3.7244200\",\"39\":\"0.14370065\",\"40\":\"0.928652825\",\"41\":\"-1.08351329\",\"42\":\"1.59612157\",\"43\":\"-0.124287912\",\"44\":\"-0.35893156\",\"45\":\"-1.02830948\",\"46\":\"-1.10136043\",\"47\":\"-0.54880442\",\"48\":\"0.346868678\",\"49\":\"-0.43830302\",\"50\":\"-0.10995920\",\"51\":\"-0.670637128\"},{\"1\":\"0.0294103069\",\"2\":\"-0.43899485\",\"3\":\"0.41791125\",\"4\":\"0.53045014\",\"5\":\"-2.4047186\",\"6\":\"1.601612580\",\"7\":\"-0.19338462\",\"8\":\"0.94589898\",\"9\":\"-1.19677898\",\"10\":\"1.37046827\",\"11\":\"-1.72354093\",\"12\":\"-0.61031989\",\"13\":\"-0.570046968\",\"14\":\"-0.23275829\",\"15\":\"-0.92793738\",\"16\":\"-0.20926555\",\"17\":\"-0.191175945\",\"18\":\"-0.48076638\",\"19\":\"-3.12312700\",\"20\":\"-0.13114838\",\"21\":\"3.1199403\",\"22\":\"0.43152192\",\"23\":\"-0.34905195\",\"24\":\"1.87876909\",\"25\":\"-0.840167267\",\"26\":\"0.153354991\",\"27\":\"-1.27557637\",\"28\":\"-1.61449756\",\"29\":\"-2.56118985\",\"30\":\"-0.808389133\",\"31\":\"-0.149773291\",\"32\":\"1.068263860\",\"33\":\"-0.24723348\",\"34\":\"-0.68213130\",\"35\":\"-0.519208609\",\"36\":\"-1.84900503\",\"37\":\"-2.53231037\",\"38\":\"-1.3339704\",\"39\":\"-0.30728987\",\"40\":\"-2.740987775\",\"41\":\"0.08688977\",\"42\":\"1.73261706\",\"43\":\"0.723564288\",\"44\":\"-0.96731842\",\"45\":\"-1.39586444\",\"46\":\"-0.45682282\",\"47\":\"-0.73501556\",\"48\":\"-0.269188813\",\"49\":\"-2.06341667\",\"50\":\"0.38849404\",\"51\":\"0.353382300\"},{\"1\":\"0.3710174553\",\"2\":\"-2.80843319\",\"3\":\"0.63787956\",\"4\":\"0.90936375\",\"5\":\"-3.0864736\",\"6\":\"1.117300712\",\"7\":\"-1.37020133\",\"8\":\"-0.61523934\",\"9\":\"1.28561248\",\"10\":\"-2.13557536\",\"11\":\"0.23142916\",\"12\":\"-2.89894017\",\"13\":\"-0.813213233\",\"14\":\"-2.97852207\",\"15\":\"0.99390861\",\"16\":\"0.87955120\",\"17\":\"0.216110175\",\"18\":\"0.48349145\",\"19\":\"0.25990106\",\"20\":\"-0.85302057\",\"21\":\"1.6228459\",\"22\":\"2.49385181\",\"23\":\"-0.53942736\",\"24\":\"-2.09119939\",\"25\":\"1.171886551\",\"26\":\"-1.102582662\",\"27\":\"-2.15277573\",\"28\":\"0.33242746\",\"29\":\"0.30536396\",\"30\":\"-0.227678789\",\"31\":\"0.659505527\",\"32\":\"0.312591186\",\"33\":\"-0.68370996\",\"34\":\"-0.27572423\",\"35\":\"-0.004667044\",\"36\":\"-1.28687335\",\"37\":\"-1.54958554\",\"38\":\"-1.8491072\",\"39\":\"0.03027331\",\"40\":\"0.464094033\",\"41\":\"-0.07798904\",\"42\":\"2.03877299\",\"43\":\"-0.140233328\",\"44\":\"-1.05971103\",\"45\":\"-0.87212942\",\"46\":\"-1.59644497\",\"47\":\"2.22738688\",\"48\":\"0.107735388\",\"49\":\"-0.93258840\",\"50\":\"1.45990408\",\"51\":\"0.200758754\"},{\"1\":\"0.1504323005\",\"2\":\"-2.10283996\",\"3\":\"-0.93500784\",\"4\":\"-1.49063603\",\"5\":\"-4.0174287\",\"6\":\"1.944598933\",\"7\":\"0.35308704\",\"8\":\"-0.92795183\",\"9\":\"-1.83823512\",\"10\":\"0.29913017\",\"11\":\"-0.32280682\",\"12\":\"0.40708497\",\"13\":\"-2.025466412\",\"14\":\"-2.60464715\",\"15\":\"0.97985082\",\"16\":\"1.98180245\",\"17\":\"0.383746930\",\"18\":\"-0.94783794\",\"19\":\"-2.73238805\",\"20\":\"-1.50420859\",\"21\":\"4.1310499\",\"22\":\"-0.92290872\",\"23\":\"0.26884559\",\"24\":\"-1.43608749\",\"25\":\"1.255522764\",\"26\":\"-0.880057841\",\"27\":\"-1.38475636\",\"28\":\"-0.81953226\",\"29\":\"-1.75701119\",\"30\":\"-0.111777011\",\"31\":\"-0.894175445\",\"32\":\"0.631861992\",\"33\":\"-0.46344732\",\"34\":\"-1.84050452\",\"35\":\"-0.905532761\",\"36\":\"-0.65916934\",\"37\":\"-1.18191200\",\"38\":\"-2.5462270\",\"39\":\"-1.94991463\",\"40\":\"-0.496955513\",\"41\":\"0.37731340\",\"42\":\"1.66534574\",\"43\":\"-2.898580393\",\"44\":\"-0.21979647\",\"45\":\"0.30460768\",\"46\":\"-3.01763772\",\"47\":\"-3.69819466\",\"48\":\"-0.124812750\",\"49\":\"-2.09850854\",\"50\":\"0.64528040\",\"51\":\"0.053147394\"},{\"1\":\"-0.7778164665\",\"2\":\"-1.17267048\",\"3\":\"-0.39830211\",\"4\":\"0.09747352\",\"5\":\"-2.9582389\",\"6\":\"-0.206926018\",\"7\":\"0.17123363\",\"8\":\"0.14493533\",\"9\":\"0.38922290\",\"10\":\"-0.89280664\",\"11\":\"-0.28299869\",\"12\":\"-1.04228368\",\"13\":\"-0.078909450\",\"14\":\"-1.24523099\",\"15\":\"0.89262618\",\"16\":\"0.36577943\",\"17\":\"0.213022205\",\"18\":\"-1.42972717\",\"19\":\"-1.24515677\",\"20\":\"1.07878265\",\"21\":\"4.2609379\",\"22\":\"-0.29500890\",\"23\":\"0.04610299\",\"24\":\"1.25728134\",\"25\":\"-0.380286842\",\"26\":\"1.041565374\",\"27\":\"-2.20644136\",\"28\":\"-0.13379019\",\"29\":\"-1.65456033\",\"30\":\"-0.393488709\",\"31\":\"1.340526449\",\"32\":\"0.089479409\",\"33\":\"-0.12587042\",\"34\":\"0.31124686\",\"35\":\"-1.712906871\",\"36\":\"-2.96454661\",\"37\":\"-1.23303739\",\"38\":\"-0.4307547\",\"39\":\"-1.25539610\",\"40\":\"-1.063427706\",\"41\":\"-0.90652513\",\"42\":\"1.60454950\",\"43\":\"-0.246764618\",\"44\":\"-3.76203859\",\"45\":\"-2.19918120\",\"46\":\"0.16008120\",\"47\":\"-1.80931012\",\"48\":\"-0.791554169\",\"49\":\"-1.49774906\",\"50\":\"-1.03256513\",\"51\":\"-0.899581933\"},{\"1\":\"1.0778812877\",\"2\":\"-2.89064463\",\"3\":\"1.84707272\",\"4\":\"2.26474979\",\"5\":\"-3.8285662\",\"6\":\"-0.734501023\",\"7\":\"1.49270660\",\"8\":\"1.48385357\",\"9\":\"0.46926185\",\"10\":\"-2.01807749\",\"11\":\"0.70385295\",\"12\":\"1.05189633\",\"13\":\"-1.335062118\",\"14\":\"-0.96457239\",\"15\":\"-0.53358887\",\"16\":\"1.00866355\",\"17\":\"0.188346606\",\"18\":\"-0.57176470\",\"19\":\"0.24406159\",\"20\":\"0.11975751\",\"21\":\"3.8141023\",\"22\":\"0.60964060\",\"23\":\"-0.13859672\",\"24\":\"-0.61234908\",\"25\":\"1.037795573\",\"26\":\"-1.881633548\",\"27\":\"-0.91233393\",\"28\":\"1.01336943\",\"29\":\"-0.80376730\",\"30\":\"-0.146942286\",\"31\":\"-0.483248383\",\"32\":\"1.935850816\",\"33\":\"-1.15323772\",\"34\":\"-0.44016575\",\"35\":\"-0.188514344\",\"36\":\"-2.42997294\",\"37\":\"-0.94418684\",\"38\":\"-3.1851846\",\"39\":\"-0.22248570\",\"40\":\"0.475714953\",\"41\":\"-1.64526291\",\"42\":\"2.40332290\",\"43\":\"-0.032373962\",\"44\":\"-1.40902289\",\"45\":\"-0.02680621\",\"46\":\"-1.22503307\",\"47\":\"-0.29448565\",\"48\":\"-2.614380820\",\"49\":\"-2.80484490\",\"50\":\"0.18035206\",\"51\":\"-0.688443728\"},{\"1\":\"-0.3631492143\",\"2\":\"-0.60878512\",\"3\":\"0.89692653\",\"4\":\"0.77284028\",\"5\":\"-3.0578289\",\"6\":\"0.001959893\",\"7\":\"0.96200061\",\"8\":\"-2.37986756\",\"9\":\"-1.49668392\",\"10\":\"0.44656650\",\"11\":\"-1.06368534\",\"12\":\"-0.15999576\",\"13\":\"-1.374141697\",\"14\":\"0.12772025\",\"15\":\"-0.09862793\",\"16\":\"1.55015354\",\"17\":\"-1.164758807\",\"18\":\"-1.45568280\",\"19\":\"-0.15752119\",\"20\":\"0.22128544\",\"21\":\"2.6979973\",\"22\":\"0.30305414\",\"23\":\"1.95530988\",\"24\":\"-2.17249857\",\"25\":\"1.146130403\",\"26\":\"-0.812088520\",\"27\":\"-2.83859190\",\"28\":\"-0.30861320\",\"29\":\"-2.67209516\",\"30\":\"-0.308622876\",\"31\":\"-1.092847210\",\"32\":\"2.456321108\",\"33\":\"0.16658960\",\"34\":\"-0.16089140\",\"35\":\"-0.781119925\",\"36\":\"-3.67588981\",\"37\":\"-0.98443710\",\"38\":\"-2.2974789\",\"39\":\"-0.28046340\",\"40\":\"0.354091300\",\"41\":\"-0.55046661\",\"42\":\"1.28364356\",\"43\":\"-0.451222580\",\"44\":\"-1.00881646\",\"45\":\"-1.25286477\",\"46\":\"-1.35942884\",\"47\":\"0.70581219\",\"48\":\"-0.901748405\",\"49\":\"-1.12355185\",\"50\":\"-0.72224439\",\"51\":\"-1.691377837\"},{\"1\":\"-0.0871878508\",\"2\":\"0.37240304\",\"3\":\"-1.15879992\",\"4\":\"-0.20484272\",\"5\":\"-2.6228351\",\"6\":\"0.625216022\",\"7\":\"0.48682035\",\"8\":\"-3.41994823\",\"9\":\"-1.50737686\",\"10\":\"0.01954615\",\"11\":\"0.84003407\",\"12\":\"-0.97309741\",\"13\":\"0.157445693\",\"14\":\"-0.57404571\",\"15\":\"0.50903477\",\"16\":\"0.67691010\",\"17\":\"2.165325817\",\"18\":\"-2.16057620\",\"19\":\"-0.65592522\",\"20\":\"-1.98635419\",\"21\":\"1.7245324\",\"22\":\"-0.98376417\",\"23\":\"-0.96600997\",\"24\":\"-0.82056591\",\"25\":\"1.634150830\",\"26\":\"1.699258353\",\"27\":\"-1.28644372\",\"28\":\"1.66252482\",\"29\":\"-0.43134581\",\"30\":\"2.122342787\",\"31\":\"-2.865966804\",\"32\":\"1.152370258\",\"33\":\"-1.76503111\",\"34\":\"-0.87886120\",\"35\":\"-2.521113195\",\"36\":\"-1.51903725\",\"37\":\"-0.27695802\",\"38\":\"-1.5115341\",\"39\":\"-0.78085642\",\"40\":\"-0.198076480\",\"41\":\"-0.16311985\",\"42\":\"1.70450001\",\"43\":\"-1.923573087\",\"44\":\"-0.25007412\",\"45\":\"-0.28913645\",\"46\":\"-0.83682215\",\"47\":\"-0.12882723\",\"48\":\"0.489909898\",\"49\":\"-0.26654250\",\"50\":\"-1.06189891\",\"51\":\"-0.550008776\"},{\"1\":\"1.2181187952\",\"2\":\"-2.92008512\",\"3\":\"-0.03734962\",\"4\":\"-0.47129410\",\"5\":\"-2.3529256\",\"6\":\"-0.567923116\",\"7\":\"1.03543733\",\"8\":\"-0.69328261\",\"9\":\"0.04686794\",\"10\":\"-0.54634955\",\"11\":\"-1.18230939\",\"12\":\"-1.30647904\",\"13\":\"-0.338040934\",\"14\":\"-1.44129754\",\"15\":\"0.97459245\",\"16\":\"0.28370352\",\"17\":\"0.405496768\",\"18\":\"-1.39325675\",\"19\":\"-0.92584603\",\"20\":\"-1.30293310\",\"21\":\"2.4398316\",\"22\":\"0.34619174\",\"23\":\"0.35016167\",\"24\":\"0.19136643\",\"25\":\"0.837156355\",\"26\":\"-1.070809985\",\"27\":\"-0.60305987\",\"28\":\"0.62368052\",\"29\":\"0.30223620\",\"30\":\"0.274809663\",\"31\":\"1.494456815\",\"32\":\"1.439178302\",\"33\":\"1.75047418\",\"34\":\"-2.58788029\",\"35\":\"-0.231679197\",\"36\":\"-0.91299310\",\"37\":\"-1.22069111\",\"38\":\"-3.2625137\",\"39\":\"-1.18284565\",\"40\":\"-1.213937212\",\"41\":\"1.09319619\",\"42\":\"0.55202391\",\"43\":\"-0.004132205\",\"44\":\"-1.11637123\",\"45\":\"0.39841891\",\"46\":\"-0.22840785\",\"47\":\"-2.39688275\",\"48\":\"-4.503381727\",\"49\":\"-1.06873836\",\"50\":\"-3.37958677\",\"51\":\"-0.241653956\"},{\"1\":\"0.2542888151\",\"2\":\"0.25170444\",\"3\":\"-0.86766797\",\"4\":\"1.43630537\",\"5\":\"-1.8397054\",\"6\":\"0.946591086\",\"7\":\"-0.27417429\",\"8\":\"-2.91035391\",\"9\":\"-0.42212323\",\"10\":\"-0.46146166\",\"11\":\"0.03068760\",\"12\":\"-0.28772772\",\"13\":\"-1.574761496\",\"14\":\"-1.79602308\",\"15\":\"0.03549981\",\"16\":\"0.74790417\",\"17\":\"-1.336368850\",\"18\":\"0.95375223\",\"19\":\"-0.51560400\",\"20\":\"-2.82709933\",\"21\":\"1.8547246\",\"22\":\"-0.21475716\",\"23\":\"0.80164056\",\"24\":\"0.72397423\",\"25\":\"-0.422718645\",\"26\":\"-1.884483445\",\"27\":\"-1.24395173\",\"28\":\"-1.01184835\",\"29\":\"-1.13821484\",\"30\":\"0.532475709\",\"31\":\"0.474752144\",\"32\":\"0.893298673\",\"33\":\"-2.95901244\",\"34\":\"0.03886716\",\"35\":\"-0.369458810\",\"36\":\"-1.37497287\",\"37\":\"-1.99747738\",\"38\":\"-1.0740718\",\"39\":\"-2.50516641\",\"40\":\"-0.999155636\",\"41\":\"-0.53556007\",\"42\":\"3.03346637\",\"43\":\"-0.339161266\",\"44\":\"-1.86050310\",\"45\":\"0.28900836\",\"46\":\"-0.56825311\",\"47\":\"1.27087385\",\"48\":\"-1.888670477\",\"49\":\"-3.01821510\",\"50\":\"-1.31347497\",\"51\":\"1.209114050\"},{\"1\":\"-1.1670971891\",\"2\":\"-2.33855439\",\"3\":\"1.32194217\",\"4\":\"0.06082246\",\"5\":\"-1.1140650\",\"6\":\"-0.242632291\",\"7\":\"0.67785326\",\"8\":\"0.23938706\",\"9\":\"-1.16800631\",\"10\":\"-0.89550393\",\"11\":\"-0.42065464\",\"12\":\"-1.66605643\",\"13\":\"-0.449174718\",\"14\":\"1.58716608\",\"15\":\"-0.26191148\",\"16\":\"1.80319926\",\"17\":\"1.519481960\",\"18\":\"0.29055235\",\"19\":\"-1.30225863\",\"20\":\"-0.50123225\",\"21\":\"1.7067544\",\"22\":\"-0.86237829\",\"23\":\"-0.22602699\",\"24\":\"0.05923610\",\"25\":\"-0.080588584\",\"26\":\"-0.411470097\",\"27\":\"-2.22717637\",\"28\":\"1.43051824\",\"29\":\"-2.75177519\",\"30\":\"-0.594122587\",\"31\":\"-0.302255625\",\"32\":\"1.320757534\",\"33\":\"-0.30275880\",\"34\":\"-0.96954018\",\"35\":\"-2.180029331\",\"36\":\"-0.40033128\",\"37\":\"-1.28864836\",\"38\":\"-2.2941930\",\"39\":\"-1.03130700\",\"40\":\"-1.911527921\",\"41\":\"-0.03885813\",\"42\":\"2.84225489\",\"43\":\"-0.405986139\",\"44\":\"-0.48279852\",\"45\":\"1.22233866\",\"46\":\"-0.06707468\",\"47\":\"-2.72578054\",\"48\":\"-0.004853552\",\"49\":\"-1.87251958\",\"50\":\"-0.03601348\",\"51\":\"0.504663295\"},{\"1\":\"0.4815892726\",\"2\":\"-2.42016409\",\"3\":\"0.27053871\",\"4\":\"3.66761047\",\"5\":\"-2.0690124\",\"6\":\"0.804442715\",\"7\":\"-1.10300090\",\"8\":\"-0.73232997\",\"9\":\"0.23003199\",\"10\":\"-0.86819662\",\"11\":\"-0.97879194\",\"12\":\"0.16020951\",\"13\":\"-1.858902647\",\"14\":\"0.12918459\",\"15\":\"-2.24956532\",\"16\":\"-0.54934555\",\"17\":\"-0.344397742\",\"18\":\"-0.21057114\",\"19\":\"-0.96537304\",\"20\":\"-2.58397698\",\"21\":\"1.1101266\",\"22\":\"1.17696006\",\"23\":\"-1.79116145\",\"24\":\"-1.04236237\",\"25\":\"-0.034033179\",\"26\":\"-1.959528152\",\"27\":\"-2.53285004\",\"28\":\"-0.02823795\",\"29\":\"-1.61254027\",\"30\":\"0.227007075\",\"31\":\"0.182506362\",\"32\":\"2.975772754\",\"33\":\"-0.53449723\",\"34\":\"-0.09117938\",\"35\":\"-1.027137564\",\"36\":\"-1.04568946\",\"37\":\"-1.37727731\",\"38\":\"-0.9508913\",\"39\":\"-1.51948701\",\"40\":\"1.586600050\",\"41\":\"-0.54916074\",\"42\":\"-0.36276197\",\"43\":\"-1.450049926\",\"44\":\"-0.83591846\",\"45\":\"-0.15153760\",\"46\":\"-0.94820548\",\"47\":\"-2.08153041\",\"48\":\"-0.578573173\",\"49\":\"0.40405715\",\"50\":\"1.64420442\",\"51\":\"-0.992433400\"},{\"1\":\"0.6657098389\",\"2\":\"-2.40349685\",\"3\":\"-0.01355838\",\"4\":\"2.31076494\",\"5\":\"-4.4453989\",\"6\":\"0.013523005\",\"7\":\"-1.16909520\",\"8\":\"-1.85433804\",\"9\":\"0.19393607\",\"10\":\"-0.76192452\",\"11\":\"-1.34578266\",\"12\":\"0.07838690\",\"13\":\"-0.232991487\",\"14\":\"-0.30865782\",\"15\":\"-0.13825393\",\"16\":\"0.04285289\",\"17\":\"1.359737039\",\"18\":\"-0.67852111\",\"19\":\"-0.90365646\",\"20\":\"-2.75836472\",\"21\":\"2.6061206\",\"22\":\"1.84055957\",\"23\":\"-0.90899049\",\"24\":\"-1.98094317\",\"25\":\"1.467608917\",\"26\":\"-2.118128108\",\"27\":\"-3.07086211\",\"28\":\"-0.46220010\",\"29\":\"-1.58078090\",\"30\":\"0.272520866\",\"31\":\"0.108424029\",\"32\":\"1.364019351\",\"33\":\"0.07185922\",\"34\":\"1.33849692\",\"35\":\"-0.676382684\",\"36\":\"-2.21621824\",\"37\":\"-1.12802970\",\"38\":\"-2.2033365\",\"39\":\"-1.99551776\",\"40\":\"-0.449888220\",\"41\":\"1.69050020\",\"42\":\"1.23317659\",\"43\":\"-0.222750946\",\"44\":\"-0.74483582\",\"45\":\"-0.98180595\",\"46\":\"-1.49862572\",\"47\":\"-1.01165471\",\"48\":\"-0.317923789\",\"49\":\"0.55781950\",\"50\":\"-0.02313350\",\"51\":\"-0.141299660\"},{\"1\":\"-0.3527891871\",\"2\":\"-1.06561419\",\"3\":\"1.28828534\",\"4\":\"2.16895300\",\"5\":\"-3.1494731\",\"6\":\"1.588793288\",\"7\":\"1.44857082\",\"8\":\"-0.94298157\",\"9\":\"-0.46920304\",\"10\":\"-1.63529236\",\"11\":\"-1.13513469\",\"12\":\"-0.28493560\",\"13\":\"-1.804077961\",\"14\":\"0.22116743\",\"15\":\"-0.71972881\",\"16\":\"0.20396156\",\"17\":\"0.850983828\",\"18\":\"-0.98100441\",\"19\":\"0.66153992\",\"20\":\"-0.27696110\",\"21\":\"3.3680380\",\"22\":\"-1.38715507\",\"23\":\"0.04226716\",\"24\":\"1.18252450\",\"25\":\"-0.137099852\",\"26\":\"-0.909191161\",\"27\":\"-0.99194714\",\"28\":\"1.75812051\",\"29\":\"0.02408475\",\"30\":\"0.380844655\",\"31\":\"-0.076740696\",\"32\":\"2.436992066\",\"33\":\"-0.88606668\",\"34\":\"-1.86506488\",\"35\":\"-1.057888824\",\"36\":\"-0.18242811\",\"37\":\"0.31337094\",\"38\":\"-2.9151451\",\"39\":\"0.23516407\",\"40\":\"-1.048807608\",\"41\":\"0.87207052\",\"42\":\"1.99935232\",\"43\":\"-0.957050839\",\"44\":\"0.30120580\",\"45\":\"1.87308421\",\"46\":\"-1.29478948\",\"47\":\"1.25707259\",\"48\":\"-0.650218687\",\"49\":\"-2.42702265\",\"50\":\"0.09638208\",\"51\":\"-1.631458001\"},{\"1\":\"1.2084354524\",\"2\":\"-1.60089818\",\"3\":\"1.38907288\",\"4\":\"1.21118437\",\"5\":\"-1.5416150\",\"6\":\"-0.426917280\",\"7\":\"0.58563045\",\"8\":\"0.45936508\",\"9\":\"-0.39911932\",\"10\":\"-0.35868448\",\"11\":\"-1.88549696\",\"12\":\"0.54963344\",\"13\":\"-2.810733430\",\"14\":\"-0.91499413\",\"15\":\"0.51332967\",\"16\":\"-0.45423725\",\"17\":\"-0.394677054\",\"18\":\"-0.62427571\",\"19\":\"0.28215714\",\"20\":\"-2.40600574\",\"21\":\"2.6814020\",\"22\":\"1.28100510\",\"23\":\"-1.03001446\",\"24\":\"-0.46833892\",\"25\":\"-0.702090554\",\"26\":\"-1.879307612\",\"27\":\"-1.26413162\",\"28\":\"0.89257777\",\"29\":\"0.03237287\",\"30\":\"0.168482259\",\"31\":\"0.005886691\",\"32\":\"1.350044192\",\"33\":\"1.92681208\",\"34\":\"0.64350137\",\"35\":\"0.050590349\",\"36\":\"-1.18569943\",\"37\":\"-0.60095920\",\"38\":\"-3.5205545\",\"39\":\"-2.04239693\",\"40\":\"-2.455246303\",\"41\":\"-0.69820199\",\"42\":\"1.93223250\",\"43\":\"-1.136412985\",\"44\":\"-1.39758509\",\"45\":\"-0.58386914\",\"46\":\"-0.17142410\",\"47\":\"-0.46219773\",\"48\":\"-0.568485077\",\"49\":\"-1.61868914\",\"50\":\"-1.48973133\",\"51\":\"0.381353670\"},{\"1\":\"-2.7663776233\",\"2\":\"-1.26902405\",\"3\":\"-2.01655673\",\"4\":\"-0.03700084\",\"5\":\"-2.5233726\",\"6\":\"0.290370793\",\"7\":\"1.91745796\",\"8\":\"-1.05279991\",\"9\":\"-0.91650482\",\"10\":\"-1.02781622\",\"11\":\"-0.62997530\",\"12\":\"-1.46067053\",\"13\":\"0.705154684\",\"14\":\"-1.85299398\",\"15\":\"-0.39594261\",\"16\":\"0.25310057\",\"17\":\"-0.051807472\",\"18\":\"-0.25950687\",\"19\":\"0.07448529\",\"20\":\"-1.28022078\",\"21\":\"1.7225711\",\"22\":\"0.36852784\",\"23\":\"-0.28641942\",\"24\":\"-1.03612933\",\"25\":\"0.964277275\",\"26\":\"-1.156080066\",\"27\":\"-1.39022855\",\"28\":\"1.06864318\",\"29\":\"-0.72404254\",\"30\":\"1.967646339\",\"31\":\"0.126182982\",\"32\":\"-0.273487315\",\"33\":\"-0.61981402\",\"34\":\"-1.07696202\",\"35\":\"-2.077309574\",\"36\":\"-1.05114658\",\"37\":\"0.62196110\",\"38\":\"-3.5531055\",\"39\":\"-1.09811680\",\"40\":\"-0.723755539\",\"41\":\"-0.59330163\",\"42\":\"2.21034499\",\"43\":\"0.418455373\",\"44\":\"-2.10456592\",\"45\":\"0.52695677\",\"46\":\"-1.84360887\",\"47\":\"-0.23811827\",\"48\":\"-1.092675070\",\"49\":\"-0.89836044\",\"50\":\"-0.36117341\",\"51\":\"0.476066796\"},{\"1\":\"-0.4799554687\",\"2\":\"-1.49486661\",\"3\":\"0.93331401\",\"4\":\"1.37364917\",\"5\":\"-2.8398545\",\"6\":\"-0.188337222\",\"7\":\"0.33569498\",\"8\":\"-0.18566708\",\"9\":\"0.25723586\",\"10\":\"0.13919623\",\"11\":\"-0.45573348\",\"12\":\"-1.40988789\",\"13\":\"-1.384079214\",\"14\":\"-1.48944650\",\"15\":\"0.67864955\",\"16\":\"3.59940299\",\"17\":\"-0.899558686\",\"18\":\"1.32343029\",\"19\":\"-0.46255181\",\"20\":\"-0.46966698\",\"21\":\"2.7930220\",\"22\":\"0.67730704\",\"23\":\"-1.01660107\",\"24\":\"-0.96965760\",\"25\":\"1.321769996\",\"26\":\"0.564442561\",\"27\":\"-0.75608920\",\"28\":\"0.89103789\",\"29\":\"-1.40880319\",\"30\":\"-1.981915208\",\"31\":\"-1.626053431\",\"32\":\"-0.088242236\",\"33\":\"-0.45219664\",\"34\":\"-0.76775050\",\"35\":\"-1.455550833\",\"36\":\"-2.55092843\",\"37\":\"-0.05357141\",\"38\":\"-2.3290967\",\"39\":\"-0.82495744\",\"40\":\"-0.843421763\",\"41\":\"-0.48758294\",\"42\":\"1.00383825\",\"43\":\"-0.311419347\",\"44\":\"-2.13537723\",\"45\":\"0.65036846\",\"46\":\"-1.94795017\",\"47\":\"0.75956328\",\"48\":\"-2.023807328\",\"49\":\"-0.93282966\",\"50\":\"-2.60206566\",\"51\":\"1.624267148\"},{\"1\":\"0.5576647598\",\"2\":\"-2.03220996\",\"3\":\"-0.12247920\",\"4\":\"1.72259607\",\"5\":\"-1.3655762\",\"6\":\"0.693793861\",\"7\":\"-0.87075445\",\"8\":\"0.66907560\",\"9\":\"1.03215478\",\"10\":\"-1.32476542\",\"11\":\"1.14043400\",\"12\":\"-1.44006594\",\"13\":\"-0.334220573\",\"14\":\"-1.83896082\",\"15\":\"-0.16778469\",\"16\":\"-0.28896234\",\"17\":\"-2.032368006\",\"18\":\"-0.37921361\",\"19\":\"-0.39829181\",\"20\":\"-0.93551945\",\"21\":\"3.1425220\",\"22\":\"-0.25098419\",\"23\":\"0.05709667\",\"24\":\"0.47471640\",\"25\":\"2.575055789\",\"26\":\"1.273323254\",\"27\":\"-2.81444248\",\"28\":\"-0.12291191\",\"29\":\"-1.17046698\",\"30\":\"0.529589950\",\"31\":\"-1.204486456\",\"32\":\"0.128478927\",\"33\":\"0.64852886\",\"34\":\"-1.24165813\",\"35\":\"-0.951121485\",\"36\":\"-1.87842017\",\"37\":\"0.62645527\",\"38\":\"-4.1863156\",\"39\":\"-0.28983843\",\"40\":\"-1.696609742\",\"41\":\"-0.35264346\",\"42\":\"0.24416285\",\"43\":\"-3.942685217\",\"44\":\"-1.87929742\",\"45\":\"0.17427910\",\"46\":\"-0.68086136\",\"47\":\"0.01626565\",\"48\":\"-2.334133283\",\"49\":\"-1.83194287\",\"50\":\"-0.03860130\",\"51\":\"-0.082326423\"},{\"1\":\"-0.6827169940\",\"2\":\"-0.85989753\",\"3\":\"0.98432948\",\"4\":\"0.98907394\",\"5\":\"-2.4462658\",\"6\":\"1.241555076\",\"7\":\"-0.39336447\",\"8\":\"-0.45863576\",\"9\":\"0.31492696\",\"10\":\"-1.44696698\",\"11\":\"-1.64953984\",\"12\":\"-1.29090481\",\"13\":\"-2.129735910\",\"14\":\"1.81646457\",\"15\":\"-0.74587890\",\"16\":\"-0.51695141\",\"17\":\"-0.988305853\",\"18\":\"-0.59896460\",\"19\":\"-0.03463031\",\"20\":\"-0.11152294\",\"21\":\"2.6747391\",\"22\":\"0.64814371\",\"23\":\"0.86382525\",\"24\":\"-1.86354719\",\"25\":\"1.269566090\",\"26\":\"-1.401301617\",\"27\":\"-0.90899563\",\"28\":\"0.59277163\",\"29\":\"-0.34975217\",\"30\":\"0.514569914\",\"31\":\"-0.818426600\",\"32\":\"1.002666349\",\"33\":\"0.22218141\",\"34\":\"-1.20794051\",\"35\":\"0.942648335\",\"36\":\"-2.85099212\",\"37\":\"-2.53216816\",\"38\":\"-3.7396082\",\"39\":\"-0.97368880\",\"40\":\"2.089677964\",\"41\":\"-1.03099295\",\"42\":\"1.75096301\",\"43\":\"-1.495185173\",\"44\":\"-2.24301521\",\"45\":\"1.14479769\",\"46\":\"-0.38186677\",\"47\":\"-2.19325219\",\"48\":\"-1.071165325\",\"49\":\"-2.20526459\",\"50\":\"0.17294066\",\"51\":\"-0.971568431\"},{\"1\":\"0.5949693040\",\"2\":\"-2.12715869\",\"3\":\"-0.56436449\",\"4\":\"0.27746197\",\"5\":\"-1.3748492\",\"6\":\"1.002533587\",\"7\":\"2.04963928\",\"8\":\"1.65480955\",\"9\":\"-1.03292427\",\"10\":\"0.37401839\",\"11\":\"-0.94492540\",\"12\":\"-0.67170509\",\"13\":\"-1.138675815\",\"14\":\"-1.93879023\",\"15\":\"-2.07412372\",\"16\":\"-0.17513093\",\"17\":\"-0.050935174\",\"18\":\"-0.09272849\",\"19\":\"-0.42920554\",\"20\":\"-1.67991957\",\"21\":\"3.2217366\",\"22\":\"0.44209244\",\"23\":\"-1.19718493\",\"24\":\"-0.78328861\",\"25\":\"0.450874107\",\"26\":\"-1.127666772\",\"27\":\"-2.77013696\",\"28\":\"0.39544995\",\"29\":\"-0.21206680\",\"30\":\"-0.728093601\",\"31\":\"-1.791553927\",\"32\":\"0.991562546\",\"33\":\"-0.29468560\",\"34\":\"-1.85957962\",\"35\":\"-0.656512149\",\"36\":\"-1.70163312\",\"37\":\"-1.87505925\",\"38\":\"-0.2173381\",\"39\":\"0.63222212\",\"40\":\"0.578650492\",\"41\":\"-0.38519715\",\"42\":\"-0.08964896\",\"43\":\"-2.556049019\",\"44\":\"-0.90458575\",\"45\":\"-0.48961417\",\"46\":\"-2.68542330\",\"47\":\"-0.25878810\",\"48\":\"-1.528711306\",\"49\":\"-1.43141447\",\"50\":\"-0.33831420\",\"51\":\"-0.430856464\"},{\"1\":\"-2.0952454246\",\"2\":\"-1.49440221\",\"3\":\"0.90527392\",\"4\":\"2.69263686\",\"5\":\"-2.6560646\",\"6\":\"-0.182631506\",\"7\":\"-1.31308647\",\"8\":\"-0.21296722\",\"9\":\"0.75991202\",\"10\":\"-2.88612865\",\"11\":\"-1.83131748\",\"12\":\"1.43881989\",\"13\":\"-0.337145366\",\"14\":\"-1.50540852\",\"15\":\"-0.80894150\",\"16\":\"0.46466307\",\"17\":\"-0.464420465\",\"18\":\"0.62506854\",\"19\":\"-1.30921861\",\"20\":\"-1.26755187\",\"21\":\"0.8896019\",\"22\":\"1.97324215\",\"23\":\"-1.65784546\",\"24\":\"0.81471499\",\"25\":\"0.621161121\",\"26\":\"-0.436853433\",\"27\":\"-1.72949358\",\"28\":\"-0.07533197\",\"29\":\"0.73242753\",\"30\":\"0.043991428\",\"31\":\"1.239257738\",\"32\":\"2.294492142\",\"33\":\"-0.64519591\",\"34\":\"-0.58319911\",\"35\":\"-1.522976969\",\"36\":\"-0.26419222\",\"37\":\"-1.72390361\",\"38\":\"-2.3583579\",\"39\":\"-0.89585644\",\"40\":\"-1.829959746\",\"41\":\"-1.16166895\",\"42\":\"2.08486699\",\"43\":\"-0.479851078\",\"44\":\"0.95559610\",\"45\":\"-1.51202578\",\"46\":\"-0.20964145\",\"47\":\"-1.07773431\",\"48\":\"-2.006682601\",\"49\":\"-0.24217767\",\"50\":\"0.17690540\",\"51\":\"-0.999327740\"},{\"1\":\"-0.3493249175\",\"2\":\"-1.75819604\",\"3\":\"-0.58836477\",\"4\":\"1.49599448\",\"5\":\"-1.6907014\",\"6\":\"1.356706725\",\"7\":\"-0.32864306\",\"8\":\"-1.20583005\",\"9\":\"-0.50164217\",\"10\":\"-0.82371066\",\"11\":\"-1.60577774\",\"12\":\"0.22457652\",\"13\":\"0.005868016\",\"14\":\"-0.32529893\",\"15\":\"0.47359548\",\"16\":\"-0.44241555\",\"17\":\"0.621754547\",\"18\":\"1.12213451\",\"19\":\"0.05382312\",\"20\":\"-2.14028109\",\"21\":\"2.3567498\",\"22\":\"1.72749287\",\"23\":\"-1.14884013\",\"24\":\"0.11895805\",\"25\":\"-0.456443004\",\"26\":\"-1.738905539\",\"27\":\"-3.55315179\",\"28\":\"-1.11698035\",\"29\":\"-2.24105569\",\"30\":\"-0.926075403\",\"31\":\"-2.260398491\",\"32\":\"-0.553588384\",\"33\":\"-0.71012113\",\"34\":\"-0.23657614\",\"35\":\"1.037211687\",\"36\":\"-2.08662449\",\"37\":\"-1.47770036\",\"38\":\"-0.8224190\",\"39\":\"-1.82947336\",\"40\":\"0.839681393\",\"41\":\"-1.56209967\",\"42\":\"2.15244804\",\"43\":\"-1.511242234\",\"44\":\"-0.95487470\",\"45\":\"-0.64122658\",\"46\":\"-0.98241494\",\"47\":\"0.81409358\",\"48\":\"-0.689876875\",\"49\":\"-1.22835927\",\"50\":\"-0.21214709\",\"51\":\"-1.322848544\"},{\"1\":\"-1.4719724308\",\"2\":\"-0.35842011\",\"3\":\"0.59253864\",\"4\":\"0.68195685\",\"5\":\"-2.7226109\",\"6\":\"0.888756857\",\"7\":\"1.78822174\",\"8\":\"1.07203823\",\"9\":\"-0.32163889\",\"10\":\"0.16240202\",\"11\":\"-1.66091492\",\"12\":\"0.49335674\",\"13\":\"-0.327581153\",\"14\":\"-1.06732473\",\"15\":\"-0.40012893\",\"16\":\"1.80176152\",\"17\":\"-0.427215048\",\"18\":\"-0.03908426\",\"19\":\"-0.35324182\",\"20\":\"-2.23734178\",\"21\":\"1.7780428\",\"22\":\"-0.22410863\",\"23\":\"-0.60233196\",\"24\":\"0.01782361\",\"25\":\"2.666523266\",\"26\":\"-0.713061524\",\"27\":\"-3.06580965\",\"28\":\"1.05318514\",\"29\":\"-0.64638286\",\"30\":\"-0.759410975\",\"31\":\"-0.793752297\",\"32\":\"0.056654256\",\"33\":\"-1.83052377\",\"34\":\"-0.89596525\",\"35\":\"-0.732434035\",\"36\":\"-1.56389325\",\"37\":\"-1.54379860\",\"38\":\"-0.5310476\",\"39\":\"-1.23848166\",\"40\":\"0.750546302\",\"41\":\"0.33854302\",\"42\":\"-0.45638660\",\"43\":\"-0.167337921\",\"44\":\"-0.07812751\",\"45\":\"-0.82783630\",\"46\":\"-1.17559536\",\"47\":\"-1.21195900\",\"48\":\"-0.953873456\",\"49\":\"-1.90101411\",\"50\":\"0.23663424\",\"51\":\"-0.329860678\"},{\"1\":\"0.6093718563\",\"2\":\"0.09644725\",\"3\":\"-0.95870109\",\"4\":\"1.19540353\",\"5\":\"-1.8351862\",\"6\":\"0.506834109\",\"7\":\"0.35074002\",\"8\":\"-0.20095347\",\"9\":\"-1.57471150\",\"10\":\"-1.74407643\",\"11\":\"-1.18090848\",\"12\":\"-0.60558918\",\"13\":\"-0.415082147\",\"14\":\"-2.46994627\",\"15\":\"0.42724350\",\"16\":\"0.78906168\",\"17\":\"-1.255853299\",\"18\":\"-1.26945164\",\"19\":\"-1.39567569\",\"20\":\"-0.87446830\",\"21\":\"2.9680712\",\"22\":\"-0.97878896\",\"23\":\"-1.21312753\",\"24\":\"-0.23949077\",\"25\":\"-0.319016847\",\"26\":\"-1.742150758\",\"27\":\"-2.17193679\",\"28\":\"-0.09238199\",\"29\":\"-0.76494809\",\"30\":\"-2.226778653\",\"31\":\"-1.730593549\",\"32\":\"-0.637941588\",\"33\":\"0.15436300\",\"34\":\"-2.32872649\",\"35\":\"0.050665802\",\"36\":\"-0.84511313\",\"37\":\"-0.70909325\",\"38\":\"-2.0605551\",\"39\":\"-0.67186395\",\"40\":\"0.295536830\",\"41\":\"0.19074658\",\"42\":\"2.38841771\",\"43\":\"-0.600814383\",\"44\":\"-1.95796096\",\"45\":\"0.04737301\",\"46\":\"0.11261433\",\"47\":\"-2.49562134\",\"48\":\"0.355964853\",\"49\":\"-1.75636011\",\"50\":\"1.31863551\",\"51\":\"-1.393114584\"},{\"1\":\"0.4773583820\",\"2\":\"-1.73569907\",\"3\":\"0.35447551\",\"4\":\"1.73847725\",\"5\":\"-1.9094693\",\"6\":\"-0.364887988\",\"7\":\"-1.28232357\",\"8\":\"-2.11862988\",\"9\":\"0.02418676\",\"10\":\"-0.53567616\",\"11\":\"1.28401991\",\"12\":\"-1.87189783\",\"13\":\"-1.230446668\",\"14\":\"-0.53158364\",\"15\":\"-2.45219659\",\"16\":\"-0.57204556\",\"17\":\"-0.968996574\",\"18\":\"-0.06810608\",\"19\":\"-1.28269028\",\"20\":\"-1.24661951\",\"21\":\"3.8195819\",\"22\":\"0.63000672\",\"23\":\"-1.77611819\",\"24\":\"-1.15696047\",\"25\":\"0.585746468\",\"26\":\"-1.511329804\",\"27\":\"-1.14146387\",\"28\":\"1.89283675\",\"29\":\"-2.74690506\",\"30\":\"1.254913150\",\"31\":\"-0.846724794\",\"32\":\"1.615418318\",\"33\":\"-0.02832293\",\"34\":\"-1.11219908\",\"35\":\"0.620535976\",\"36\":\"-3.21680154\",\"37\":\"-2.42876841\",\"38\":\"-2.1764190\",\"39\":\"-3.53150200\",\"40\":\"0.104809876\",\"41\":\"-1.03392822\",\"42\":\"1.22500416\",\"43\":\"-1.046602405\",\"44\":\"-1.07700942\",\"45\":\"-1.21392283\",\"46\":\"0.48505479\",\"47\":\"-0.47667995\",\"48\":\"-2.228820690\",\"49\":\"0.36240561\",\"50\":\"0.58853472\",\"51\":\"-0.328664570\"},{\"1\":\"-0.4052945214\",\"2\":\"-0.44411509\",\"3\":\"2.36441466\",\"4\":\"2.15350692\",\"5\":\"-2.4593355\",\"6\":\"1.184772386\",\"7\":\"0.20695868\",\"8\":\"-1.08564427\",\"9\":\"-0.64511972\",\"10\":\"-0.08472056\",\"11\":\"0.12808837\",\"12\":\"0.23136072\",\"13\":\"-0.617153375\",\"14\":\"-1.80432248\",\"15\":\"0.20241752\",\"16\":\"0.25186352\",\"17\":\"-2.493195182\",\"18\":\"-0.55015150\",\"19\":\"-1.84464881\",\"20\":\"-0.23499934\",\"21\":\"2.9278867\",\"22\":\"-1.24046606\",\"23\":\"1.25579953\",\"24\":\"-0.55240974\",\"25\":\"1.228978223\",\"26\":\"-0.813965932\",\"27\":\"-1.22260871\",\"28\":\"1.55921905\",\"29\":\"-1.23541336\",\"30\":\"-0.562322233\",\"31\":\"-0.766940033\",\"32\":\"0.656340700\",\"33\":\"-1.51963494\",\"34\":\"-0.29662780\",\"35\":\"-0.091712668\",\"36\":\"-2.99845778\",\"37\":\"-1.69508443\",\"38\":\"-1.9835962\",\"39\":\"-1.43655724\",\"40\":\"-0.149344674\",\"41\":\"0.80688830\",\"42\":\"0.77567949\",\"43\":\"-1.153750555\",\"44\":\"-0.28926967\",\"45\":\"0.40018782\",\"46\":\"-2.14173952\",\"47\":\"-0.61401066\",\"48\":\"-1.625106276\",\"49\":\"-1.69894570\",\"50\":\"-0.49116416\",\"51\":\"-0.141881696\"},{\"1\":\"-0.1939349288\",\"2\":\"0.58324468\",\"3\":\"1.49096512\",\"4\":\"-0.79896896\",\"5\":\"-1.0062888\",\"6\":\"-1.060922721\",\"7\":\"0.95301740\",\"8\":\"0.57396098\",\"9\":\"-3.01821930\",\"10\":\"-2.15616177\",\"11\":\"-0.08671830\",\"12\":\"-0.68280467\",\"13\":\"-0.248031171\",\"14\":\"-2.07682375\",\"15\":\"-0.16550404\",\"16\":\"0.70675592\",\"17\":\"0.758961330\",\"18\":\"-1.19719634\",\"19\":\"-2.43125442\",\"20\":\"-1.89352884\",\"21\":\"3.0763143\",\"22\":\"0.69029837\",\"23\":\"-1.02989552\",\"24\":\"-1.28452898\",\"25\":\"-1.092871874\",\"26\":\"-0.782171637\",\"27\":\"-0.51248887\",\"28\":\"0.27622069\",\"29\":\"-1.57590219\",\"30\":\"0.589881974\",\"31\":\"-0.984312993\",\"32\":\"-0.736896230\",\"33\":\"-0.66287865\",\"34\":\"-1.43015944\",\"35\":\"0.799003465\",\"36\":\"-2.55661327\",\"37\":\"-1.72443348\",\"38\":\"-1.5003001\",\"39\":\"-1.29946748\",\"40\":\"0.324867359\",\"41\":\"-0.65844146\",\"42\":\"1.89528371\",\"43\":\"-1.429909866\",\"44\":\"-1.21032398\",\"45\":\"-1.44450540\",\"46\":\"0.01731430\",\"47\":\"-0.98614067\",\"48\":\"-1.182265281\",\"49\":\"-0.48880912\",\"50\":\"-1.63827708\",\"51\":\"-0.548955074\"},{\"1\":\"-1.6606098792\",\"2\":\"-0.69141232\",\"3\":\"1.16611833\",\"4\":\"-0.35848579\",\"5\":\"-2.3675491\",\"6\":\"-1.522977256\",\"7\":\"1.57336431\",\"8\":\"-1.29360968\",\"9\":\"0.02176282\",\"10\":\"-1.94985049\",\"11\":\"-1.69527123\",\"12\":\"-0.20478692\",\"13\":\"-2.336841381\",\"14\":\"-1.89051090\",\"15\":\"-0.23620204\",\"16\":\"1.05091637\",\"17\":\"0.393040206\",\"18\":\"-1.89522974\",\"19\":\"-1.23652569\",\"20\":\"-1.38612535\",\"21\":\"1.8966600\",\"22\":\"-0.34657993\",\"23\":\"0.45791397\",\"24\":\"0.37152041\",\"25\":\"1.420947211\",\"26\":\"0.122661538\",\"27\":\"-1.00580006\",\"28\":\"0.89970308\",\"29\":\"-2.19154639\",\"30\":\"-0.289808967\",\"31\":\"-4.030603924\",\"32\":\"0.282449907\",\"33\":\"0.81169779\",\"34\":\"-1.29950527\",\"35\":\"-1.292179332\",\"36\":\"-1.32825191\",\"37\":\"-1.54205799\",\"38\":\"-1.3789148\",\"39\":\"-1.57959407\",\"40\":\"-1.326912965\",\"41\":\"-0.74956276\",\"42\":\"2.73011337\",\"43\":\"-0.869136222\",\"44\":\"-0.07010203\",\"45\":\"1.47482651\",\"46\":\"-1.62640927\",\"47\":\"-2.02506464\",\"48\":\"-2.515108274\",\"49\":\"0.21973280\",\"50\":\"-0.10577030\",\"51\":\"-0.692784576\"},{\"1\":\"1.3699286245\",\"2\":\"-0.69710942\",\"3\":\"-0.76352255\",\"4\":\"1.54547102\",\"5\":\"-1.9725332\",\"6\":\"-0.023274061\",\"7\":\"-0.48090423\",\"8\":\"1.16308265\",\"9\":\"0.71253900\",\"10\":\"-2.67356998\",\"11\":\"0.99228012\",\"12\":\"0.48829723\",\"13\":\"-1.192778472\",\"14\":\"0.45767559\",\"15\":\"1.13908960\",\"16\":\"1.99950183\",\"17\":\"0.133170032\",\"18\":\"0.33405979\",\"19\":\"-0.04186571\",\"20\":\"1.43700543\",\"21\":\"3.1375204\",\"22\":\"1.35697197\",\"23\":\"-1.44093513\",\"24\":\"-0.03817201\",\"25\":\"0.765677834\",\"26\":\"-1.098598951\",\"27\":\"-0.99368588\",\"28\":\"1.50378452\",\"29\":\"-0.77393831\",\"30\":\"2.008703174\",\"31\":\"-3.432202079\",\"32\":\"0.107087997\",\"33\":\"0.79849973\",\"34\":\"-1.87906666\",\"35\":\"1.097361393\",\"36\":\"-1.54862452\",\"37\":\"-1.77201924\",\"38\":\"-4.1952402\",\"39\":\"-1.28962466\",\"40\":\"-0.943649997\",\"41\":\"-1.41956925\",\"42\":\"3.01462640\",\"43\":\"-2.176896978\",\"44\":\"-0.16131726\",\"45\":\"1.16901436\",\"46\":\"-0.86197876\",\"47\":\"-1.80742898\",\"48\":\"-1.392024061\",\"49\":\"-0.80832098\",\"50\":\"-0.92406336\",\"51\":\"-1.145919709\"},{\"1\":\"0.4866298102\",\"2\":\"-0.32953099\",\"3\":\"1.58843468\",\"4\":\"1.68272110\",\"5\":\"-1.3706391\",\"6\":\"-0.939501446\",\"7\":\"2.36313355\",\"8\":\"-0.30726421\",\"9\":\"-0.67217445\",\"10\":\"-0.46071365\",\"11\":\"1.11614724\",\"12\":\"0.21083052\",\"13\":\"-1.700223589\",\"14\":\"-0.93244746\",\"15\":\"0.39888512\",\"16\":\"0.75582553\",\"17\":\"0.010604295\",\"18\":\"0.25355644\",\"19\":\"0.57900384\",\"20\":\"-0.50405087\",\"21\":\"2.1376729\",\"22\":\"1.11858419\",\"23\":\"-0.90751752\",\"24\":\"-0.91072395\",\"25\":\"0.309432701\",\"26\":\"-0.127302461\",\"27\":\"-2.41027887\",\"28\":\"0.29021351\",\"29\":\"-3.41609495\",\"30\":\"0.226923411\",\"31\":\"-0.215328311\",\"32\":\"1.399607674\",\"33\":\"-1.69675444\",\"34\":\"-0.11798339\",\"35\":\"-2.324158334\",\"36\":\"-0.38234664\",\"37\":\"0.03550781\",\"38\":\"-2.1326437\",\"39\":\"-3.33279955\",\"40\":\"-1.296301117\",\"41\":\"-0.49024819\",\"42\":\"0.24895023\",\"43\":\"-0.395848653\",\"44\":\"-1.48809453\",\"45\":\"-0.72941794\",\"46\":\"-0.51341401\",\"47\":\"-0.98114003\",\"48\":\"-1.815489371\",\"49\":\"-1.67370776\",\"50\":\"0.96966498\",\"51\":\"-1.606617189\"},{\"1\":\"0.0103614843\",\"2\":\"-1.51222513\",\"3\":\"1.13599491\",\"4\":\"0.19996488\",\"5\":\"-1.9170068\",\"6\":\"0.724935574\",\"7\":\"0.49217323\",\"8\":\"-1.12526416\",\"9\":\"0.16686752\",\"10\":\"-0.99963469\",\"11\":\"-1.73032683\",\"12\":\"-2.54246461\",\"13\":\"-2.364125085\",\"14\":\"-0.25212270\",\"15\":\"0.24821649\",\"16\":\"-0.64132862\",\"17\":\"0.286200594\",\"18\":\"-0.51190466\",\"19\":\"-0.29873072\",\"20\":\"-0.37265939\",\"21\":\"1.8911358\",\"22\":\"1.71729042\",\"23\":\"-0.07745090\",\"24\":\"0.71400346\",\"25\":\"0.924226308\",\"26\":\"-2.402350583\",\"27\":\"-2.58067013\",\"28\":\"3.59723133\",\"29\":\"0.04888548\",\"30\":\"2.203703139\",\"31\":\"-1.828106454\",\"32\":\"1.659714041\",\"33\":\"0.32642883\",\"34\":\"-1.37807899\",\"35\":\"-1.476621175\",\"36\":\"-2.86354257\",\"37\":\"-0.39874603\",\"38\":\"-1.5669430\",\"39\":\"-0.99475691\",\"40\":\"-0.460174819\",\"41\":\"-0.60288351\",\"42\":\"1.01180130\",\"43\":\"-1.462756357\",\"44\":\"-1.62732328\",\"45\":\"-0.14055571\",\"46\":\"-0.86116245\",\"47\":\"0.06959583\",\"48\":\"-3.254957194\",\"49\":\"-1.29198751\",\"50\":\"-2.13090906\",\"51\":\"0.352424245\"},{\"1\":\"-0.6135147480\",\"2\":\"-2.20568678\",\"3\":\"-0.27237500\",\"4\":\"1.44514906\",\"5\":\"-2.6169119\",\"6\":\"2.052608214\",\"7\":\"1.07161523\",\"8\":\"-0.18311011\",\"9\":\"-1.00954606\",\"10\":\"0.22371545\",\"11\":\"-0.68411392\",\"12\":\"-2.63468711\",\"13\":\"0.187680509\",\"14\":\"-1.33492179\",\"15\":\"2.07926013\",\"16\":\"1.39599706\",\"17\":\"-0.746872211\",\"18\":\"-1.22944351\",\"19\":\"-0.04187004\",\"20\":\"-1.84286738\",\"21\":\"2.4783741\",\"22\":\"-0.39111893\",\"23\":\"-0.66296219\",\"24\":\"1.05057516\",\"25\":\"-0.011215150\",\"26\":\"-0.426511267\",\"27\":\"-2.04853189\",\"28\":\"1.13941056\",\"29\":\"0.47100793\",\"30\":\"0.149089027\",\"31\":\"-0.838928588\",\"32\":\"-0.171039461\",\"33\":\"-0.34876238\",\"34\":\"2.45849761\",\"35\":\"-1.087718719\",\"36\":\"-2.06816276\",\"37\":\"-0.92926824\",\"38\":\"-2.3500581\",\"39\":\"-1.33796385\",\"40\":\"-0.147637564\",\"41\":\"-0.39837915\",\"42\":\"1.59587775\",\"43\":\"-1.812610309\",\"44\":\"1.50245275\",\"45\":\"-0.65427333\",\"46\":\"-2.45720454\",\"47\":\"-1.33297203\",\"48\":\"-1.391155353\",\"49\":\"-1.74426585\",\"50\":\"-0.93957991\",\"51\":\"-0.474487431\"},{\"1\":\"-0.0214213251\",\"2\":\"-0.42734831\",\"3\":\"-0.05439998\",\"4\":\"-0.60958288\",\"5\":\"-3.8104274\",\"6\":\"-0.100565167\",\"7\":\"-0.09624151\",\"8\":\"0.75449586\",\"9\":\"-2.29411509\",\"10\":\"-2.67345194\",\"11\":\"-0.63998201\",\"12\":\"1.22653555\",\"13\":\"0.133982872\",\"14\":\"-0.85282212\",\"15\":\"-0.14585872\",\"16\":\"0.41966934\",\"17\":\"-1.443049379\",\"18\":\"-0.78113781\",\"19\":\"-1.66341159\",\"20\":\"1.16046526\",\"21\":\"1.9652363\",\"22\":\"2.15056787\",\"23\":\"0.30924491\",\"24\":\"0.58061617\",\"25\":\"-1.799287742\",\"26\":\"0.151940989\",\"27\":\"-3.22326596\",\"28\":\"0.48138983\",\"29\":\"0.22771696\",\"30\":\"1.435837638\",\"31\":\"-0.135918739\",\"32\":\"2.127370156\",\"33\":\"-0.08707822\",\"34\":\"0.30359938\",\"35\":\"-0.268148509\",\"36\":\"-3.73068742\",\"37\":\"-2.58264740\",\"38\":\"-1.9542801\",\"39\":\"-1.83342169\",\"40\":\"0.307762665\",\"41\":\"-0.02072918\",\"42\":\"1.51551534\",\"43\":\"-1.394756200\",\"44\":\"-1.04791397\",\"45\":\"-1.48705712\",\"46\":\"-1.50074186\",\"47\":\"-1.83996379\",\"48\":\"-1.641390357\",\"49\":\"-0.02426877\",\"50\":\"-0.10181975\",\"51\":\"0.334290660\"},{\"1\":\"-0.5444608209\",\"2\":\"-1.40952158\",\"3\":\"-0.33180584\",\"4\":\"0.62204155\",\"5\":\"-1.2243353\",\"6\":\"0.171936428\",\"7\":\"1.79117956\",\"8\":\"-1.37634291\",\"9\":\"-1.49026010\",\"10\":\"-0.06123175\",\"11\":\"-3.00331337\",\"12\":\"-1.59717154\",\"13\":\"-1.284258240\",\"14\":\"-0.96658430\",\"15\":\"0.76703734\",\"16\":\"-0.14892608\",\"17\":\"-0.054911664\",\"18\":\"-1.49762366\",\"19\":\"-2.40543161\",\"20\":\"0.23279201\",\"21\":\"4.5320788\",\"22\":\"-0.60000097\",\"23\":\"0.01305591\",\"24\":\"0.53865314\",\"25\":\"1.129642834\",\"26\":\"-0.751638579\",\"27\":\"-1.53991910\",\"28\":\"0.62993083\",\"29\":\"-0.11022622\",\"30\":\"0.108277714\",\"31\":\"-1.104245424\",\"32\":\"1.568909717\",\"33\":\"-1.34778925\",\"34\":\"-0.87542736\",\"35\":\"-0.974706685\",\"36\":\"-0.01033730\",\"37\":\"1.76615512\",\"38\":\"-1.2876355\",\"39\":\"-4.20541191\",\"40\":\"0.234761667\",\"41\":\"0.44070285\",\"42\":\"1.00446025\",\"43\":\"0.806026103\",\"44\":\"-0.84874530\",\"45\":\"-2.94196898\",\"46\":\"0.54532316\",\"47\":\"-3.67271734\",\"48\":\"0.025692002\",\"49\":\"-1.40153945\",\"50\":\"-0.67556466\",\"51\":\"-1.741137809\"},{\"1\":\"0.8930563627\",\"2\":\"-1.14937309\",\"3\":\"1.10557457\",\"4\":\"2.10969238\",\"5\":\"-4.4366311\",\"6\":\"1.180080189\",\"7\":\"1.84207274\",\"8\":\"0.09257456\",\"9\":\"-0.36915057\",\"10\":\"-0.56160413\",\"11\":\"-0.01725244\",\"12\":\"-1.46907740\",\"13\":\"-1.683658501\",\"14\":\"1.10580065\",\"15\":\"-0.28166840\",\"16\":\"2.09607938\",\"17\":\"-0.608238912\",\"18\":\"-1.07871691\",\"19\":\"-1.37146683\",\"20\":\"0.58884432\",\"21\":\"2.8471541\",\"22\":\"-1.09653419\",\"23\":\"-0.37094708\",\"24\":\"-0.93515882\",\"25\":\"0.004511478\",\"26\":\"-0.836687624\",\"27\":\"-1.68083064\",\"28\":\"0.53610239\",\"29\":\"-0.77595655\",\"30\":\"0.333663144\",\"31\":\"-1.650417160\",\"32\":\"1.336215864\",\"33\":\"-0.68268007\",\"34\":\"-0.70702357\",\"35\":\"0.081852920\",\"36\":\"-0.54476498\",\"37\":\"-0.23259350\",\"38\":\"-2.3276527\",\"39\":\"-1.75220593\",\"40\":\"1.151401982\",\"41\":\"-0.13848697\",\"42\":\"-0.89261612\",\"43\":\"-2.826641869\",\"44\":\"-0.90991066\",\"45\":\"-0.30571750\",\"46\":\"-0.82154646\",\"47\":\"-0.47426448\",\"48\":\"-1.711387115\",\"49\":\"0.29799750\",\"50\":\"-1.12997923\",\"51\":\"-0.327823544\"},{\"1\":\"0.9769032117\",\"2\":\"-1.99151968\",\"3\":\"-0.58710207\",\"4\":\"1.20787212\",\"5\":\"-1.7508843\",\"6\":\"-1.206772229\",\"7\":\"-0.05033341\",\"8\":\"0.01694883\",\"9\":\"-1.67956050\",\"10\":\"-0.29566770\",\"11\":\"-1.73287982\",\"12\":\"-1.59516654\",\"13\":\"0.068668873\",\"14\":\"2.23211587\",\"15\":\"-0.47204781\",\"16\":\"-0.07504967\",\"17\":\"0.348833840\",\"18\":\"-0.62036512\",\"19\":\"-0.75315537\",\"20\":\"-0.03806416\",\"21\":\"1.6926408\",\"22\":\"0.25242052\",\"23\":\"-0.74795215\",\"24\":\"0.63092297\",\"25\":\"1.991021542\",\"26\":\"-1.095438762\",\"27\":\"-1.96131418\",\"28\":\"1.88376546\",\"29\":\"-0.86298693\",\"30\":\"-0.258139842\",\"31\":\"-1.162554258\",\"32\":\"1.366739445\",\"33\":\"-2.53400577\",\"34\":\"-1.42674202\",\"35\":\"-0.081228613\",\"36\":\"-2.26989438\",\"37\":\"0.06626526\",\"38\":\"-0.6428573\",\"39\":\"-1.22278465\",\"40\":\"0.303015429\",\"41\":\"0.52666409\",\"42\":\"1.17111390\",\"43\":\"-1.417503634\",\"44\":\"-1.42357151\",\"45\":\"-0.31499626\",\"46\":\"-1.83016400\",\"47\":\"-0.54117399\",\"48\":\"-0.549806597\",\"49\":\"-1.81359842\",\"50\":\"-0.82854919\",\"51\":\"0.176316350\"},{\"1\":\"-0.1925884304\",\"2\":\"-3.51184430\",\"3\":\"-0.06487149\",\"4\":\"1.84125731\",\"5\":\"-3.5682263\",\"6\":\"-1.102529750\",\"7\":\"-0.21059528\",\"8\":\"-0.45115298\",\"9\":\"-0.05126158\",\"10\":\"0.73445809\",\"11\":\"-0.07217775\",\"12\":\"-1.07666290\",\"13\":\"-0.954078589\",\"14\":\"-0.15910904\",\"15\":\"0.91266662\",\"16\":\"2.13006049\",\"17\":\"0.575185822\",\"18\":\"-0.43970945\",\"19\":\"-1.31993065\",\"20\":\"-0.93939626\",\"21\":\"2.0729328\",\"22\":\"0.60610307\",\"23\":\"-1.82696596\",\"24\":\"-1.64552257\",\"25\":\"-0.397890935\",\"26\":\"-0.547879807\",\"27\":\"-1.26261632\",\"28\":\"1.81808214\",\"29\":\"-1.13725256\",\"30\":\"0.087477435\",\"31\":\"0.672592326\",\"32\":\"1.534717468\",\"33\":\"-1.21471640\",\"34\":\"-0.42810201\",\"35\":\"0.177602848\",\"36\":\"-1.88191330\",\"37\":\"-3.05900398\",\"38\":\"-1.7274203\",\"39\":\"-1.41215396\",\"40\":\"0.962023063\",\"41\":\"0.59950303\",\"42\":\"0.26769263\",\"43\":\"-0.962053495\",\"44\":\"-1.78234058\",\"45\":\"1.36173604\",\"46\":\"-1.65026878\",\"47\":\"0.34067654\",\"48\":\"-0.964688899\",\"49\":\"-1.89910314\",\"50\":\"0.10570798\",\"51\":\"-0.523126334\"},{\"1\":\"0.3322137356\",\"2\":\"-0.50122056\",\"3\":\"-0.84995118\",\"4\":\"0.09711768\",\"5\":\"-2.4135746\",\"6\":\"2.263681031\",\"7\":\"-0.25296579\",\"8\":\"-1.03697752\",\"9\":\"-0.22903285\",\"10\":\"0.12638704\",\"11\":\"-0.39634673\",\"12\":\"-1.12857715\",\"13\":\"-1.753480767\",\"14\":\"-1.90931439\",\"15\":\"-0.08365212\",\"16\":\"0.80421601\",\"17\":\"-1.288418113\",\"18\":\"-0.57777113\",\"19\":\"0.12301885\",\"20\":\"-1.40944902\",\"21\":\"3.9112240\",\"22\":\"1.39548300\",\"23\":\"-1.29085632\",\"24\":\"0.58124940\",\"25\":\"1.143741416\",\"26\":\"0.132198304\",\"27\":\"-2.87982802\",\"28\":\"0.71050174\",\"29\":\"-1.78423744\",\"30\":\"0.701083652\",\"31\":\"0.624088930\",\"32\":\"2.075519700\",\"33\":\"-0.78221520\",\"34\":\"-0.70215814\",\"35\":\"0.981202965\",\"36\":\"-1.76392274\",\"37\":\"-1.39027056\",\"38\":\"-3.7757339\",\"39\":\"-1.94969062\",\"40\":\"0.803148184\",\"41\":\"-3.39637960\",\"42\":\"1.48262154\",\"43\":\"-1.606301505\",\"44\":\"-1.99109982\",\"45\":\"-2.27608515\",\"46\":\"0.06322601\",\"47\":\"0.49820832\",\"48\":\"-2.344178407\",\"49\":\"-1.10885373\",\"50\":\"0.37134386\",\"51\":\"-0.688242126\"},{\"1\":\"-0.2220993809\",\"2\":\"-0.92179546\",\"3\":\"1.00309280\",\"4\":\"1.22451211\",\"5\":\"-2.4291504\",\"6\":\"-0.098399913\",\"7\":\"2.07456679\",\"8\":\"-1.26366549\",\"9\":\"0.41930984\",\"10\":\"0.02082860\",\"11\":\"-0.47443112\",\"12\":\"-1.15180219\",\"13\":\"-1.452303482\",\"14\":\"-1.19434324\",\"15\":\"-0.66331382\",\"16\":\"1.90854204\",\"17\":\"-1.669272741\",\"18\":\"0.07342730\",\"19\":\"-0.50122944\",\"20\":\"-1.68294538\",\"21\":\"1.4064599\",\"22\":\"0.63905811\",\"23\":\"-1.66418928\",\"24\":\"0.98067638\",\"25\":\"1.022408801\",\"26\":\"0.245117461\",\"27\":\"-3.34684970\",\"28\":\"0.41590198\",\"29\":\"-0.81550853\",\"30\":\"0.474758791\",\"31\":\"1.009956161\",\"32\":\"0.573103488\",\"33\":\"0.82782455\",\"34\":\"-2.43914026\",\"35\":\"-1.926542098\",\"36\":\"0.16626252\",\"37\":\"-0.39949173\",\"38\":\"-2.3672049\",\"39\":\"-1.01934790\",\"40\":\"-0.882754272\",\"41\":\"-0.82867128\",\"42\":\"0.61177925\",\"43\":\"-1.479911856\",\"44\":\"0.05859771\",\"45\":\"-0.94279376\",\"46\":\"-0.64825659\",\"47\":\"-1.11157038\",\"48\":\"-0.733174220\",\"49\":\"-1.22779724\",\"50\":\"0.13638451\",\"51\":\"-1.278756604\"},{\"1\":\"-0.2190141767\",\"2\":\"-1.39228492\",\"3\":\"-1.22699891\",\"4\":\"-0.45304577\",\"5\":\"-4.1202475\",\"6\":\"0.205884459\",\"7\":\"1.04151946\",\"8\":\"-0.62826123\",\"9\":\"-1.79121317\",\"10\":\"-0.52249850\",\"11\":\"-0.23803529\",\"12\":\"-1.45261306\",\"13\":\"-3.108906206\",\"14\":\"-0.78962817\",\"15\":\"-0.26243049\",\"16\":\"1.69011964\",\"17\":\"1.160404174\",\"18\":\"-2.82624082\",\"19\":\"-1.53137319\",\"20\":\"-0.43731373\",\"21\":\"1.2123603\",\"22\":\"-0.64233950\",\"23\":\"-0.65917785\",\"24\":\"-0.05518283\",\"25\":\"0.412705149\",\"26\":\"-0.458199302\",\"27\":\"-0.87696768\",\"28\":\"1.16413545\",\"29\":\"-0.27230528\",\"30\":\"-1.657794884\",\"31\":\"0.564891412\",\"32\":\"1.148066031\",\"33\":\"-1.53425293\",\"34\":\"-2.55291365\",\"35\":\"0.468716920\",\"36\":\"-1.59069675\",\"37\":\"-0.77966560\",\"38\":\"-1.6124052\",\"39\":\"-2.25148272\",\"40\":\"0.457007423\",\"41\":\"0.10403500\",\"42\":\"1.33188519\",\"43\":\"-0.686294386\",\"44\":\"-1.84142747\",\"45\":\"0.59941499\",\"46\":\"-1.89152662\",\"47\":\"0.32999941\",\"48\":\"-1.213404316\",\"49\":\"-1.75643741\",\"50\":\"1.74965540\",\"51\":\"1.561312030\"},{\"1\":\"1.6249448779\",\"2\":\"-2.73992252\",\"3\":\"-0.94997582\",\"4\":\"1.11021301\",\"5\":\"-2.9968491\",\"6\":\"1.735485538\",\"7\":\"0.71546809\",\"8\":\"-1.14744646\",\"9\":\"0.61909987\",\"10\":\"0.64043860\",\"11\":\"-0.10495004\",\"12\":\"0.96884477\",\"13\":\"-1.344116310\",\"14\":\"-0.46360275\",\"15\":\"-0.11850294\",\"16\":\"0.75887871\",\"17\":\"-1.305866165\",\"18\":\"1.61093066\",\"19\":\"0.53726206\",\"20\":\"-1.46947166\",\"21\":\"2.8114392\",\"22\":\"1.03484399\",\"23\":\"-0.48188896\",\"24\":\"-0.53315652\",\"25\":\"-0.686017801\",\"26\":\"-1.198082738\",\"27\":\"-2.42383096\",\"28\":\"-0.02136171\",\"29\":\"-2.33216277\",\"30\":\"1.201143097\",\"31\":\"-2.529145718\",\"32\":\"3.896988960\",\"33\":\"-0.17387289\",\"34\":\"-0.10823701\",\"35\":\"-0.766723828\",\"36\":\"-1.21609518\",\"37\":\"-0.55848623\",\"38\":\"-2.0173605\",\"39\":\"-0.64171214\",\"40\":\"0.159220482\",\"41\":\"-1.58553301\",\"42\":\"0.70797369\",\"43\":\"-0.846128635\",\"44\":\"-0.18787922\",\"45\":\"0.06176442\",\"46\":\"-0.98807487\",\"47\":\"-0.96720077\",\"48\":\"-0.941256206\",\"49\":\"-2.83338270\",\"50\":\"0.64966945\",\"51\":\"0.253651496\"},{\"1\":\"0.9797066675\",\"2\":\"-1.17406247\",\"3\":\"-1.25732418\",\"4\":\"0.06141071\",\"5\":\"-3.6236599\",\"6\":\"1.202031822\",\"7\":\"1.49852913\",\"8\":\"-0.36098362\",\"9\":\"-0.99117230\",\"10\":\"-0.10810884\",\"11\":\"-0.52912901\",\"12\":\"0.47849490\",\"13\":\"1.260477777\",\"14\":\"-1.71064021\",\"15\":\"0.54776569\",\"16\":\"2.96089516\",\"17\":\"-1.265724610\",\"18\":\"1.31656624\",\"19\":\"-1.58427383\",\"20\":\"-0.63435688\",\"21\":\"3.4749265\",\"22\":\"-0.75202898\",\"23\":\"0.15455437\",\"24\":\"-0.97746411\",\"25\":\"0.647459849\",\"26\":\"1.036937392\",\"27\":\"-2.32468111\",\"28\":\"0.63140639\",\"29\":\"-1.27381692\",\"30\":\"-0.758790740\",\"31\":\"-2.791470491\",\"32\":\"0.014297344\",\"33\":\"-0.38561989\",\"34\":\"-3.02737761\",\"35\":\"-1.304363611\",\"36\":\"-0.92952135\",\"37\":\"-0.57710065\",\"38\":\"-3.5520227\",\"39\":\"-0.51526082\",\"40\":\"-0.175115625\",\"41\":\"-1.42654790\",\"42\":\"1.04114930\",\"43\":\"-1.742397232\",\"44\":\"0.55123086\",\"45\":\"-0.15886915\",\"46\":\"-0.39766957\",\"47\":\"-1.64492439\",\"48\":\"-0.449283344\",\"49\":\"-1.22191946\",\"50\":\"-0.23611839\",\"51\":\"1.327358345\"},{\"1\":\"-1.4509573655\",\"2\":\"-1.89693123\",\"3\":\"-0.35431492\",\"4\":\"-0.67461682\",\"5\":\"-3.4187466\",\"6\":\"-1.422449226\",\"7\":\"-0.03119423\",\"8\":\"-0.21493677\",\"9\":\"-2.44703846\",\"10\":\"-0.58281758\",\"11\":\"-1.76374057\",\"12\":\"0.18522849\",\"13\":\"-1.318746136\",\"14\":\"-0.31510448\",\"15\":\"0.07859098\",\"16\":\"1.53391699\",\"17\":\"-0.108618210\",\"18\":\"-0.07258730\",\"19\":\"-2.13037166\",\"20\":\"-0.70578552\",\"21\":\"0.4369810\",\"22\":\"1.28767890\",\"23\":\"-1.07394316\",\"24\":\"-1.75971622\",\"25\":\"-0.871407869\",\"26\":\"0.288444463\",\"27\":\"-1.89345109\",\"28\":\"0.38855880\",\"29\":\"-1.36261748\",\"30\":\"0.927944115\",\"31\":\"-0.870740520\",\"32\":\"1.397727117\",\"33\":\"-1.83898533\",\"34\":\"-1.08975211\",\"35\":\"-2.278292163\",\"36\":\"-0.93930252\",\"37\":\"-1.60276002\",\"38\":\"-4.0639922\",\"39\":\"-0.38344978\",\"40\":\"-1.197681567\",\"41\":\"-0.19216107\",\"42\":\"1.07172550\",\"43\":\"-0.501209810\",\"44\":\"0.30241433\",\"45\":\"-0.90138404\",\"46\":\"0.72821173\",\"47\":\"-1.81671091\",\"48\":\"-0.993355273\",\"49\":\"-1.96856258\",\"50\":\"-1.18359821\",\"51\":\"-0.416790316\"},{\"1\":\"1.2695129747\",\"2\":\"-1.86743676\",\"3\":\"0.56498984\",\"4\":\"0.19598239\",\"5\":\"-2.5516852\",\"6\":\"1.597847951\",\"7\":\"0.23788307\",\"8\":\"1.70221736\",\"9\":\"-0.53857160\",\"10\":\"0.09488331\",\"11\":\"-1.76038231\",\"12\":\"-1.04585422\",\"13\":\"-1.854913768\",\"14\":\"-0.21276266\",\"15\":\"0.18796530\",\"16\":\"0.29456856\",\"17\":\"-1.475387955\",\"18\":\"-1.91843575\",\"19\":\"-0.67475893\",\"20\":\"-0.38889633\",\"21\":\"2.6068084\",\"22\":\"0.51650054\",\"23\":\"-1.34513149\",\"24\":\"-0.66496714\",\"25\":\"-0.303654337\",\"26\":\"-1.618518357\",\"27\":\"-2.22253471\",\"28\":\"-0.84198860\",\"29\":\"-0.72025822\",\"30\":\"-0.138640376\",\"31\":\"-1.113669489\",\"32\":\"-0.335667019\",\"33\":\"-0.19306921\",\"34\":\"0.94572486\",\"35\":\"-1.350294952\",\"36\":\"-3.30015293\",\"37\":\"-1.41838916\",\"38\":\"-2.2480867\",\"39\":\"-0.54214692\",\"40\":\"0.293688598\",\"41\":\"-0.90732083\",\"42\":\"2.77786298\",\"43\":\"-0.889159069\",\"44\":\"-0.99411783\",\"45\":\"-0.07967773\",\"46\":\"-1.87608956\",\"47\":\"-1.31545542\",\"48\":\"0.477840971\",\"49\":\"-0.16937493\",\"50\":\"2.39531201\",\"51\":\"-1.128259256\"},{\"1\":\"0.0144707323\",\"2\":\"-0.31820511\",\"3\":\"-1.08503863\",\"4\":\"3.04724527\",\"5\":\"-2.8201518\",\"6\":\"-0.042598410\",\"7\":\"1.43506345\",\"8\":\"-1.01503137\",\"9\":\"0.02603790\",\"10\":\"-1.56470363\",\"11\":\"-1.76536687\",\"12\":\"-0.95169842\",\"13\":\"-0.136714924\",\"14\":\"-1.09521458\",\"15\":\"1.90191016\",\"16\":\"0.74700137\",\"17\":\"0.261867532\",\"18\":\"0.27170966\",\"19\":\"-0.47129790\",\"20\":\"-1.07749918\",\"21\":\"4.6322800\",\"22\":\"0.43685948\",\"23\":\"-0.46107393\",\"24\":\"-0.60033571\",\"25\":\"-0.266055917\",\"26\":\"-0.488169431\",\"27\":\"-0.21689541\",\"28\":\"0.01144437\",\"29\":\"-1.88611686\",\"30\":\"0.055412468\",\"31\":\"-2.413692688\",\"32\":\"1.315379027\",\"33\":\"1.10510637\",\"34\":\"-2.37229509\",\"35\":\"-0.800736280\",\"36\":\"-0.88904516\",\"37\":\"-2.09388865\",\"38\":\"-1.4927327\",\"39\":\"-1.69312040\",\"40\":\"-0.230565111\",\"41\":\"-2.19738536\",\"42\":\"2.16593257\",\"43\":\"-0.382300974\",\"44\":\"-1.39468648\",\"45\":\"-0.51652835\",\"46\":\"-1.37428603\",\"47\":\"-0.74103487\",\"48\":\"-0.991764752\",\"49\":\"-2.20467134\",\"50\":\"0.15358738\",\"51\":\"-2.010138077\"},{\"1\":\"0.8245945961\",\"2\":\"-0.32845680\",\"3\":\"1.75926148\",\"4\":\"0.59038311\",\"5\":\"-1.6096320\",\"6\":\"-0.358886713\",\"7\":\"-1.05221101\",\"8\":\"-0.89371131\",\"9\":\"0.76785794\",\"10\":\"0.29274853\",\"11\":\"-1.15668065\",\"12\":\"-0.94256765\",\"13\":\"-0.615720794\",\"14\":\"-0.36114065\",\"15\":\"-1.69959994\",\"16\":\"0.76960523\",\"17\":\"-0.866056347\",\"18\":\"-2.87637430\",\"19\":\"-2.60313998\",\"20\":\"-0.63684132\",\"21\":\"2.7640960\",\"22\":\"-0.73233247\",\"23\":\"-0.77557237\",\"24\":\"0.75279695\",\"25\":\"1.708709219\",\"26\":\"-2.333369896\",\"27\":\"-0.42012601\",\"28\":\"-0.53405497\",\"29\":\"-0.06353534\",\"30\":\"0.505334910\",\"31\":\"-2.930241036\",\"32\":\"2.077258180\",\"33\":\"0.46444717\",\"34\":\"-0.41471037\",\"35\":\"-2.441502540\",\"36\":\"-2.55321837\",\"37\":\"-0.08018346\",\"38\":\"-2.8880404\",\"39\":\"-1.36594002\",\"40\":\"-0.649129714\",\"41\":\"0.43995730\",\"42\":\"1.21720708\",\"43\":\"-2.395906385\",\"44\":\"-1.93425813\",\"45\":\"-0.16696189\",\"46\":\"0.00176994\",\"47\":\"-0.99591572\",\"48\":\"-2.361317232\",\"49\":\"-0.12550316\",\"50\":\"-1.20814846\",\"51\":\"-1.132949788\"},{\"1\":\"-0.7369444080\",\"2\":\"-0.84008098\",\"3\":\"0.48405041\",\"4\":\"0.59538846\",\"5\":\"-3.3638900\",\"6\":\"-1.245666069\",\"7\":\"1.15597416\",\"8\":\"-0.72735214\",\"9\":\"-0.91467174\",\"10\":\"-1.14582791\",\"11\":\"-0.68873185\",\"12\":\"-0.51254210\",\"13\":\"-0.572487385\",\"14\":\"-2.62743072\",\"15\":\"-0.29658563\",\"16\":\"2.29167671\",\"17\":\"1.218117716\",\"18\":\"0.91476395\",\"19\":\"-0.97797428\",\"20\":\"-1.65639590\",\"21\":\"3.2972246\",\"22\":\"-0.51473045\",\"23\":\"-0.54219387\",\"24\":\"-1.52663261\",\"25\":\"-1.151375566\",\"26\":\"-2.319972588\",\"27\":\"-1.39810151\",\"28\":\"1.51512314\",\"29\":\"-1.52531613\",\"30\":\"-0.914977390\",\"31\":\"0.311571572\",\"32\":\"-1.251164609\",\"33\":\"0.65583715\",\"34\":\"0.86046140\",\"35\":\"-0.861290848\",\"36\":\"-1.66078204\",\"37\":\"-3.11157848\",\"38\":\"-1.8023624\",\"39\":\"-0.09591982\",\"40\":\"0.628201886\",\"41\":\"-1.30673718\",\"42\":\"0.22326937\",\"43\":\"-1.836559162\",\"44\":\"-0.87392677\",\"45\":\"-0.85855220\",\"46\":\"-1.45346097\",\"47\":\"-0.76763653\",\"48\":\"-0.365453413\",\"49\":\"-1.90102890\",\"50\":\"-0.33733604\",\"51\":\"-0.270548425\"},{\"1\":\"0.0744183459\",\"2\":\"-1.51208250\",\"3\":\"-0.17087341\",\"4\":\"0.55276897\",\"5\":\"-3.1323267\",\"6\":\"-1.540632427\",\"7\":\"-1.00547026\",\"8\":\"-0.70662926\",\"9\":\"0.07606387\",\"10\":\"-0.75884661\",\"11\":\"-1.42674470\",\"12\":\"-0.97025980\",\"13\":\"-1.574073588\",\"14\":\"-0.69186532\",\"15\":\"-0.03990411\",\"16\":\"2.25444954\",\"17\":\"-1.666645690\",\"18\":\"0.42868469\",\"19\":\"-2.69423807\",\"20\":\"-1.76166357\",\"21\":\"2.4538910\",\"22\":\"1.21953472\",\"23\":\"2.04568884\",\"24\":\"-0.55262789\",\"25\":\"-0.398814736\",\"26\":\"-1.512378199\",\"27\":\"-1.65858705\",\"28\":\"-0.59775635\",\"29\":\"0.24649197\",\"30\":\"-0.082784722\",\"31\":\"0.734427174\",\"32\":\"0.517779734\",\"33\":\"-0.68928898\",\"34\":\"-0.19749314\",\"35\":\"0.008848127\",\"36\":\"-3.55688645\",\"37\":\"-1.44823970\",\"38\":\"-1.5992819\",\"39\":\"-0.73005123\",\"40\":\"0.698031510\",\"41\":\"-0.07954969\",\"42\":\"2.49703436\",\"43\":\"-1.261345232\",\"44\":\"-1.08798032\",\"45\":\"0.90794188\",\"46\":\"0.46592567\",\"47\":\"-0.76957165\",\"48\":\"-2.330219808\",\"49\":\"-0.95951581\",\"50\":\"-0.84822142\",\"51\":\"0.516840390\"},{\"1\":\"-0.8128077374\",\"2\":\"-1.12267876\",\"3\":\"0.33632440\",\"4\":\"0.37865738\",\"5\":\"-2.3080815\",\"6\":\"0.516490616\",\"7\":\"-0.35926397\",\"8\":\"-0.12854274\",\"9\":\"-0.01712969\",\"10\":\"-0.72227250\",\"11\":\"-0.04247682\",\"12\":\"0.91949846\",\"13\":\"-1.322189889\",\"14\":\"-0.07464587\",\"15\":\"-1.31089663\",\"16\":\"2.48839258\",\"17\":\"0.617181032\",\"18\":\"-1.84583800\",\"19\":\"-0.75559458\",\"20\":\"-1.15778783\",\"21\":\"1.7655752\",\"22\":\"0.56001645\",\"23\":\"0.57704762\",\"24\":\"-0.86383402\",\"25\":\"-0.899695703\",\"26\":\"-0.660596019\",\"27\":\"-2.06127375\",\"28\":\"0.45466747\",\"29\":\"-1.53518692\",\"30\":\"-0.712161848\",\"31\":\"-0.672025414\",\"32\":\"3.356171696\",\"33\":\"0.48224583\",\"34\":\"0.57646236\",\"35\":\"-1.799228479\",\"36\":\"-1.41479044\",\"37\":\"-0.35554171\",\"38\":\"-1.2054136\",\"39\":\"-0.99411016\",\"40\":\"0.579270043\",\"41\":\"-0.05346743\",\"42\":\"0.01308908\",\"43\":\"-0.109591526\",\"44\":\"-0.69907109\",\"45\":\"0.77931328\",\"46\":\"0.04890610\",\"47\":\"-0.25391496\",\"48\":\"-3.026212324\",\"49\":\"-0.35328316\",\"50\":\"-0.79853234\",\"51\":\"-0.244099822\"},{\"1\":\"2.3397161766\",\"2\":\"-1.52485276\",\"3\":\"0.68963405\",\"4\":\"0.29719558\",\"5\":\"-4.2028391\",\"6\":\"1.274031872\",\"7\":\"0.85374053\",\"8\":\"1.67502924\",\"9\":\"-0.55894060\",\"10\":\"-0.79397368\",\"11\":\"-1.06150126\",\"12\":\"-1.50263825\",\"13\":\"-0.492191591\",\"14\":\"-1.25467676\",\"15\":\"2.66142188\",\"16\":\"2.89090116\",\"17\":\"-0.514739529\",\"18\":\"0.20686057\",\"19\":\"-1.11599049\",\"20\":\"-1.82157102\",\"21\":\"1.3150847\",\"22\":\"-0.36813579\",\"23\":\"-1.17576261\",\"24\":\"-0.77872124\",\"25\":\"0.857007060\",\"26\":\"-1.258267942\",\"27\":\"-0.45275566\",\"28\":\"-0.39648128\",\"29\":\"0.18547820\",\"30\":\"0.666070991\",\"31\":\"-0.765201650\",\"32\":\"0.328276491\",\"33\":\"-2.84640271\",\"34\":\"-1.67695479\",\"35\":\"-0.506105463\",\"36\":\"-2.63413233\",\"37\":\"-1.37532295\",\"38\":\"-1.5925871\",\"39\":\"-0.06181348\",\"40\":\"-2.905337320\",\"41\":\"1.05537110\",\"42\":\"0.26702734\",\"43\":\"-1.597674086\",\"44\":\"-1.45937439\",\"45\":\"1.05613521\",\"46\":\"-2.65338105\",\"47\":\"-1.24169609\",\"48\":\"-1.917254583\",\"49\":\"-1.77072824\",\"50\":\"-1.45733146\",\"51\":\"-1.668798270\"},{\"1\":\"-0.8907041289\",\"2\":\"-2.08981418\",\"3\":\"0.45011095\",\"4\":\"1.12514746\",\"5\":\"-2.5145743\",\"6\":\"-1.283728736\",\"7\":\"0.31996086\",\"8\":\"-0.39292144\",\"9\":\"1.66763575\",\"10\":\"-3.00436711\",\"11\":\"-2.74569179\",\"12\":\"-0.28812000\",\"13\":\"-2.075900990\",\"14\":\"-1.42337296\",\"15\":\"-0.46110725\",\"16\":\"1.27530181\",\"17\":\"1.981365746\",\"18\":\"-0.60033300\",\"19\":\"-1.47071620\",\"20\":\"-0.61969345\",\"21\":\"1.7510793\",\"22\":\"0.37431335\",\"23\":\"0.36650480\",\"24\":\"0.21972228\",\"25\":\"0.963209363\",\"26\":\"0.534294458\",\"27\":\"-1.20893075\",\"28\":\"0.66955672\",\"29\":\"-1.35990623\",\"30\":\"0.319077885\",\"31\":\"-1.058053989\",\"32\":\"-0.321370434\",\"33\":\"-1.72885169\",\"34\":\"-0.07705068\",\"35\":\"-1.846110295\",\"36\":\"-3.80804696\",\"37\":\"0.28313806\",\"38\":\"-1.9347609\",\"39\":\"-1.96783903\",\"40\":\"-1.191610691\",\"41\":\"-0.26933330\",\"42\":\"0.67329143\",\"43\":\"-2.101529715\",\"44\":\"-0.22632951\",\"45\":\"-0.64779217\",\"46\":\"-0.57038230\",\"47\":\"0.66683314\",\"48\":\"-1.851995421\",\"49\":\"-0.69754733\",\"50\":\"-0.40698277\",\"51\":\"0.171864371\"},{\"1\":\"-0.1781165576\",\"2\":\"-1.62719760\",\"3\":\"0.53169556\",\"4\":\"0.92418375\",\"5\":\"-2.5928225\",\"6\":\"-1.146543855\",\"7\":\"1.10140219\",\"8\":\"-0.84560338\",\"9\":\"-0.62969492\",\"10\":\"-0.88959552\",\"11\":\"1.00200743\",\"12\":\"0.24148306\",\"13\":\"-0.325588109\",\"14\":\"-1.02556229\",\"15\":\"1.09321527\",\"16\":\"1.04612361\",\"17\":\"-0.553637577\",\"18\":\"-0.33729517\",\"19\":\"-1.97712615\",\"20\":\"0.69530897\",\"21\":\"1.0511125\",\"22\":\"1.61880795\",\"23\":\"-1.20912692\",\"24\":\"-0.40233378\",\"25\":\"2.210011841\",\"26\":\"1.390735382\",\"27\":\"-1.23538372\",\"28\":\"0.10144794\",\"29\":\"-0.37654330\",\"30\":\"-1.437867737\",\"31\":\"-1.430376008\",\"32\":\"1.559966928\",\"33\":\"-0.65044103\",\"34\":\"-0.52636137\",\"35\":\"-0.552942246\",\"36\":\"-3.30164260\",\"37\":\"-0.32612608\",\"38\":\"-3.7460434\",\"39\":\"-1.31572992\",\"40\":\"0.642941460\",\"41\":\"0.19971281\",\"42\":\"0.47718276\",\"43\":\"-0.296897233\",\"44\":\"-0.14119506\",\"45\":\"-0.58495971\",\"46\":\"-2.41350300\",\"47\":\"-0.53082043\",\"48\":\"-1.714824115\",\"49\":\"-1.33995956\",\"50\":\"-0.20466788\",\"51\":\"-2.146950892\"},{\"1\":\"0.9517157053\",\"2\":\"-0.99529343\",\"3\":\"0.28210159\",\"4\":\"1.79187725\",\"5\":\"-3.3001319\",\"6\":\"1.287839819\",\"7\":\"-0.58221330\",\"8\":\"-0.61181318\",\"9\":\"-0.93009145\",\"10\":\"-1.01339908\",\"11\":\"0.45343821\",\"12\":\"-0.46942657\",\"13\":\"-0.534652449\",\"14\":\"1.01420106\",\"15\":\"-0.47052700\",\"16\":\"2.00972773\",\"17\":\"-1.157149204\",\"18\":\"-0.72965990\",\"19\":\"-1.07002781\",\"20\":\"-0.99646543\",\"21\":\"2.3965225\",\"22\":\"-0.27417003\",\"23\":\"-2.20057470\",\"24\":\"-0.34075325\",\"25\":\"-0.281768716\",\"26\":\"0.215484454\",\"27\":\"-2.94450807\",\"28\":\"2.92664716\",\"29\":\"-0.74632444\",\"30\":\"-0.327640497\",\"31\":\"-2.326483565\",\"32\":\"0.379296655\",\"33\":\"-0.36708149\",\"34\":\"0.64067608\",\"35\":\"0.393591733\",\"36\":\"-3.04981560\",\"37\":\"-2.03335708\",\"38\":\"-2.6881678\",\"39\":\"-0.03948419\",\"40\":\"-1.039630194\",\"41\":\"0.67469355\",\"42\":\"0.54583870\",\"43\":\"-0.603286059\",\"44\":\"0.22052147\",\"45\":\"-0.63090263\",\"46\":\"-2.45903253\",\"47\":\"-2.16205017\",\"48\":\"0.499441373\",\"49\":\"-2.38719882\",\"50\":\"-1.60137024\",\"51\":\"-0.862702205\"},{\"1\":\"-1.3332215356\",\"2\":\"-1.02832318\",\"3\":\"0.65721131\",\"4\":\"1.75703765\",\"5\":\"-2.8963083\",\"6\":\"0.756624191\",\"7\":\"0.12669512\",\"8\":\"0.83163567\",\"9\":\"-1.26787178\",\"10\":\"-0.69469177\",\"11\":\"0.92598661\",\"12\":\"2.01425990\",\"13\":\"-1.951922301\",\"14\":\"-1.13549753\",\"15\":\"-0.70510378\",\"16\":\"1.59871224\",\"17\":\"-0.687232810\",\"18\":\"-0.23776444\",\"19\":\"-1.95288037\",\"20\":\"-0.41133136\",\"21\":\"1.5049128\",\"22\":\"-1.56649191\",\"23\":\"0.79229233\",\"24\":\"0.01945115\",\"25\":\"2.118907926\",\"26\":\"0.566667334\",\"27\":\"-0.57051156\",\"28\":\"0.24272429\",\"29\":\"-1.11490738\",\"30\":\"-0.613452712\",\"31\":\"-1.140848894\",\"32\":\"2.586042175\",\"33\":\"0.04132738\",\"34\":\"1.77788763\",\"35\":\"-2.681140333\",\"36\":\"-1.07856183\",\"37\":\"-1.22749707\",\"38\":\"-1.3217608\",\"39\":\"-1.59078289\",\"40\":\"0.114245771\",\"41\":\"-0.87227867\",\"42\":\"2.73670021\",\"43\":\"-2.294313791\",\"44\":\"1.39439088\",\"45\":\"1.09352176\",\"46\":\"-0.92391910\",\"47\":\"-1.24516412\",\"48\":\"0.528281254\",\"49\":\"-1.52206550\",\"50\":\"-3.75698025\",\"51\":\"-0.812968286\"},{\"1\":\"0.4347734538\",\"2\":\"-1.04715469\",\"3\":\"0.16046297\",\"4\":\"1.52931067\",\"5\":\"-3.9870951\",\"6\":\"0.911723965\",\"7\":\"0.37225074\",\"8\":\"-0.84143017\",\"9\":\"-0.52888861\",\"10\":\"0.06973999\",\"11\":\"0.08872108\",\"12\":\"-0.64747374\",\"13\":\"-0.723688371\",\"14\":\"-0.89088953\",\"15\":\"-0.93711627\",\"16\":\"1.62251091\",\"17\":\"-0.060366229\",\"18\":\"0.54899722\",\"19\":\"0.62073298\",\"20\":\"-1.66295097\",\"21\":\"2.7458174\",\"22\":\"0.75357698\",\"23\":\"-0.34619587\",\"24\":\"-2.00878962\",\"25\":\"0.964356128\",\"26\":\"0.167305923\",\"27\":\"-2.05164341\",\"28\":\"1.32495705\",\"29\":\"0.47118016\",\"30\":\"-0.678519057\",\"31\":\"-1.984822143\",\"32\":\"2.184346409\",\"33\":\"0.24604131\",\"34\":\"-0.59477834\",\"35\":\"1.805158372\",\"36\":\"-1.31866029\",\"37\":\"-1.15608811\",\"38\":\"-1.7281729\",\"39\":\"-1.20599485\",\"40\":\"-0.111381186\",\"41\":\"-2.12145889\",\"42\":\"1.34330866\",\"43\":\"0.978034517\",\"44\":\"-0.65747403\",\"45\":\"-0.58034349\",\"46\":\"-0.93764185\",\"47\":\"-0.45263127\",\"48\":\"-0.381227096\",\"49\":\"0.36780399\",\"50\":\"-0.77870277\",\"51\":\"-2.445096005\"},{\"1\":\"-0.6522672869\",\"2\":\"1.13315703\",\"3\":\"0.04197656\",\"4\":\"0.95154508\",\"5\":\"-3.1272736\",\"6\":\"-0.432114818\",\"7\":\"0.79994964\",\"8\":\"-1.87093549\",\"9\":\"-0.70849604\",\"10\":\"-0.81193711\",\"11\":\"-2.66864754\",\"12\":\"-1.91379585\",\"13\":\"-1.848401897\",\"14\":\"-2.10317918\",\"15\":\"-0.99048481\",\"16\":\"0.81863365\",\"17\":\"-0.330873565\",\"18\":\"-1.29112499\",\"19\":\"-0.22223131\",\"20\":\"-0.04613070\",\"21\":\"1.7952331\",\"22\":\"0.18721457\",\"23\":\"-0.43419127\",\"24\":\"-0.54862057\",\"25\":\"0.678562806\",\"26\":\"0.399801781\",\"27\":\"-1.10671271\",\"28\":\"0.96012396\",\"29\":\"-0.83953385\",\"30\":\"-0.009430046\",\"31\":\"-0.745202112\",\"32\":\"1.902055990\",\"33\":\"-0.93553691\",\"34\":\"0.38630033\",\"35\":\"-1.669008416\",\"36\":\"-0.94401956\",\"37\":\"-0.89850781\",\"38\":\"-3.0779439\",\"39\":\"-1.48766642\",\"40\":\"0.813108432\",\"41\":\"-0.32296750\",\"42\":\"0.73362531\",\"43\":\"0.430031725\",\"44\":\"-1.43091095\",\"45\":\"-0.18298786\",\"46\":\"-1.02704825\",\"47\":\"-1.37956965\",\"48\":\"-2.381153118\",\"49\":\"-1.46611706\",\"50\":\"-0.49431029\",\"51\":\"0.423207565\"},{\"1\":\"-0.5569730776\",\"2\":\"-3.29070964\",\"3\":\"-1.22385017\",\"4\":\"1.32102363\",\"5\":\"-2.7402889\",\"6\":\"-0.036383038\",\"7\":\"-0.29515842\",\"8\":\"-0.82374542\",\"9\":\"-1.48183263\",\"10\":\"-2.37510015\",\"11\":\"-0.94453614\",\"12\":\"-1.28329865\",\"13\":\"-0.934609122\",\"14\":\"0.20839232\",\"15\":\"-2.60211172\",\"16\":\"2.27022243\",\"17\":\"-0.779184220\",\"18\":\"-3.55405160\",\"19\":\"0.87435278\",\"20\":\"-0.89694647\",\"21\":\"1.7966072\",\"22\":\"-0.58821038\",\"23\":\"-1.20030656\",\"24\":\"-0.32312537\",\"25\":\"1.249195152\",\"26\":\"1.768050303\",\"27\":\"-1.39849554\",\"28\":\"1.25377595\",\"29\":\"-0.59810387\",\"30\":\"-1.832367375\",\"31\":\"-0.228290539\",\"32\":\"-0.322918255\",\"33\":\"-0.95720463\",\"34\":\"-1.11214991\",\"35\":\"0.439171658\",\"36\":\"-2.16100396\",\"37\":\"-1.69577977\",\"38\":\"-1.8610285\",\"39\":\"-0.10706260\",\"40\":\"-1.004665529\",\"41\":\"0.86001677\",\"42\":\"2.12121846\",\"43\":\"-2.457591808\",\"44\":\"-0.93268550\",\"45\":\"0.10056503\",\"46\":\"0.26994115\",\"47\":\"-0.62351927\",\"48\":\"-1.084171637\",\"49\":\"-2.06976835\",\"50\":\"0.07044566\",\"51\":\"-1.119721552\"},{\"1\":\"-0.8034386133\",\"2\":\"-2.86581238\",\"3\":\"1.50053513\",\"4\":\"2.19832174\",\"5\":\"-2.8150810\",\"6\":\"-0.959285014\",\"7\":\"2.81178955\",\"8\":\"-1.76348049\",\"9\":\"-1.35251267\",\"10\":\"-0.89429289\",\"11\":\"-0.33633836\",\"12\":\"0.51478104\",\"13\":\"-0.767115816\",\"14\":\"-1.25779831\",\"15\":\"0.85011314\",\"16\":\"1.55626893\",\"17\":\"-0.208305235\",\"18\":\"1.12914421\",\"19\":\"-0.49825952\",\"20\":\"-3.22393395\",\"21\":\"3.2267338\",\"22\":\"-0.55178670\",\"23\":\"0.75176760\",\"24\":\"-0.72776531\",\"25\":\"-0.524822961\",\"26\":\"-1.387750661\",\"27\":\"-0.13057776\",\"28\":\"1.59831989\",\"29\":\"-1.16587489\",\"30\":\"1.909780252\",\"31\":\"-1.226813283\",\"32\":\"1.461501379\",\"33\":\"-0.82486840\",\"34\":\"-1.06850975\",\"35\":\"1.577843535\",\"36\":\"-1.44730801\",\"37\":\"-1.78469310\",\"38\":\"-2.2740042\",\"39\":\"-1.20556721\",\"40\":\"-0.352096228\",\"41\":\"-1.87217520\",\"42\":\"1.64712989\",\"43\":\"1.084733740\",\"44\":\"-2.48328452\",\"45\":\"0.39758955\",\"46\":\"-0.69935219\",\"47\":\"-0.53411846\",\"48\":\"-0.620196959\",\"49\":\"-1.30600881\",\"50\":\"-0.46469295\",\"51\":\"-0.830886607\"},{\"1\":\"0.0195262057\",\"2\":\"-0.62055155\",\"3\":\"-0.31353372\",\"4\":\"0.97444378\",\"5\":\"-3.0816968\",\"6\":\"0.923435573\",\"7\":\"-0.50902616\",\"8\":\"-0.88400050\",\"9\":\"0.54812566\",\"10\":\"-2.71565047\",\"11\":\"-0.45463421\",\"12\":\"0.86616073\",\"13\":\"-1.624788866\",\"14\":\"0.76186996\",\"15\":\"-0.36301487\",\"16\":\"2.01279734\",\"17\":\"0.045561387\",\"18\":\"-2.53626466\",\"19\":\"-0.11583615\",\"20\":\"-0.38942740\",\"21\":\"3.1057956\",\"22\":\"0.23616616\",\"23\":\"-0.29812365\",\"24\":\"0.36457024\",\"25\":\"0.246347083\",\"26\":\"-1.891743389\",\"27\":\"-0.09874797\",\"28\":\"0.08904424\",\"29\":\"-1.42977976\",\"30\":\"0.460883868\",\"31\":\"0.548047986\",\"32\":\"1.483520097\",\"33\":\"-1.03735905\",\"34\":\"-1.26222827\",\"35\":\"-1.445082084\",\"36\":\"-1.21749729\",\"37\":\"-1.42999178\",\"38\":\"-0.9157313\",\"39\":\"-1.27375290\",\"40\":\"0.050629558\",\"41\":\"0.54623407\",\"42\":\"0.22939954\",\"43\":\"-2.797759464\",\"44\":\"-0.72544148\",\"45\":\"-0.54829627\",\"46\":\"-1.66742690\",\"47\":\"0.33496337\",\"48\":\"-1.244345696\",\"49\":\"-0.92184428\",\"50\":\"-0.11042922\",\"51\":\"0.898297935\"},{\"1\":\"-0.4501057197\",\"2\":\"-1.21544791\",\"3\":\"1.11554864\",\"4\":\"1.12562623\",\"5\":\"-4.4948216\",\"6\":\"-0.018650049\",\"7\":\"-0.43646237\",\"8\":\"0.01445958\",\"9\":\"-0.05300174\",\"10\":\"-0.92304770\",\"11\":\"-0.15955545\",\"12\":\"-0.88160147\",\"13\":\"-2.038289785\",\"14\":\"-1.94154531\",\"15\":\"0.24613107\",\"16\":\"0.84464173\",\"17\":\"-2.571419785\",\"18\":\"-0.05339078\",\"19\":\"1.79192853\",\"20\":\"-0.18537180\",\"21\":\"4.6845301\",\"22\":\"0.08617341\",\"23\":\"0.80669623\",\"24\":\"-1.88105009\",\"25\":\"-0.203054422\",\"26\":\"1.922219079\",\"27\":\"-0.14563004\",\"28\":\"-0.55872316\",\"29\":\"1.18479160\",\"30\":\"-1.949581510\",\"31\":\"0.739276554\",\"32\":\"-0.981160986\",\"33\":\"-0.60029578\",\"34\":\"-2.06411502\",\"35\":\"-1.176712206\",\"36\":\"-1.71415252\",\"37\":\"-0.25527209\",\"38\":\"-2.2140490\",\"39\":\"-2.02221530\",\"40\":\"0.978360589\",\"41\":\"-0.52602838\",\"42\":\"0.88853114\",\"43\":\"-0.966600239\",\"44\":\"-1.28103777\",\"45\":\"2.06534266\",\"46\":\"-0.87475178\",\"47\":\"-1.62021023\",\"48\":\"-0.935572710\",\"49\":\"-0.29666127\",\"50\":\"-1.62160029\",\"51\":\"0.139824454\"},{\"1\":\"1.9067960747\",\"2\":\"-0.94365774\",\"3\":\"-0.31582533\",\"4\":\"-0.71480967\",\"5\":\"-2.2128052\",\"6\":\"-0.416118337\",\"7\":\"0.39892162\",\"8\":\"-2.25833207\",\"9\":\"-1.24217368\",\"10\":\"-2.93952909\",\"11\":\"-0.33841379\",\"12\":\"-2.00590265\",\"13\":\"-1.645139844\",\"14\":\"-0.29028645\",\"15\":\"-0.23236843\",\"16\":\"0.95742738\",\"17\":\"-1.692583572\",\"18\":\"-0.47019421\",\"19\":\"-2.60403635\",\"20\":\"-0.34483620\",\"21\":\"2.4730019\",\"22\":\"0.21994034\",\"23\":\"-0.14083371\",\"24\":\"-3.24839711\",\"25\":\"2.616859946\",\"26\":\"-1.268588590\",\"27\":\"-1.53534470\",\"28\":\"1.23837517\",\"29\":\"-1.23497352\",\"30\":\"-0.928958312\",\"31\":\"0.301461637\",\"32\":\"1.730131449\",\"33\":\"0.40195925\",\"34\":\"-0.63610118\",\"35\":\"0.520392267\",\"36\":\"-2.73579967\",\"37\":\"-0.04400868\",\"38\":\"-2.5682087\",\"39\":\"-1.75945613\",\"40\":\"-0.471674694\",\"41\":\"-0.36641612\",\"42\":\"1.98322890\",\"43\":\"-2.209921851\",\"44\":\"-0.44935289\",\"45\":\"-1.20811766\",\"46\":\"-1.50873659\",\"47\":\"-0.98539518\",\"48\":\"-2.052112108\",\"49\":\"-0.10802601\",\"50\":\"0.18734714\",\"51\":\"-0.605281654\"},{\"1\":\"0.2628247283\",\"2\":\"-2.06904136\",\"3\":\"1.54260695\",\"4\":\"0.03412373\",\"5\":\"-3.5741028\",\"6\":\"1.121251949\",\"7\":\"-0.62528483\",\"8\":\"-1.10539378\",\"9\":\"-0.40590416\",\"10\":\"-0.06861237\",\"11\":\"-2.74372469\",\"12\":\"0.91166414\",\"13\":\"-1.420673903\",\"14\":\"-2.38740505\",\"15\":\"0.27176908\",\"16\":\"0.05611386\",\"17\":\"-1.774484547\",\"18\":\"-0.15685822\",\"19\":\"-3.00677416\",\"20\":\"-0.86082666\",\"21\":\"0.6153581\",\"22\":\"-0.08653469\",\"23\":\"0.07387194\",\"24\":\"-1.64751082\",\"25\":\"-0.340977393\",\"26\":\"-1.993244641\",\"27\":\"-1.56175388\",\"28\":\"-0.35136664\",\"29\":\"-0.87985134\",\"30\":\"0.355281831\",\"31\":\"-2.347948577\",\"32\":\"1.402910792\",\"33\":\"-0.01224617\",\"34\":\"-0.74842857\",\"35\":\"-1.318761491\",\"36\":\"-0.49995987\",\"37\":\"-1.77113898\",\"38\":\"-2.4404945\",\"39\":\"-2.91020740\",\"40\":\"-0.003887862\",\"41\":\"-0.81511934\",\"42\":\"3.39981173\",\"43\":\"-1.445651812\",\"44\":\"-1.12417482\",\"45\":\"-1.70718018\",\"46\":\"-1.06245165\",\"47\":\"-1.53620677\",\"48\":\"-2.394938499\",\"49\":\"-1.15146349\",\"50\":\"0.19506061\",\"51\":\"0.016912821\"},{\"1\":\"-0.0009192252\",\"2\":\"-3.03352735\",\"3\":\"-0.62692656\",\"4\":\"1.46510640\",\"5\":\"-2.5933725\",\"6\":\"-0.125275663\",\"7\":\"-0.01251780\",\"8\":\"-0.59142405\",\"9\":\"-0.78103102\",\"10\":\"-0.09071055\",\"11\":\"-0.94892225\",\"12\":\"-0.42346682\",\"13\":\"-1.250126744\",\"14\":\"0.63199375\",\"15\":\"-0.84608098\",\"16\":\"1.82101064\",\"17\":\"0.706196802\",\"18\":\"0.66292499\",\"19\":\"-1.95521789\",\"20\":\"-0.26986853\",\"21\":\"1.4440077\",\"22\":\"0.71553676\",\"23\":\"-1.35674723\",\"24\":\"0.02907571\",\"25\":\"0.545083070\",\"26\":\"-1.745829845\",\"27\":\"-1.35186886\",\"28\":\"1.94002211\",\"29\":\"-0.69232022\",\"30\":\"-2.308434754\",\"31\":\"-2.477693231\",\"32\":\"0.043900308\",\"33\":\"-0.91495842\",\"34\":\"0.01242985\",\"35\":\"-1.458378795\",\"36\":\"0.03892216\",\"37\":\"-1.11229587\",\"38\":\"-3.0574742\",\"39\":\"-0.93140665\",\"40\":\"-1.637142065\",\"41\":\"0.57095574\",\"42\":\"3.03143949\",\"43\":\"-1.417424822\",\"44\":\"-2.23634917\",\"45\":\"-0.23832034\",\"46\":\"-2.14235199\",\"47\":\"-2.09564719\",\"48\":\"0.300447546\",\"49\":\"-0.08741064\",\"50\":\"-0.27217705\",\"51\":\"-0.097578150\"},{\"1\":\"0.2820096915\",\"2\":\"-1.04938106\",\"3\":\"-0.22778609\",\"4\":\"-0.40995214\",\"5\":\"-2.2991367\",\"6\":\"1.234268804\",\"7\":\"0.82540995\",\"8\":\"-0.38500310\",\"9\":\"-0.88980019\",\"10\":\"-0.69843475\",\"11\":\"-1.20710757\",\"12\":\"-0.53957872\",\"13\":\"-1.551938389\",\"14\":\"-0.47745508\",\"15\":\"-0.15876769\",\"16\":\"-0.30873675\",\"17\":\"-0.378834679\",\"18\":\"-0.50061321\",\"19\":\"0.10192216\",\"20\":\"-0.92489662\",\"21\":\"3.0563438\",\"22\":\"-0.80196818\",\"23\":\"-0.24783953\",\"24\":\"1.31846415\",\"25\":\"0.959256689\",\"26\":\"0.054310745\",\"27\":\"-0.95944730\",\"28\":\"-0.51877613\",\"29\":\"-0.84988170\",\"30\":\"-0.497161789\",\"31\":\"-0.859004190\",\"32\":\"0.893648087\",\"33\":\"-1.16801037\",\"34\":\"-0.92435900\",\"35\":\"1.079861219\",\"36\":\"0.39000946\",\"37\":\"-2.16827769\",\"38\":\"-0.8872882\",\"39\":\"-0.49319000\",\"40\":\"0.338756171\",\"41\":\"0.95825894\",\"42\":\"2.28728379\",\"43\":\"-0.745757642\",\"44\":\"-0.81878131\",\"45\":\"1.48682047\",\"46\":\"-1.10958456\",\"47\":\"-2.81748463\",\"48\":\"-0.839945504\",\"49\":\"-2.01624583\",\"50\":\"0.83344632\",\"51\":\"1.166006490\"},{\"1\":\"-0.3852036905\",\"2\":\"-0.74923766\",\"3\":\"0.19191542\",\"4\":\"1.01910723\",\"5\":\"-1.9432130\",\"6\":\"0.085277964\",\"7\":\"1.10522586\",\"8\":\"0.77283696\",\"9\":\"-0.79723517\",\"10\":\"-0.02837697\",\"11\":\"-0.79008626\",\"12\":\"-1.49154910\",\"13\":\"-1.688591851\",\"14\":\"0.27401554\",\"15\":\"0.54423076\",\"16\":\"-0.39412384\",\"17\":\"-0.323606906\",\"18\":\"-0.05679257\",\"19\":\"-2.31858853\",\"20\":\"0.13122726\",\"21\":\"2.2863080\",\"22\":\"-0.67365241\",\"23\":\"-1.55163854\",\"24\":\"1.12280991\",\"25\":\"-1.779591569\",\"26\":\"-1.234193857\",\"27\":\"-1.47782368\",\"28\":\"-1.98956321\",\"29\":\"0.40528430\",\"30\":\"-0.034383203\",\"31\":\"-0.777625902\",\"32\":\"3.150270776\",\"33\":\"-0.58004587\",\"34\":\"-1.62502497\",\"35\":\"1.265184741\",\"36\":\"-0.73654543\",\"37\":\"-1.92579809\",\"38\":\"-2.0148518\",\"39\":\"-2.67837750\",\"40\":\"-0.087474153\",\"41\":\"1.10495125\",\"42\":\"1.43642660\",\"43\":\"-2.192982342\",\"44\":\"-2.20860916\",\"45\":\"-0.22787267\",\"46\":\"-0.89140368\",\"47\":\"-0.77298526\",\"48\":\"-1.515715835\",\"49\":\"-3.59649929\",\"50\":\"-0.11935965\",\"51\":\"-0.220956554\"},{\"1\":\"1.8784250757\",\"2\":\"-3.01854346\",\"3\":\"0.31731654\",\"4\":\"0.72027122\",\"5\":\"-2.4578591\",\"6\":\"0.598442730\",\"7\":\"1.07214475\",\"8\":\"0.62058029\",\"9\":\"-0.96256363\",\"10\":\"-1.99370892\",\"11\":\"-2.36241158\",\"12\":\"-0.49425570\",\"13\":\"-0.245972626\",\"14\":\"-0.14927703\",\"15\":\"0.51082811\",\"16\":\"2.23091896\",\"17\":\"1.350887118\",\"18\":\"-1.47332557\",\"19\":\"0.76890776\",\"20\":\"-2.05332962\",\"21\":\"3.3675674\",\"22\":\"1.95976437\",\"23\":\"-2.91224518\",\"24\":\"-1.85863575\",\"25\":\"1.096862292\",\"26\":\"-1.093609986\",\"27\":\"-2.77502002\",\"28\":\"-0.48330786\",\"29\":\"-2.19265186\",\"30\":\"1.255286950\",\"31\":\"-0.262504169\",\"32\":\"1.886394824\",\"33\":\"-0.68359299\",\"34\":\"-0.83787858\",\"35\":\"-0.728293219\",\"36\":\"-1.81629815\",\"37\":\"-1.77905508\",\"38\":\"-2.7832467\",\"39\":\"-0.93963846\",\"40\":\"0.345013484\",\"41\":\"-1.43329827\",\"42\":\"-0.27629970\",\"43\":\"-3.825692446\",\"44\":\"0.04164156\",\"45\":\"-0.17089696\",\"46\":\"-1.69608356\",\"47\":\"-0.36694909\",\"48\":\"-0.782046973\",\"49\":\"-1.72366931\",\"50\":\"-0.25946385\",\"51\":\"0.009422666\"},{\"1\":\"1.1450308698\",\"2\":\"-0.03714160\",\"3\":\"0.96908691\",\"4\":\"1.92997050\",\"5\":\"-2.9129718\",\"6\":\"0.709546654\",\"7\":\"-0.30869956\",\"8\":\"-1.19491168\",\"9\":\"-0.02496738\",\"10\":\"0.48358893\",\"11\":\"-1.07931250\",\"12\":\"-0.03718509\",\"13\":\"-2.229457721\",\"14\":\"1.07607781\",\"15\":\"0.01007375\",\"16\":\"-1.75325857\",\"17\":\"-1.227955500\",\"18\":\"-0.28056604\",\"19\":\"0.42126042\",\"20\":\"-0.10605462\",\"21\":\"3.3994488\",\"22\":\"1.22863945\",\"23\":\"0.45092167\",\"24\":\"-1.28109676\",\"25\":\"-1.450665912\",\"26\":\"-1.001046097\",\"27\":\"-2.33819283\",\"28\":\"0.05731513\",\"29\":\"-1.37125339\",\"30\":\"1.660826277\",\"31\":\"-2.405536145\",\"32\":\"-0.174931768\",\"33\":\"0.74371533\",\"34\":\"1.13077045\",\"35\":\"1.779852134\",\"36\":\"-1.75679088\",\"37\":\"-2.48434153\",\"38\":\"-1.7814357\",\"39\":\"-1.01205729\",\"40\":\"-0.704964424\",\"41\":\"0.29338830\",\"42\":\"0.71864269\",\"43\":\"-1.164453823\",\"44\":\"-2.68472435\",\"45\":\"0.58257961\",\"46\":\"-0.95310945\",\"47\":\"-0.32935616\",\"48\":\"0.955162780\",\"49\":\"-1.76784138\",\"50\":\"-0.25578421\",\"51\":\"-0.149297982\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nLet us isolate a single simulated data set and run best subset regression to find the optimal model under Mallow’s CP.\n\n\nregModels <- regsubsets(y ~ ., data = dat, method = \"seqrep\")\nsummary(regModels)\n\n\nSubset selection object\nCall: regsubsets.formula(y ~ ., data = dat, method = \"seqrep\")\n50 Variables  (and intercept)\n    Forced in Forced out\nV1      FALSE      FALSE\nV2      FALSE      FALSE\nV3      FALSE      FALSE\nV4      FALSE      FALSE\nV5      FALSE      FALSE\nV6      FALSE      FALSE\nV7      FALSE      FALSE\nV8      FALSE      FALSE\nV9      FALSE      FALSE\nV10     FALSE      FALSE\nV11     FALSE      FALSE\nV12     FALSE      FALSE\nV13     FALSE      FALSE\nV14     FALSE      FALSE\nV15     FALSE      FALSE\nV16     FALSE      FALSE\nV17     FALSE      FALSE\nV18     FALSE      FALSE\nV19     FALSE      FALSE\nV20     FALSE      FALSE\nV21     FALSE      FALSE\nV22     FALSE      FALSE\nV23     FALSE      FALSE\nV24     FALSE      FALSE\nV25     FALSE      FALSE\nV26     FALSE      FALSE\nV27     FALSE      FALSE\nV28     FALSE      FALSE\nV29     FALSE      FALSE\nV30     FALSE      FALSE\nV31     FALSE      FALSE\nV32     FALSE      FALSE\nV33     FALSE      FALSE\nV34     FALSE      FALSE\nV35     FALSE      FALSE\nV36     FALSE      FALSE\nV37     FALSE      FALSE\nV38     FALSE      FALSE\nV39     FALSE      FALSE\nV40     FALSE      FALSE\nV41     FALSE      FALSE\nV42     FALSE      FALSE\nV43     FALSE      FALSE\nV44     FALSE      FALSE\nV45     FALSE      FALSE\nV46     FALSE      FALSE\nV47     FALSE      FALSE\nV48     FALSE      FALSE\nV49     FALSE      FALSE\nV50     FALSE      FALSE\n1 subsets of each size up to 8\nSelection Algorithm: 'sequential replacement'\n         V1  V2  V3  V4  V5  V6  V7  V8  V9  V10 V11 V12 V13 V14 V15\n1  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\n2  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\n3  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\n4  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\n5  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\n6  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\n7  ( 1 ) \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \"*\" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\n8  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\n         V16 V17 V18 V19 V20 V21 V22 V23 V24 V25 V26 V27 V28 V29 V30\n1  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \" \" \" \"\n2  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \" \" \" \"\n3  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \" \" \" \"\n4  ( 1 ) \" \" \" \" \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \" \" \" \"\n5  ( 1 ) \" \" \" \" \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \" \" \" \"\n6  ( 1 ) \" \" \" \" \" \" \" \" \"*\" \"*\" \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \" \" \" \"\n7  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\n8  ( 1 ) \" \" \" \" \" \" \" \" \"*\" \"*\" \"*\" \"*\" \" \" \"*\" \" \" \" \" \" \" \" \" \" \"\n         V31 V32 V33 V34 V35 V36 V37 V38 V39 V40 V41 V42 V43 V44 V45\n1  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\n2  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"*\" \" \" \" \" \" \"\n3  ( 1 ) \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"*\" \" \" \" \" \" \"\n4  ( 1 ) \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"*\" \" \" \" \" \" \"\n5  ( 1 ) \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \" \" \" \" \" \" \"*\" \"*\" \" \" \" \" \" \"\n6  ( 1 ) \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"*\" \" \" \" \" \"*\"\n7  ( 1 ) \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\n8  ( 1 ) \" \" \" \" \" \" \"*\" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"*\" \" \" \" \" \"*\"\n         V46 V47 V48 V49 V50\n1  ( 1 ) \" \" \" \" \" \" \" \" \" \"\n2  ( 1 ) \" \" \" \" \" \" \" \" \" \"\n3  ( 1 ) \" \" \" \" \" \" \" \" \" \"\n4  ( 1 ) \" \" \" \" \" \" \" \" \" \"\n5  ( 1 ) \" \" \" \" \" \" \" \" \" \"\n6  ( 1 ) \" \" \" \" \" \" \" \" \" \"\n7  ( 1 ) \" \" \" \" \" \" \" \" \" \"\n8  ( 1 ) \" \" \" \" \" \" \" \" \" \"\n\n(summary(regModels))$cp\n\n\n[1] -14.0521112 -17.0406336 -18.3085899 -18.9432957 -19.1090465\n[6] -19.8467302   0.5527809 -18.5851708\n\nWe can see here that the number of predictors with the lower Mallow CP score is 6. Suppose we chose this model as our optimal predictor, and use the selected model for inference on the training data. What would be the result?\n\n\nsimData <-\nsimData %>% \n  mutate(models = map(xyDat, ~regsubsets(y ~ ., data = .x, method = \"seqrep\"))) %>%\n  mutate(mallowcp = map(models, ~(summary(.x))$cp)) %>%\n  mutate(coefvals = map2(models, mallowcp, ~coef(.x, which.min(.y)) %>% unname() ) )\n\npaged_table(simData)\n\n\n\n\n{\"columns\":[{\"label\":[\"run\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"xyDat\"],\"name\":[2],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"models\"],\"name\":[3],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"mallowcp\"],\"name\":[4],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"coefvals\"],\"name\":[5],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"2\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"3\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"4\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"5\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"6\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"7\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"8\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"9\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"10\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [3]>\"},{\"1\":\"11\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"12\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"13\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"14\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"15\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"16\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"17\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"18\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"19\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"20\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"21\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"22\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"23\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"24\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"25\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"26\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"27\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"28\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"29\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"30\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"31\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"32\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"33\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"34\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"35\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"36\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"37\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"38\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"39\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"40\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"41\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"42\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"43\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"44\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"45\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"46\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"47\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"48\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"49\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"50\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"51\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"52\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"53\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"54\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"55\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"56\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"57\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"58\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"59\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"60\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"61\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"62\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"63\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"64\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"65\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"66\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"67\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"68\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"69\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"70\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"71\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"72\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"73\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"74\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"75\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"76\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [2]>\"},{\"1\":\"77\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"78\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"79\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"80\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"81\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"82\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"83\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"84\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [2]>\"},{\"1\":\"85\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"86\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"87\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"88\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"89\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"90\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"91\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"92\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [3]>\"},{\"1\":\"93\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"94\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"95\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"96\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"97\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"98\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"99\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"100\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"101\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"102\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"103\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"104\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"105\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"106\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"107\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"108\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"109\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"110\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"111\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"112\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"113\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"114\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"115\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"116\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"117\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"118\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"119\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"120\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"121\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"122\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"123\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"124\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"125\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"126\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"127\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"128\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"129\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"130\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"131\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"132\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"133\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"134\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"135\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"136\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"137\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"138\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"139\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"140\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"141\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"142\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"143\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"144\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"145\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"146\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"147\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"148\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"149\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"150\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"151\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"152\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"153\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"154\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"155\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"156\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"157\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"158\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"159\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"160\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"161\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"162\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"163\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"164\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"165\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"166\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"167\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"168\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"169\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"170\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"171\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"172\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"173\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"174\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"175\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"176\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"177\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"178\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"179\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"180\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"181\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"182\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"183\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"184\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [3]>\"},{\"1\":\"185\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"186\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"187\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"188\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"189\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"190\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"191\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"192\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"193\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"194\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"195\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"196\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"197\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"198\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"199\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"200\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"201\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"202\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"203\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"204\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"205\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"206\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"207\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"208\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"209\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"210\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"211\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"212\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"213\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"214\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"215\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"216\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"217\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"218\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"219\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"220\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"221\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [2]>\"},{\"1\":\"222\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"223\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"224\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"225\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"226\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"227\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"228\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"229\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"230\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"231\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [2]>\"},{\"1\":\"232\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"233\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"234\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"235\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"236\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"237\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"238\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"239\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"240\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"241\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"242\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"243\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"244\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"245\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"246\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"247\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"248\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"249\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"250\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"251\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"252\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"253\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"254\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"255\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"256\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"257\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"258\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"259\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"260\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"261\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"262\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"263\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"264\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"265\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"266\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"267\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"268\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"269\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"270\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"271\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"272\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"273\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"274\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"275\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"276\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"277\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"278\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"279\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"280\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"281\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"282\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"283\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"284\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"285\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"286\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"287\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"288\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"289\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"290\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"291\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"292\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"293\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"294\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"295\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"296\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"297\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"298\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"299\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"300\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"301\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"302\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"303\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"304\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"305\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"306\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"307\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"308\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"309\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"310\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"311\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"312\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"313\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"314\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"315\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"316\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"317\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"318\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"319\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"320\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"321\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"322\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"323\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"324\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [2]>\"},{\"1\":\"325\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"326\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"327\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"328\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"329\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"330\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"331\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"332\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"333\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"334\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"335\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"336\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"337\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"338\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"339\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"340\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"341\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"342\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"343\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"344\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"345\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"346\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"347\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"348\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"349\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"350\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"351\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"352\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [3]>\"},{\"1\":\"353\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"354\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"355\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"356\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"357\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"358\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"359\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [3]>\"},{\"1\":\"360\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"361\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"362\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"363\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"364\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [3]>\"},{\"1\":\"365\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"366\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [3]>\"},{\"1\":\"367\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"368\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"369\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"370\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"371\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"372\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"373\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"374\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"375\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"376\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"377\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"378\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"379\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"380\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"381\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"382\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [2]>\"},{\"1\":\"383\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"384\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"385\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"386\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"387\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"388\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"389\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"390\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"391\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"392\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"393\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"394\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"395\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"396\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"397\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"398\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"399\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"400\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"401\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"402\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"403\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"404\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [3]>\"},{\"1\":\"405\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"406\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"407\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"408\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"409\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"410\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"411\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"412\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"413\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"414\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"415\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"416\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"417\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"418\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"419\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"420\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"421\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"422\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"423\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"424\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"425\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"426\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"427\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"428\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"429\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [3]>\"},{\"1\":\"430\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"431\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"432\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"433\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"434\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"435\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"436\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"437\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"438\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"439\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"440\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"441\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"442\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"443\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"444\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"445\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"446\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"447\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"448\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"449\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"450\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"451\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"452\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"453\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"454\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"455\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"456\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"457\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"458\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"459\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"460\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"461\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"462\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [3]>\"},{\"1\":\"463\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"464\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"465\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"466\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"467\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"468\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"469\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"470\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"471\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"472\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"473\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [3]>\"},{\"1\":\"474\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"475\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"476\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"477\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"478\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [7]>\"},{\"1\":\"479\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"480\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"481\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"482\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"483\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"484\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [4]>\"},{\"1\":\"485\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"486\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"487\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"488\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"489\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [6]>\"},{\"1\":\"490\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [5]>\"},{\"1\":\"491\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"492\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"493\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"494\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"495\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"496\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"497\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [8]>\"},{\"1\":\"498\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"499\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"},{\"1\":\"500\",\"2\":\"<tbl_df[,51]>\",\"3\":\"<S3: regsubsets>\",\"4\":\"<dbl [8]>\",\"5\":\"<dbl [9]>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nNow let us plot the coefficient values from the estimation\n\n\ncoefdat <- flatten(simData$coefvals) %>% as.double()\ntibble(coefdat = coefdat) %>% ggplot() + geom_density(aes(x = coefdat))\n\n\n\n\nSuppose instead we fix the model in advance that we estimate\n\n\nsimData <-\n  simData %>% \n  mutate(fixedMod = map(xyDat, ~lm(y ~ V1 + V2 + V3 + V4, data = .x) ) ) %>%\n  mutate(fixedCoef = map(fixedMod, ~coef(.x) %>% unname() ) )\n\ncoefdata <- flatten(simData$fixedCoef) %>% as.double()\ntibble(coefdat = coefdata) %>% ggplot() + geom_density(aes(x = coefdata))\n\n\n\n\n\n\n\n",
    "preview": "https://d33wubrfki0l68.cloudfront.net/478f2689f1b9903ce2feed61a1f5e9c9deb2bcc9/55b03/post/commentary/inference-vs-prediction_files/figure-html/unnamed-chunk-1-1.png",
    "last_modified": "2021-02-09T15:07:19+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-03-predictive-accuracy-the-what-and-the-how/",
    "title": "Predictive Accuracy: The What and the How",
    "description": "measuring and managing the performance of an algorithmic model",
    "author": [
      {
        "name": "Amit Gandhi",
        "url": {}
      }
    ],
    "date": "2021-02-03",
    "categories": [],
    "contents": "\nIntroduction\nIn the last post, we examined decision tree as an algorithmic model to understand the behavior of data. As we saw, the optimal tree is one where we grew a large tree, and pruned it to avoid an “overfitting problem” as measured by the cost complexity criterion. But what is the over-fitting problem with algorithmic models, and why did the cost complexity criterion allow us to manage it?\nTrees are formed via an algorithm - CART - which is a predictive structure for predicting an outcome variable \\(Y\\) from explanatory variables \\(X\\). The particular tree that was formed depended on two key inputs\nThe training sample \\(D = \\{(y_1, x_1),\\dots, (y_n, x_n)\\}\\)\nThe tuning parameters (also called hyperparameters) \\(\\eta\\) which governs the behavior of the algorithm.\nThe predictive structure is connected to the conditional distribution of the outcome variable \\(Y\\) given the explanatory variables \\(X\\), e.g., a feature \\(F_{Y\\mid X}(y \\mid X = x)\\).\nGiven the training sample \\(D\\) and hyperparameters, the CART algorithm generates a fitted predictor \\(\\hat{m}\\). Although we do not have that much choice over the training sample \\(D\\) (although as we will see below, we have some choice), we do have more discretion over the tuning parameters. Thus a very practical problem we face in algorithmic model is that we must se tthe value of \\(\\eta\\), e.g., \\(\\hat{\\eta}\\). This process is called (rather simply) tuning. A more elaborate description would be hyperparameter optimization\nIn this post we examine the more general principles around tuning with an eye towards its practical implementation in the case of the CART algorithm.\nThe tuning problem\nWhat are the tuning parameters in CART? Lets take a look a look at the help file?\n\n\nrpart\n\n\nR Documentation\n\n\nRecursive Partitioning and Regression Trees\n\n\nDescription\n\n\nFit a rpart model\n\n\nUsage\n\n\nrpart(formula, data, weights, subset, na.action = na.rpart, method,\n      model = FALSE, x = FALSE, y = TRUE, parms, control, cost, ...)\n\n\nArguments\n\n\nformula\n\n\n\na formula, with a response but no interaction terms. If this a a data frame, that is taken as the model frame (see model.frame).\n\n\n\ndata\n\n\n\nan optional data frame in which to interpret the variables named in the formula.\n\n\n\nweights\n\n\n\noptional case weights.\n\n\n\nsubset\n\n\n\noptional expression saying that only a subset of the rows of the data should be used in the fit.\n\n\n\nna.action\n\n\n\nthe default action deletes all observations for which y is missing, but keeps those in which one or more predictors are missing.\n\n\n\nmethod\n\n\n\none of “anova”, “poisson”, “class” or “exp”. If method is missing then the routine tries to make an intelligent guess. If y is a survival object, then method = “exp” is assumed, if y has 2 columns then method = “poisson” is assumed, if y is a factor then method = “class” is assumed, otherwise method = “anova” is assumed. It is wisest to specify the method directly, especially as more criteria may added to the function in future.\n\n\nAlternatively, method can be a list of functions named init, split and eval. Examples are given in the file ‘tests/usersplits.R’ in the sources, and in the vignettes ‘User Written Split Functions’.\n\n\n\nmodel\n\n\n\nif logical: keep a copy of the model frame in the result? If the input value for model is a model frame (likely from an earlier call to the rpart function), then this frame is used rather than constructing new data.\n\n\n\nx\n\n\n\nkeep a copy of the x matrix in the result.\n\n\n\ny\n\n\n\nkeep a copy of the dependent variable in the result. If missing and model is supplied this defaults to FALSE.\n\n\n\nparms\n\n\n\noptional parameters for the splitting function. Anova splitting has no parameters. Poisson splitting has a single parameter, the coefficient of variation of the prior distribution on the rates. The default value is 1. Exponential splitting has the same parameter as Poisson. For classification splitting, the list can contain any of: the vector of prior probabilities (component prior), the loss matrix (component loss) or the splitting index (component split). The priors must be positive and sum to 1. The loss matrix must have zeros on the diagonal and positive off-diagonal elements. The splitting index can be gini or information. The default priors are proportional to the data counts, the losses default to 1, and the split defaults to gini.\n\n\n\ncontrol\n\n\n\na list of options that control details of the rpart algorithm. See rpart.control.\n\n\n\ncost\n\n\n\na vector of non-negative costs, one for each variable in the model. Defaults to one for all variables. These are scalings to be applied when considering splits, so the improvement on splitting on a variable is divided by its cost in deciding which split to choose.\n\n\n\n…\n\n\n\narguments to rpart.control may also be specified in the call to rpart. They are checked against the list of valid arguments.\n\n\n\nDetails\n\n\nThis differs from the tree function in S mainly in its handling of surrogate variables. In most details it follows Breiman et. al (1984) quite closely. R package tree provides a re-implementation of tree.\n\n\nValue\n\n\nAn object of class rpart. See rpart.object.\n\n\nReferences\n\n\nBreiman L., Friedman J. H., Olshen R. A., and Stone, C. J. (1984) Classification and Regression Trees. Wadsworth.\n\n\nSee Also\n\n\nrpart.control, rpart.object, summary.rpart, print.rpart\n\n\nExamples\n\n\nfit <- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis)\nfit2 <- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis,\n              parms = list(prior = c(.65,.35), split = \"information\"))\nfit3 <- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis,\n              control = rpart.control(cp = 0.05))\npar(mfrow = c(1,2), xpd = NA) # otherwise on some devices the text is clipped\nplot(fit)\ntext(fit, use.n = TRUE)\nplot(fit2)\ntext(fit2, use.n = TRUE)\n\n\nThe help file reveals several places where the algorithm can be tuned. Among them is a reference to an argument control, which is a list of options that control the detail of the algorithm. We can examine the parameters of the list:\n\n\nrpart.control\n\n\nR Documentation\n\n\nControl for Rpart Fits\n\n\nDescription\n\n\nVarious parameters that control aspects of the rpart fit.\n\n\nUsage\n\n\nrpart.control(minsplit = 20, minbucket = round(minsplit/3), cp = 0.01, \n              maxcompete = 4, maxsurrogate = 5, usesurrogate = 2, xval = 10,\n              surrogatestyle = 0, maxdepth = 30, ...)\n\n\nArguments\n\n\nminsplit\n\n\n\nthe minimum number of observations that must exist in a node in order for a split to be attempted.\n\n\n\nminbucket\n\n\n\nthe minimum number of observations in any terminal <leaf> node. If only one of minbucket or minsplit is specified, the code either sets minsplit to minbucket*3 or minbucket to minsplit/3, as appropriate.\n\n\n\ncp\n\n\n\ncomplexity parameter. Any split that does not decrease the overall lack of fit by a factor of cp is not attempted. For instance, with anova splitting, this means that the overall R-squared must increase by cp at each step. The main role of this parameter is to save computing time by pruning off splits that are obviously not worthwhile. Essentially,the user informs the program that any split which does not improve the fit by cp will likely be pruned off by cross-validation, and that hence the program need not pursue it.\n\n\n\nmaxcompete\n\n\n\nthe number of competitor splits retained in the output. It is useful to know not just which split was chosen, but which variable came in second, third, etc.\n\n\n\nmaxsurrogate\n\n\n\nthe number of surrogate splits retained in the output. If this is set to zero the compute time will be reduced, since approximately half of the computational time (other than setup) is used in the search for surrogate splits.\n\n\n\nusesurrogate\n\n\n\nhow to use surrogates in the splitting process. 0 means display only; an observation with a missing value for the primary split rule is not sent further down the tree. 1 means use surrogates, in order, to split subjects missing the primary variable; if all surrogates are missing the observation is not split. For value 2 ,if all surrogates are missing, then send the observation in the majority direction. A value of 0 corresponds to the action of tree, and 2 to the recommendations of Breiman et.al (1984).\n\n\n\nxval\n\n\n\nnumber of cross-validations.\n\n\n\nsurrogatestyle\n\n\n\ncontrols the selection of a best surrogate. If set to 0 (default) the program uses the total number of correct classification for a potential surrogate variable, if set to 1 it uses the percent correct, calculated over the non-missing values of the surrogate. The first option more severely penalizes covariates with a large number of missing values.\n\n\n\nmaxdepth\n\n\n\nSet the maximum depth of any node of the final tree, with the root node counted as depth 0. Values greater than 30 rpart will give nonsense results on 32-bit machines.\n\n\n\n…\n\n\n\nmop up other arguments.\n\n\n\nValue\n\n\nA list containing the options.\n\n\nSee Also\n\n\nrpart\n\n\nWe can see a few tuning parameters that stand out - minsplit, minbucket, cp, and xval, which are initiatlized to specific values. The user has control of the algorithm by setting these values.\nPrediction Error\nThe tuning parameters in general should be set to maximize the performance of the model. But what is performance?\nSuppose we make a prediction \\(\\hat{Y}\\) and the realized outcome is \\(Y\\), where in general we should not expect perfect prediction and hence \\(\\hat{Y} \\neq Y\\). There is a loss \\(L(Y,\\hat{Y})\\) incurred from missing the target. Common loss functions are\n\\[\nL(\\hat{Y}, Y) = \n\\begin{cases}\n(Y-\\hat{Y})^2 \\mbox{ for regression}\\\\\n\\mathbf{1}(Y \\neq \\hat{Y}) \\mbox{ for classification}\n\\end{cases}\n\\]\nGiven the loss function, what is the predictive performance of the predictor \\(\\hat{m}\\).\nIf the goal is to use the predictor to predict in the population that has yet to be observed, then the natural performance criterion is the average loss in the population\n\\[\nErr_{D} = E_{Y^{0}, X^{0}} \\left[L(Y^{0}, \\hat{m}(X^{0})) \\mid D \\right]\n\\] where the expectation is taken with respect to the randomness in \\((Y^{0}, X^{0}) \\sim F_{Y,X}\\). This is the test error or generalization error, e.g., the average error we would expect in an independent test sample. Notice that the training sample \\(D\\) is conditioned out in the assesment of performance under \\(Err_{D}\\)\nAlthough \\(Err_{D}\\) is the ideal performance measure, it is challenging to analyze or forecast. However if we could measure it, then this provides a path to tuning. Notice that \\(Err_{D} = Err_{D}(\\eta)\\), and hence optimal tuning would amount to\n\\[\n\\hat{\\eta} = \\arg \\max_{\\eta} Err_{D}(\\eta)\n\\] Thus \\(Err_{D}(\\eta)\\) would serve two distinct purposes (ESL p 222)\n Model tuning : estimating the performance of different algorithmic models indexed by \\(\\eta\\) in order to choose the best one.\n Model assessment : having chosen a final model, estimating its prediction error (generalization error) on new data.\nIn an ideal circumstance to carry out these calculations we would have a sample of data broken into three parts.\nTraining Set\nValidation Set\nTest Set\n\n\n\nThe training set would be used to fit the data \\(\\hat{f}(\\eta)\\). The validation set could be used to tune the algorithm’s \\(\\eta\\) based on average loss in the validation set. And then the test set would provide a clean assesment of the test error of the tuned model at $.\nWe typically will not have enough data for this rather clean experiment without seriously compromising the size of the training sample (which detracts from the algorithm’s performance).\nInstead we will need to live in a second best world and consider a slightly augmented measure of performance, the average test error, where we also account for randomness in the training sample itself\n\\[\nErr(\\eta) = E_D\\left[Err_{D}\\right(\\eta)]\n\\] If we imagine ordering \\(\\eta\\) such that lower values of \\(eta\\) generate simpler fitted models, and higher values of \\(\\eta\\) generate more complex fitted models, then the behavior of \\(Err(\\eta)\\) creates the canonical picture of Bias Variance Tradeoff (ESL p. 220)\n\n\n\nOptimism\nLet the training sample be $ D = {(y_i,x_i)}_{i=1}^{n}$\nConsider a fitted model \\(\\hat{y}_{i}=\\hat{m}\\left(x_{i}\\right)\\), which can come from any algorithmic model \\(m\\), and implicitly depends on the tuning parameter \\(\\eta\\).\nFor simplicity consider a regression problem with squared error loss (the analysis below generalizes to many loss functions)\nThe in-sample training error is \\[\n\\overline{err}=\\frac{1}{n}\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\n\\]\nWe have a general understanding that the \\(\\overline{err}\\) is an optimistic assessment of the object of interest, namely the test error \\(Err_{D}\\). Can we formalize the relationship to gauge just how optimistic?\nOne source of the discrepancy is that the test experiment is evaluated at potentially different points of the explanatory variables as compared to the training simple. To eliminate this additional variability, it is useful to consider the in-sample test error \\[\nErr_{\\mbox{in}} = \\frac{1}{n} \\sum E_{Y^{0}}\\left[L(Y_{i}^{0}, \\hat{m}(x_{i}) \\mid D \\right]\n\\]\nOptimism can be defined as\n\\[\n\\mbox{opp} \\equiv Err_{\\mbox{in}} - \\overline{err}\n\\]\nIt turns out there is a natural characterization of the expected optimism, or \\[\n\\omega = E_{\\mathbf{y}}[\\mbox{opp}]\n\\] Where the expectation is taken with respect to the training points \\(\\mathbf{y} = (y_i)_{i=1}^{n}\\)\n\n\\(\\omega = \\frac{2}{n}\\sum_{i}\\mbox{Cov}(y_{i}, \\hat{y}_i)\\)\n\n\nThe interpretation, to quote ESL\n\nThus the amount by which \\(\\overline{err}\\) underestimates the true error depends on how strongly \\(y_{i}\\) affects its own prediction. The harder we fit the data, the greater \\(Cov(\\hat{y}_i, y_i)\\) will be, thereby increasing the optimism.\n\nThe proof of this result is remarkably straightforward.\nFor ease of notation, let the new test data generated from the same points for the explanatory variables as the training set be denoted simply as \\(y_{i}^{\\prime} = Y_{i}^{0}\\)\nThe prediction error is then \\[\n\\frac{1}{n}\\sum\\left(y_{i}^{\\prime}-\\hat{y}_{i}\\right)^{2}\n\\]\nObserve that the \\(\\hat{y}_{i}'s\\) are functions of all the \\(y_{i}'s\\) and so are dependent random variables.\nHowever \\(y_{i}^{\\prime}\\) is independent of \\(\\hat{y}_{i}\\).\nRecall the formula\n\\[V\\left(Z\\right)=E\\left[Z^{2}\\right]-E\\left[Z\\right]^{2}\\implies E\\left[Z^{2}\\right]=V\\left[Z\\right]+E\\left[Z\\right]^{2}\\]\nThen \\[\\begin{align*}\nE\\left[\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\\right] & =V\\left[y_{i}-\\hat{y}_{i}\\right]+E\\left[y_{i}-\\hat{y}_{i}\\right]^{2}\\\\\n & =V\\left[y_{i}\\right]+V\\left[\\hat{y}_{i}\\right]-2Cov\\left[y_{i},\\hat{y}_{i}\\right]+\\left(E\\left[y_{i}\\right]-E\\left[\\hat{y}_{i}\\right]\\right)^{2}\n\\end{align*}\\]\nObserve on the other hand that using the fact \\(E\\left[y_{i}\\right]=E\\left[y_{i}^{\\prime}\\right]\\) and \\(V\\left[y_{i}^{\\prime}\\right]=V\\left[y_{i}\\right]\\)\n\\[\\begin{align*}\nE\\left[\\left(y_{i}^{\\prime}-\\hat{y}_{i}\\right)^{2}\\right] & =V\\left[y_{i}^{\\prime}\\right]+V\\left[\\hat{y}_{i}\\right]-2Cov\\left[y_{i}^{\\prime},\\hat{y}_{i}\\right]+\\left(E\\left[y_{i}^{\\prime}\\right]-E\\left[\\hat{y}_{i}\\right]\\right)^{2}\\\\\n & =V\\left[y_{i}\\right]+V\\left[\\hat{y}_{i}\\right]+\\left(E\\left[y_{i}\\right]-E\\left[\\hat{y}_{i}\\right]\\right)^{2}\n\\end{align*}\\]\nHence we have the relationship that \\[\nE\\left[\\left(y_{i}^{\\prime}-\\hat{y}_{i}\\right)^{2}\\right]=E\\left[\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\\right]+2Cov\\left[y_{i},\\hat{y}_{i}\\right].\n\\]\nAveraging over data points \\[\nE\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_{i}^{\\prime}-\\hat{y}_{i}\\right)^{2}\\right]=E\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\\right]+\\frac{2}{n}\\sum_{i}Cov\\left(y_{i},\\hat{y}_{i}\\right).\n\\]\nWe can frame the result in a slightly different way for the specialized case where the true DGP is\n\\[\ny_{i} = m(x_i)+\\epsilon_i\n\\] For a homoskedastic \\(\\epsilon_i\\) with variance \\(\\sigma^2\\).\nLet us define the degrees of freedom \\(df\\left(\\hat{y}\\right)\\) of the fitted model \\(\\hat{y}\\) as \\[\ndf\\left(\\hat{y}\\right)=\\frac{1}{\\sigma^{2}}\\sum Cov\\left(y_{i},\\hat{y}_{i}\\right),\n\\]\nThen the relationship becomes \\[\nE\\left[\\left(y_{i}^{\\prime}-\\hat{y}_{i}\\right)^{2}\\right]=E\\left[\\left(y_{i}-\\hat{y}_{i}\\right)^{2}\\right]+\\frac{2\\sigma^{2}}{n}df\\left(\\hat{y}\\right)\n\\] which is words says that the expected test error is exactly the expected training error plus a constant factor \\(\\left(\\frac{2\\sigma^{2}}{n}\\right)\\) times the degree of freedom.\nThis gives us an approach to model selection. Suppose we have a family of fitted values \\(\\hat{y}_{\\eta}\\) which depends on a tuning parameter.\nThen we can estimate \\[\nErr_{\\mbox{in}}(\\eta) =\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_{i}-\\left(\\hat{y}_{\\eta}\\right)_{i}\\right)^{2}+\\frac{2\\sigma^{2}}{n}df\\left(\\hat{y}_{\\eta}\\right)\n\\] replacing \\(\\sigma^{2}\\) and \\(df\\) with estimates if needed.\nThen we can select \\[\n\\hat{\\eta}=\\arg\\min_{\\eta\\in\\Theta}\\frac{1}{n}\\left(y_{i}-\\left(\\hat{y}_{\\eta}\\right)_{i}\\right)^{2}+\\frac{2\\sigma^{2}}{n}df\\left(\\hat{y}_{\\eta}\\right)\n\\]\nObserve that for a linear regression model this becomes \\[\\begin{align*}\ndf\\left(\\hat{y}^{linreg}\\right) & =\\\\\n\\frac{1}{\\sigma^{2}}Tr\\left(Cov\\left(X\\left(X^{\\prime}X\\right)^{-1}X^{\\prime}Y\\right),Y\\right) & =\\\\\n\\frac{1}{\\sigma^{2}}Tr\\left(X\\left(X^{\\prime}X\\right)^{-1}X^{\\prime}V\\left[Y\\right]\\right) & =\\\\\nTr\\left(X\\left(X^{\\prime}X\\right)^{-1}X^{\\prime}\\right) & =\\\\\nTr\\left(X^{\\prime}X\\left(X^{\\prime}X\\right)^{-1}\\right) & =p\n\\end{align*}\\]\nThe optimism term \\(\\frac{2}{n}\\sigma^{2}\\left(p\\right)\\) depends on 3 key factors\nGrows with \\(\\sigma^{2}\\): more noise gives the model more opportunities to seem to fit well by capitalizing on chance.\nShrinks with \\(n\\): more data at any noise level makes it harder to pretend the fit is better than it is in reality.\nGrows with \\(p\\): every extra parameter is another control which can adjust to fit the noise.\n\nHence model selection on the number of predictors becomes \\[\n\\hat{k}=\\arg\\min_{k\\in\\left\\{ 1,\\dots,p\\right\\} }\\frac{1}{n}\\sum\\left(y_{i}-\\left(\\hat{y}_{k}\\right)_{i}\\right)^{2}+\\frac{2\\sigma^{2}}{n}k\n\\] which gives Mallow’s \\(C_{p}\\) criterion for choice among linear models.\nCross-Validation\nAn alternative approach to estimating the expected test error \\(Err\\) associated with an ML technique \\(\\hat{m}\\) is cross validation.\nLet the fitted value under a given ML technique class be \\(\\hat{y}_{\\eta}\\) for model tuning parameter \\(\\eta\\in\\Theta\\)\nGenerally \\(\\eta\\) is ordered such that larger or smaller values are associated with a higher degree of regularization in the method. We wish to select the value \\(\\eta^{\\ast}\\) that minimizes \\(Err\\).\nCross validation is a resampling technique that allows us to statistically approximate \\(Err\\)\nSplit the training set randomly into \\(K\\) divisions or folds for some number \\(K\\). Express the folds as \\(F_{1},\\dots,F_{K}\\) where \\[F_{1}\\cup \\dots \\cup F_{K}= \\{ 1,\\dots,n\\} \\] with \\(n_{k}=\\left|F_{k}\\right|\\) points in fold \\(k\\).\nFor each \\(k=1,\\dots,K\\), we fit our model to all points besides the \\(k^{th}\\) fold, and let the \\(i^{th}\\) fitted values be denotes \\(\\hat{m}_{\\eta}^{-k}\\left(x_{i}\\right)\\).\nWe then evaluate the error on the points in the \\(k^{th}\\) fold \\[\nCV_{k}\\left(\\eta\\right)=\\frac{1}{n_{k}}\\sum_{i\\in F_{k}}\\left(y_{i}-\\hat{m}_{\\eta}^{-k}\\left(x_{i}\\right)\\right)^{2}\n\\]\nWe then average over the folds to estimate prediction error \\[\nCV\\left(\\eta\\right)=\\frac{1}{K}CV_{k}\\left(\\eta\\right)\n\\]\nThe process can be depicted as\n\n\n\nThis is \\(K\\)-fold cross validation, and the tuning procedure becomes \\[\n\\hat{\\eta}=\\arg\\min_{\\eta\\in\\left\\{ \\eta_{1},\\dots,\\eta_{m}\\right\\} }CV\\left(\\eta\\right)\n\\]\nThis leaves open the choice of \\(K\\).\nFor \\(K=2\\) we have split sample cross-validation. The problem is that the CV error estimate will be biased upwards.\nFor \\(K=n\\) we have leave-one-out cross validation. The problem is that the CV error estimate will have high variance.\nA standard to balance this bias-variance tradeoff is setting \\(K=5\\) or \\(K=10\\), where each iteration we train on a fraction of about \\(\\frac{K-1}{K}\\) of the total training set so we reduce bias, and there is less overlap among training set, thus reducing bias.\nRecognizing there is some variance in the CV error estimate, the one standard error rule is an alternative to choice of \\(\\eta\\). Let \\[\nSD\\left(\\eta\\right)=\\sqrt{var\\left(CV_{1}\\left(\\eta\\right),\\dots,CV_{K}\\left(\\eta\\right)\\right)}\n\\] and \\[\nSE\\left(\\eta\\right)=\\frac{SD\\left(\\eta\\right)}{\\sqrt{K}}\n\\] is standard error estimate of \\(CV\\left(\\eta\\right).\\)\nThe one standard error rule is to move \\(\\eta\\) in the direction of increasing regularization until it ceases to be true that \\[\nCV\\left(\\eta\\right)\\leq CV\\left(\\hat{\\eta}\\right)+SE\\left(\\hat{\\eta}\\right)\n\\] e.g., we take the most simplest model whose error is within one standard error of the minimal error.\nSee the interesting discussion on the proper application of CV at the top of page 245.\nLet us now revisit the Ames, Iowa data to see if multidimensional tuning would play a role.\n\n\nlibrary(rsample)     # data splitting \nlibrary(dplyr)       # data wrangling\nlibrary(rpart)       # performing regression trees\nlibrary(rpart.plot)  # plotting regression trees\n\n\n\nCreate training and test samples.\n\n\n# Create training (70%) and test (30%) sets for the AmesHousing::make_ames() data.\n# Use set.seed for reproducibility\n\nset.seed(123)\names_split <- initial_split(AmesHousing::make_ames(), prop = .7)\names_train <- training(ames_split)\names_test  <- testing(ames_split)\n\n\n\nSetup a grid for the tuning parameters\n\n\nhyper_grid <- expand.grid(\n  minsplit = seq(5, 20, 1),\n  maxdepth = seq(8, 15, 1)\n)\n\nhead(hyper_grid)\n\n\n  minsplit maxdepth\n1        5        8\n2        6        8\n3        7        8\n4        8        8\n5        9        8\n6       10        8\n\nUse CART for each tuning parameter value in the grid.\n\n\nmodels <- list()\n\nfor (i in 1:nrow(hyper_grid)) {\n  \n  # get minsplit, maxdepth values at row i\n  minsplit <- hyper_grid$minsplit[i]\n  maxdepth <- hyper_grid$maxdepth[i]\n\n  # train a model and store in the list\n  models[[i]] <- rpart(\n    formula = Sale_Price ~ .,\n    data    = ames_train,\n    method  = \"anova\",\n    control = list(minsplit = minsplit, maxdepth = maxdepth)\n    )\n}\n\n\n\n\n\n# function to get optimal cp\nget_cp <- function(x) {\n  min    <- which.min(x$cptable[, \"xerror\"])\n  cp <- x$cptable[min, \"CP\"] \n}\n\n# function to get minimum error\nget_min_error <- function(x) {\n  min    <- which.min(x$cptable[, \"xerror\"])\n  xerror <- x$cptable[min, \"xerror\"] \n}\n\nhyper_grid %>%\n  mutate(\n    cp    = purrr::map_dbl(models, get_cp),\n    error = purrr::map_dbl(models, get_min_error)\n    ) %>%\n  arrange(error) %>%\n  top_n(-5, wt = error)\n\n\n  minsplit maxdepth         cp     error\n1       19       12 0.01060346 0.2628987\n2        5        8 0.01000000 0.2635207\n3        9       11 0.01000000 0.2645615\n4       14       11 0.01000000 0.2650862\n5       13       10 0.01000000 0.2655860\n\nExtract the tree for the optimal value of the tuning parameters.\n\n\noptimal_tree <- rpart(\n    formula = Sale_Price ~ .,\n    data    = ames_train,\n    method  = \"anova\",\n    control = list(minsplit = 17, maxdepth = 12, cp = 0.01)\n    )\n\n\n\nThe new test error\n\n\npred <- predict(optimal_tree, newdata = ames_test)\np_error <- Metrics::rmse(actual = ames_test$Sale_Price, predicted = pred)\np_error\n\n\n[1] 39852.01\n\n\n\n\n",
    "preview": "https://i0.wp.com/blog.rankone.io/wp-content/uploads/2018/11/accuracy1.png?fit=1801%2C901&ssl=1",
    "last_modified": "2021-02-04T06:48:04+00:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "A First Look at Algorithmic Modeling : Regression Trees",
    "description": "An example of a regression tree in action",
    "author": [
      {
        "name": "Amit Gandhi",
        "url": {}
      }
    ],
    "date": "2021-01-28",
    "categories": [],
    "contents": "\n\nContents\n\n\nAlgorithmic models begin with an ``expressive space’’ for representing the non-parametric primitive of interest (see previous post for the 3 main classes of non-parametric primitives). In the case of supervised learning, we seek a space to represent the conditional mean of \\(Y\\) given \\(X\\), which is the theoretically optimal predictor of \\(Y\\) from \\(X\\) under squared error loss\nThe algorithms themselves are concerned with finding a particular representation in the expressive space to fit the data at hand. The behavior of the algorithm for conducting this search is governed by a set of tuning parameters \\(\\eta\\). The process of finding the optimal tuning parameters is called (rather simply) tuning,\nDecision Trees\nThe general idea of prediction/decision trees is that we will partition the predictor space into a number of simple, rectangular regions.\nIn order to make a prediction for a given observation, we typically use the mean of the training data in the region to which it belongs.\nRectangles can be achieved by making successive binary splits on the predictors variables \\(X_1,\\ldots X_p\\). i.e., we choose a variable \\(X_j\\), \\(j=1,\\ldots p\\), and  divide  up the feature space according to \\[X_j \\leq c \\;\\;\\;\\text{and}\\;\\;\\; X_j > c\\] Then we proceed on each half\nThe splitting rules can be summarized visually as a tree, these approaches are called decision tree methods.\n\nConstructing a partitioned space from a decision tree\n\n\n\n\nThese methods are both simple and useful for interpretation.\nNote however that not every partition of the predictor space can be represented as a tree\n\n\n\nHow to use trees?\nFor an observation falling in region \\(R_{j}\\), we predict a value for the the outcome \\(Y\\) as \\(c_{j}\\)\nThe estimated regression function has the form \\[\\hat{f}^\\mathrm{tree}(x) \\;=\\; \\sum_{j=1}^m c_j \\cdot 1\\{x \\in R_j\\}\n\\;=\\; c_j \\;\\, \\mathrm{such}\\;\\mathrm{that}\\;\\, x \\in R_j\\]\nIn the case of a regression problem, the \\(c_j\\) are real numbers. How would we choose these? Simple: just take the average response of all of the points in the region. Note that each region \\(R_j\\) contains some subset of the training data \\((x_i,y_i)\\), \\(i=1,\\ldots n\\), say, \\(n_j\\) points. Thus \\[c_j = \\frac{1}{n_j} \\sum_{x_i \\in R_j} y_i\\]\nIn the case of a classification problem, the prediction is a class \\(c_{j} \\in \\{1,\\dots,K\\}\\) The predicted class \\(c_j\\) is just most common occuring class among these points.\nIn particular, for each class \\(k=1,\\ldots K\\), we can estimate the probability that the class label is \\(k\\) given that the feature vector lies in region \\(R_j\\), \\(\\mathrm{P}(C=k|X\\in R_j)\\), by \\[\\hat{p}_k (R_j) = \\frac{1}{n_j}\\sum_{x_i \\in R_j} 1\\{y_i = k\\}\\] the  proportion of points  in the region that are of class \\(k\\).\nWe can now express the predicted class as \\[c_j = \\mathop{\\mathrm{argmax}}_{k=1,\\ldots K} \\; \\hat{p}_k (R_j)\\]\nPrediction of baseball player’s salary\nSuppose we wish predict a baseball player’s Salary based on Years (the number of years that he has played in the major leagues) and Hits (the number of hits that he made in the previous year).\nSalary is measured in thousands of dollars.\n Prediction of baseball player’s salary \nFigure 1\n\n\n\nThe regression tree depicts the prediction of the log salary of a baseball player, based on the number of years that he has played in the major leagues and the number of hits that he made in the previous year. At a given internal node, the label (of the form \\(X_j < t_k\\)) indicates the left-hand branch resulting from that split, and the right-hand branch corresponds to \\(X_j \\geq t_k.\\)\nThe tree represents a series of splits starting at the top of the tree.\nThe top split assigns observations having \\(Years < 4.5\\) to the left branch.\nThe predicted salary for these players is given by the mean response value for the players in the data set with \\(Years < 4.5.\\)\nFor such players, the mean log salary is 5.107, and so we make a prediction of \\(e^{5.107}\\) thousands of dollars, i.e. \\(165,174\\)\nAnother way to see the result of the tree is through the rectangular partition of the predictor space.\nFigure 2\n\n\n\nWe can write these regions as the following:\n\\(R_1 ={X \\mid Years < 4.5}\\)\n\\(R_2 ={X \\mid Years \\geq 4.5, Hits < 117.5}\\)\n\\(R_3 = {X \\mid Years \\geq 4.5, Hits \\geq 117.5}.\\)\n\nNotice the powerful appeal of interpretability of the resulting tree - even without a deep domain understanding of baseball, there is an intuitive sense that emerges for how baseball salaries work.\nTerminology\nIn keeping with the tree analogy, the regions \\(R_1\\), \\(R_2\\), …, \\(R_{J}\\) are known as terminal nodes or leaves of the tree.\nThe points along the tree where the predictor space is split are referred to as internal nodes.\nIn Figure 1, the two internal nodes are indicated by the text \\(Years<4.5\\) and \\(Hits<117.5.\\)\nWe refer to the segments of the trees that connect the nodes as branches\nHow to build trees?\nThere are two main issues to consider in building a tree:\nHow to choose the splits?\nHow big to grow the tree?\n\nThink first about varying the depth of the tree …\nWhich is more complex - a big tree or a small tree?\nWhat  tradeoff  is at play here?\nHow might we eventually consider choosing the depth?\n\nNow for a fixed depth, consider choosing the splits. -If the tree has depth \\(d\\), then it has \\(\\approx 2^d\\) nodes.\nAt each node we could choose any of \\(p\\) the variables for the split\nThis means that the number of possibilities is \\[p \\cdot 2^d\\]\nThis is  huge  even for moderate \\(d\\)! And we haven’t even counted the actual split points themselves\n\nThe CART Algorithm\nThe  CART algorithm 1 chooses the splits in a top down fashion: then chooses the first variable to at the root, then the variables at the second level, etc.\nAt each node \\(t\\) encountered along the algorithm (starting with the root node), we have a measure of node impurity \\(Q_{t} = Q(D_{t})\\), which is a function of the data set \\(D_{t}\\) arriving at node \\(t\\). Let \\(c_{t}\\) be the predicted value for node \\(t\\).\nFor regression trees, a common impurity measure is the variance \\[\\frac{1}{N_{t}} \\sum_{i=1}^{N_{t}} (y_{i,t} - \\bar{y}_t)^{2}\\]\nFor classification trees, a common impurity measure is the mis-classification rate \\[1 - \\hat{p}_{c_{t}}\\] where \\(c_{t}\\) is the predicted class for node \\(t\\).\nAlternatives to misclassification error for classification trees are the Gini index or cross-entropy.\n\nAt node \\(t\\) we must determine the optimal split \\((j,s)\\) where \\(j\\) indexes the predictor variable \\(X_{j}\\) we split and \\(s\\) the split point. Let \\(D_{left}\\) and \\(D_{right}\\) be the induced data sets going to the left and right nodes from the split \\((j,s)\\), with number of observations \\(N_{left}\\) and \\(N_{right}\\) respectively.\nAt each step of the CART algorithm we seek to maximize the information gain \\(IG\\) of the split as measured by \\[IG(D,j, s) = Q(D) - \\frac{N_{left}}{N} Q(D_{left}) - \\frac{N_{right}}{N} Q(D_{right})\\] where \\(D\\) is the dataset of the parent node.\nThe CART algorithm greedily chooses the split to minimize \\[N_{left} Q(D_{left}) + N_{right} Q(D_{right})\\]\nHaving done this, we now recursively repeat the process for each new node arising from the split, treating \\(D_{left}\\) and \\(D_{right}\\) as parent data sets.\nHow do we find the best split \\(s\\)? Aren’t there  infinitely many  to consider? No, to split at node \\(t\\) on a variable \\(j\\), we really only need to consider \\(N_t\\) splits (or \\(N_t-1\\) splits)\n\n\n\n\nWhen does the process stop? stopping We stop only when each terminal node has fewer than some minimum number of observations (e.g., 10 observations).\nPruning the tree\nContinuing on in this manner, we will get a big tree \\(T_0\\). Let the size \\(\\tilde{T}_{0} = |T_{0}|\\) be denoted by the number of leaf nodes.\nA natural concern with CART is overfitting - we have grown the tree to large.\nWe then  prune  this tree, meaning that we collapse some of its leaves into the parent nodes.\nNotice that the total information gain from building the tree is \\[Q(D) - \\sum_{t}^{T} \\frac{N_{t}}{N}Q(D_t)\\] where \\(D\\) is the data entering the root node (e.g., the full training sample)\nWe seek to find the subtree \\(T \\subset T_{0}\\) to minimize the cost complexity criterion \\[C_{\\alpha}(T) = \\sum_{t=1}^{|T|} N_{t}Q_t + \\alpha |T|\\]\nWhat is the logic of this approach? That is, why grow a large tree and prune, instead of just stopping at some point when the information gain ? Because any stopping rule may be  short-sighted , in that a split may look bad but it may lead to a good split below it.\n\n\n\n\nFor any given \\(\\alpha\\), the optimal pruned tree \\(T(\\alpha)\\) can be found via a convenient algorithm - weakest link pruning.\nWhen \\(\\alpha = 0,\\) then the subtree T will simply equal \\(T_0\\), because then the penalized objective just measures the training error.\nHowever, as \\(\\alpha = 0\\) increases, there is a price to pay for having a tree with many terminal nodes, and so the penalized objective will be minimized for a smaller sub-tree.\nWe start from the full tree \\(T_{0}\\)\nFor any internal node \\(t\\),we let \\(T{t}\\) be the branch of \\(T\\) with root \\(t\\) (e.g., the pruned part if we snip the tree at node \\(t\\))\nThe cost complexity criterion would become smaller by pruning at \\(t\\) if the following held\n\\[ N_{t} Q(D_{t}) + \\alpha  < \\sum _{t^\\prime = 1}^{|T_{t}|} N_{t^\\prime}Q(D_{t^\\prime}) + \\alpha|T_{t}| \\]\nIt pays to prune at \\(t\\) if \\[\\alpha > \\frac{N_{t} Q(D_{t}) - \\sum _{t^\\prime = 1}^{|T_{t}|} N_{t^\\prime}Q(D_{t^\\prime})}{|T_{t}| - 1} = g_{0}(t)\\]\nObserve that \\(\\alpha\\) is always positive because the numerator of the RHS is a re-scaled version of the information gain from splitting at \\(t\\). this can be done by pruning the weakest leaf one at a time.\nDefine the weakest link in \\(T_{0}\\) as the internal node \\(t_{0}\\) such that \\(g_{0}(t_{0}) = \\min g_{0}(t)\\), and let \\(\\alpha_{1} = g_{0}(t_{0})\\)\nPrune the tree \\(T_{0} - T_{1}\\) and repeat the weakest link process.\nThis gives us a decreasing sequence of trees \\[T_{0} \\prec T_{1} \\dots \\prec t_{root}\\] all the way down to the root node \\(t_{root}\\), as well as an increasing sequence of \\(\\alpha\\) values \\[0 < \\alpha_{1} < \\alpha_{2} < \\dots < \\alpha_{K}\\]\nA key result in Breiman et al (1984) is that for \\(\\alpha\\) such that \\(\\alpha_{k} < \\alpha < \\alpha_{k+1}\\), the optimum tree \\(T(\\alpha)\\) is \\(T_{k}\\).\n\\(\\alpha\\) is a  tuning parameter , and a larger \\(\\alpha\\) yields a smaller tree.\nThus as \\(\\alpha = 0\\) increases from 0, branches are pruned from the tree in a nested and predictable way (resulting in the whole sequence of subtrees as a function of \\(\\alpha\\)).\nCART picks from the finite menu of potential \\(\\alpha_{k}\\) by 5- or 10-fold cross-validation\nAlgorithm for Building a Regression Tree\nUse recursive binary splitting to grow a large tree on the training data, stopping only when each terminal node has fewer than some minimum number of observations.\nApply cost complexity pruning to the large tree in order to obtain a sequence of best subtrees, as a function of \\(\\alpha.\\)\nUse \\(K\\)-fold cross-validation to choose \\(\\alpha.\\) That is, divide the training observations into \\(K\\) folds. For each \\(k = 1, \\ldots, K\\):\nRepeat Steps 1 and 2 on all but the kth fold of the training data.\nEvaluate the mean squared prediction error on the data in the left-out kth fold, as a function of \\(\\alpha.\\)\nAverage the results for each value of \\(\\alpha\\), and pick \\(\\alpha\\) to minimize the average error.\n\nReturn the subtree from Step 2 that corresponds to the chosen value of \\(\\alpha.\\)\nSome considerations\nSplitting a categorical variable predictor variable with many levels can be onerous, e.g., a categorical variable with \\(q\\) levels has \\(2^{q-1} - 1\\) potential splits, and thus need to carefully consider category definitions in using such predictors.\nAn Empirical Example: Spam Data\n-In an empirical analysis, we will split our data \\(D\\) into a test \\(D_{test}\\) and training \\(D_{train}\\) set.\nWe will run the CART algorithm (grow and prune a tree) on \\(D_{train}\\) to extract a prediction tree, and perform predictions on the \\(D_{test}\\)\nCross validation is usually done with 5 or 10 folds, and the “one standard error” rule is applied (the simplest model with performance at the min of the CV performance + one standard error)\nExample from ESL: \\(n=4601\\) emails, of which 1813 are considered spam. For each email we have \\(p=58\\) attributes. The first 54 measure the frequencies of 54 key words or characters (e.g., “free”, “need”, “$”). The last 3 measure\nthe average length of uninterrupted sequences of capitals;\nthe length of the longest uninterrupted sequence of capitals;\nthe sum of lengths of uninterrupted sequences of capitals\n\nCross-validation error curve for the spam data (from ESL page 314):\n\n\n\nThe blue curve is the 10-fold cross validation estimate of the mis-classification rate with SE bars. The orange curve is the test error, which tracks the CV error closely.\nThe min occurs at a tree of size 17 (with one SE rule applied)\n\n\n\nRunning CART in R\nThe package rpart provides a fast implementation and interface for the CART algorithm and decision trees in R. We consider an example here with the Ames, Iowa Housing Data (sometimes called the new iris data). For a description, see here\nWe can first load the data\n\n\nlibrary(rsample)     # data splitting \nlibrary(dplyr)       # data wrangling\nlibrary(rpart)       # performing regression trees\nlibrary(rpart.plot)  # plotting regression trees\nlibrary(skimr)\n\n\n\nLets skim the data.\n\nTable 1: Data summary\nName\nAmesHousing::make_ames()\nNumber of rows\n2930\nNumber of columns\n81\n_______________________\n\nColumn type frequency:\n\nfactor\n46\nnumeric\n35\n________________________\n\nGroup variables\nNone\nVariable type: factor\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\nMS_SubClass\n0\n1\nFALSE\n16\nOne: 1079, Two: 575, One: 287, One: 192\nMS_Zoning\n0\n1\nFALSE\n7\nRes: 2273, Res: 462, Flo: 139, Res: 27\nStreet\n0\n1\nFALSE\n2\nPav: 2918, Grv: 12\nAlley\n0\n1\nFALSE\n3\nNo_: 2732, Gra: 120, Pav: 78\nLot_Shape\n0\n1\nFALSE\n4\nReg: 1859, Sli: 979, Mod: 76, Irr: 16\nLand_Contour\n0\n1\nFALSE\n4\nLvl: 2633, HLS: 120, Bnk: 117, Low: 60\nUtilities\n0\n1\nFALSE\n3\nAll: 2927, NoS: 2, NoS: 1\nLot_Config\n0\n1\nFALSE\n5\nIns: 2140, Cor: 511, Cul: 180, FR2: 85\nLand_Slope\n0\n1\nFALSE\n3\nGtl: 2789, Mod: 125, Sev: 16\nNeighborhood\n0\n1\nFALSE\n28\nNor: 443, Col: 267, Old: 239, Edw: 194\nCondition_1\n0\n1\nFALSE\n9\nNor: 2522, Fee: 164, Art: 92, RRA: 50\nCondition_2\n0\n1\nFALSE\n8\nNor: 2900, Fee: 13, Art: 5, Pos: 4\nBldg_Type\n0\n1\nFALSE\n5\nOne: 2425, Twn: 233, Dup: 109, Twn: 101\nHouse_Style\n0\n1\nFALSE\n8\nOne: 1481, Two: 873, One: 314, SLv: 128\nOverall_Qual\n0\n1\nFALSE\n10\nAve: 825, Abo: 732, Goo: 602, Ver: 350\nOverall_Cond\n0\n1\nFALSE\n9\nAve: 1654, Abo: 533, Goo: 390, Ver: 144\nRoof_Style\n0\n1\nFALSE\n6\nGab: 2321, Hip: 551, Gam: 22, Fla: 20\nRoof_Matl\n0\n1\nFALSE\n8\nCom: 2887, Tar: 23, WdS: 9, WdS: 7\nExterior_1st\n0\n1\nFALSE\n16\nVin: 1026, Met: 450, HdB: 442, Wd : 420\nExterior_2nd\n0\n1\nFALSE\n17\nVin: 1015, Met: 447, HdB: 406, Wd : 397\nMas_Vnr_Type\n0\n1\nFALSE\n5\nNon: 1775, Brk: 880, Sto: 249, Brk: 25\nExter_Qual\n0\n1\nFALSE\n4\nTyp: 1799, Goo: 989, Exc: 107, Fai: 35\nExter_Cond\n0\n1\nFALSE\n5\nTyp: 2549, Goo: 299, Fai: 67, Exc: 12\nFoundation\n0\n1\nFALSE\n6\nPCo: 1310, CBl: 1244, Brk: 311, Sla: 49\nBsmt_Qual\n0\n1\nFALSE\n6\nTyp: 1283, Goo: 1219, Exc: 258, Fai: 88\nBsmt_Cond\n0\n1\nFALSE\n6\nTyp: 2616, Goo: 122, Fai: 104, No_: 80\nBsmt_Exposure\n0\n1\nFALSE\n5\nNo: 1906, Av: 418, Gd: 284, Mn: 239\nBsmtFin_Type_1\n0\n1\nFALSE\n7\nGLQ: 859, Unf: 851, ALQ: 429, Rec: 288\nBsmtFin_Type_2\n0\n1\nFALSE\n7\nUnf: 2499, Rec: 106, LwQ: 89, No_: 81\nHeating\n0\n1\nFALSE\n6\nGas: 2885, Gas: 27, Gra: 9, Wal: 6\nHeating_QC\n0\n1\nFALSE\n5\nExc: 1495, Typ: 864, Goo: 476, Fai: 92\nCentral_Air\n0\n1\nFALSE\n2\nY: 2734, N: 196\nElectrical\n0\n1\nFALSE\n6\nSBr: 2682, Fus: 188, Fus: 50, Fus: 8\nKitchen_Qual\n0\n1\nFALSE\n5\nTyp: 1494, Goo: 1160, Exc: 205, Fai: 70\nFunctional\n0\n1\nFALSE\n8\nTyp: 2728, Min: 70, Min: 65, Mod: 35\nFireplace_Qu\n0\n1\nFALSE\n6\nNo_: 1422, Goo: 744, Typ: 600, Fai: 75\nGarage_Type\n0\n1\nFALSE\n7\nAtt: 1731, Det: 782, Bui: 186, No_: 157\nGarage_Finish\n0\n1\nFALSE\n4\nUnf: 1231, RFn: 812, Fin: 728, No_: 159\nGarage_Qual\n0\n1\nFALSE\n6\nTyp: 2615, No_: 159, Fai: 124, Goo: 24\nGarage_Cond\n0\n1\nFALSE\n6\nTyp: 2665, No_: 159, Fai: 74, Goo: 15\nPaved_Drive\n0\n1\nFALSE\n3\nPav: 2652, Dir: 216, Par: 62\nPool_QC\n0\n1\nFALSE\n5\nNo_: 2917, Exc: 4, Goo: 4, Typ: 3\nFence\n0\n1\nFALSE\n5\nNo_: 2358, Min: 330, Goo: 118, Goo: 112\nMisc_Feature\n0\n1\nFALSE\n6\nNon: 2824, She: 95, Gar: 5, Oth: 4\nSale_Type\n0\n1\nFALSE\n10\nWD : 2536, New: 239, COD: 87, Con: 26\nSale_Condition\n0\n1\nFALSE\n6\nNor: 2413, Par: 245, Abn: 190, Fam: 46\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nLot_Frontage\n0\n1\n57.65\n33.50\n0.00\n43.00\n63.00\n78.00\n313.00\n▇▇▁▁▁\nLot_Area\n0\n1\n10147.92\n7880.02\n1300.00\n7440.25\n9436.50\n11555.25\n215245.00\n▇▁▁▁▁\nYear_Built\n0\n1\n1971.36\n30.25\n1872.00\n1954.00\n1973.00\n2001.00\n2010.00\n▁▂▃▆▇\nYear_Remod_Add\n0\n1\n1984.27\n20.86\n1950.00\n1965.00\n1993.00\n2004.00\n2010.00\n▅▂▂▃▇\nMas_Vnr_Area\n0\n1\n101.10\n178.63\n0.00\n0.00\n0.00\n162.75\n1600.00\n▇▁▁▁▁\nBsmtFin_SF_1\n0\n1\n4.18\n2.23\n0.00\n3.00\n3.00\n7.00\n7.00\n▃▂▇▁▇\nBsmtFin_SF_2\n0\n1\n49.71\n169.14\n0.00\n0.00\n0.00\n0.00\n1526.00\n▇▁▁▁▁\nBsmt_Unf_SF\n0\n1\n559.07\n439.54\n0.00\n219.00\n465.50\n801.75\n2336.00\n▇▅▂▁▁\nTotal_Bsmt_SF\n0\n1\n1051.26\n440.97\n0.00\n793.00\n990.00\n1301.50\n6110.00\n▇▃▁▁▁\nFirst_Flr_SF\n0\n1\n1159.56\n391.89\n334.00\n876.25\n1084.00\n1384.00\n5095.00\n▇▃▁▁▁\nSecond_Flr_SF\n0\n1\n335.46\n428.40\n0.00\n0.00\n0.00\n703.75\n2065.00\n▇▃▂▁▁\nLow_Qual_Fin_SF\n0\n1\n4.68\n46.31\n0.00\n0.00\n0.00\n0.00\n1064.00\n▇▁▁▁▁\nGr_Liv_Area\n0\n1\n1499.69\n505.51\n334.00\n1126.00\n1442.00\n1742.75\n5642.00\n▇▇▁▁▁\nBsmt_Full_Bath\n0\n1\n0.43\n0.52\n0.00\n0.00\n0.00\n1.00\n3.00\n▇▆▁▁▁\nBsmt_Half_Bath\n0\n1\n0.06\n0.25\n0.00\n0.00\n0.00\n0.00\n2.00\n▇▁▁▁▁\nFull_Bath\n0\n1\n1.57\n0.55\n0.00\n1.00\n2.00\n2.00\n4.00\n▁▇▇▁▁\nHalf_Bath\n0\n1\n0.38\n0.50\n0.00\n0.00\n0.00\n1.00\n2.00\n▇▁▅▁▁\nBedroom_AbvGr\n0\n1\n2.85\n0.83\n0.00\n2.00\n3.00\n3.00\n8.00\n▁▇▂▁▁\nKitchen_AbvGr\n0\n1\n1.04\n0.21\n0.00\n1.00\n1.00\n1.00\n3.00\n▁▇▁▁▁\nTotRms_AbvGrd\n0\n1\n6.44\n1.57\n2.00\n5.00\n6.00\n7.00\n15.00\n▁▇▂▁▁\nFireplaces\n0\n1\n0.60\n0.65\n0.00\n0.00\n1.00\n1.00\n4.00\n▇▇▁▁▁\nGarage_Cars\n0\n1\n1.77\n0.76\n0.00\n1.00\n2.00\n2.00\n5.00\n▅▇▂▁▁\nGarage_Area\n0\n1\n472.66\n215.19\n0.00\n320.00\n480.00\n576.00\n1488.00\n▃▇▃▁▁\nWood_Deck_SF\n0\n1\n93.75\n126.36\n0.00\n0.00\n0.00\n168.00\n1424.00\n▇▁▁▁▁\nOpen_Porch_SF\n0\n1\n47.53\n67.48\n0.00\n0.00\n27.00\n70.00\n742.00\n▇▁▁▁▁\nEnclosed_Porch\n0\n1\n23.01\n64.14\n0.00\n0.00\n0.00\n0.00\n1012.00\n▇▁▁▁▁\nThree_season_porch\n0\n1\n2.59\n25.14\n0.00\n0.00\n0.00\n0.00\n508.00\n▇▁▁▁▁\nScreen_Porch\n0\n1\n16.00\n56.09\n0.00\n0.00\n0.00\n0.00\n576.00\n▇▁▁▁▁\nPool_Area\n0\n1\n2.24\n35.60\n0.00\n0.00\n0.00\n0.00\n800.00\n▇▁▁▁▁\nMisc_Val\n0\n1\n50.64\n566.34\n0.00\n0.00\n0.00\n0.00\n17000.00\n▇▁▁▁▁\nMo_Sold\n0\n1\n6.22\n2.71\n1.00\n4.00\n6.00\n8.00\n12.00\n▅▆▇▃▃\nYear_Sold\n0\n1\n2007.79\n1.32\n2006.00\n2007.00\n2008.00\n2009.00\n2010.00\n▇▇▇▇▃\nSale_Price\n0\n1\n180796.06\n79886.69\n12789.00\n129500.00\n160000.00\n213500.00\n755000.00\n▇▇▁▁▁\nLongitude\n0\n1\n-93.64\n0.03\n-93.69\n-93.66\n-93.64\n-93.62\n-93.58\n▅▅▇▆▁\nLatitude\n0\n1\n42.03\n0.02\n41.99\n42.02\n42.03\n42.05\n42.06\n▂▂▇▇▇\n\nCreate training and test samples.\n\n\n# Create training (70%) and test (30%) sets for the AmesHousing::make_ames() data.\n# Use set.seed for reproducibility\n\nset.seed(123)\names_split <- initial_split(AmesHousing::make_ames(), prop = .7)\names_train <- training(ames_split)\names_test  <- testing(ames_split)\n\n\n\nConstruct a tree on the training sample\n\n\nm1 <- rpart(\n  formula = Sale_Price ~ .,\n  data    = ames_train,\n  method  = \"anova\"\n  )\n\nclass(m1)\n\n\n[1] \"rpart\"\n\nm1\n\n\nn= 2051 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 2051 1.273987e+13 180775.50  \n   2) Overall_Qual=Very_Poor,Poor,Fair,Below_Average,Average,Above_Average,Good 1703 4.032269e+12 156431.40  \n     4) Neighborhood=North_Ames,Old_Town,Edwards,Sawyer,Mitchell,Brookside,Iowa_DOT_and_Rail_Road,South_and_West_of_Iowa_State_University,Meadow_Village,Briardale,Northpark_Villa,Blueste 1015 1.360332e+12 131803.50  \n       8) First_Flr_SF< 1048.5 611 4.924281e+11 118301.50  \n        16) Overall_Qual=Very_Poor,Poor,Fair,Below_Average 152 1.053743e+11  91652.57 *\n        17) Overall_Qual=Average,Above_Average,Good 459 2.433622e+11 127126.40 *\n       9) First_Flr_SF>=1048.5 404 5.880574e+11 152223.50  \n        18) Gr_Liv_Area< 2007.5 359 2.957141e+11 145749.50 *\n        19) Gr_Liv_Area>=2007.5 45 1.572566e+11 203871.90 *\n     5) Neighborhood=College_Creek,Somerset,Northridge_Heights,Gilbert,Northwest_Ames,Sawyer_West,Crawford,Timberland,Northridge,Stone_Brook,Clear_Creek,Bloomington_Heights,Veenker,Green_Hills 688 1.148069e+12 192764.70  \n      10) Gr_Liv_Area< 1725.5 482 5.162415e+11 178531.00  \n        20) Total_Bsmt_SF< 1331 352 2.315412e+11 167759.00 *\n        21) Total_Bsmt_SF>=1331 130 1.332603e+11 207698.30 *\n      11) Gr_Liv_Area>=1725.5 206 3.056877e+11 226068.80 *\n   3) Overall_Qual=Very_Good,Excellent,Very_Excellent 348 2.759339e+12 299907.90  \n     6) Overall_Qual=Very_Good 249 9.159879e+11 268089.10  \n      12) Gr_Liv_Area< 1592.5 78 1.339905e+11 220448.90 *\n      13) Gr_Liv_Area>=1592.5 171 5.242201e+11 289819.70 *\n     7) Overall_Qual=Excellent,Very_Excellent 99 9.571896e+11 379937.20  \n      14) Gr_Liv_Area< 1947 42 7.265064e+10 325865.10 *\n      15) Gr_Liv_Area>=1947 57 6.712559e+11 419779.80  \n        30) Neighborhood=Old_Town,Edwards,Timberland 7 8.073100e+10 295300.00 *\n        31) Neighborhood=College_Creek,Somerset,Northridge_Heights,Northridge,Stone_Brook 50 4.668730e+11 437207.00  \n          62) Total_Bsmt_SF< 2168.5 40 1.923959e+11 408996.90 *\n          63) Total_Bsmt_SF>=2168.5 10 1.153154e+11 550047.30 *\n\nPlot the fitted tree\n\n\n\nVisualize the cross validation experiment\n\n\nplotcp(m1)\n\n\n\n\nWe can force a larger tree to be fit\n\n\nm2 <- rpart(\n    formula = Sale_Price ~ .,\n    data    = ames_train,\n    method  = \"anova\", \n    control = list(cp = 0, xval = 10)\n)\n\nplotcp(m2)\n\n\n\n\nThe data underlying cross validation can be extracted\n\n\nm1$cptable\n\n\n           CP nsplit rel error    xerror       xstd\n1  0.46690132      0 1.0000000 1.0009222 0.05855161\n2  0.11961409      1 0.5330987 0.5347929 0.03116217\n3  0.06955813      2 0.4134846 0.4151417 0.03058554\n4  0.02559992      3 0.3439265 0.3461258 0.02207839\n5  0.02196620      4 0.3183265 0.3242197 0.02182111\n6  0.02023390      5 0.2963603 0.3074877 0.02129292\n7  0.01674138      6 0.2761264 0.2963372 0.02106996\n8  0.01188709      7 0.2593850 0.2795199 0.01903482\n9  0.01127889      8 0.2474980 0.2762666 0.01936472\n10 0.01109955      9 0.2362191 0.2699895 0.01902217\n11 0.01060346     11 0.2140200 0.2672133 0.01883219\n12 0.01000000     12 0.2034165 0.2635207 0.01881691\n\nNow predict on the test set:\n\n\npred <- predict(m1, newdata = ames_test)\np_error <- Metrics::rmse(actual = ames_test$Sale_Price, predicted = pred)\np_error\n\n\n[1] 39852.01\n\ne.g.,the average distance between predicted values and actuals is 39,852 dollars.\n\nBreiman et al. (1984), ``Classification and Regression Trees’’↩︎\n",
    "preview": "https://static.packt-cdn.com/products/9781788830577/graphics/a480732e-a17a-4220-8b7d-e04d7430bce1.png",
    "last_modified": "2021-02-05T14:14:50+00:00",
    "input_file": {}
  }
]
