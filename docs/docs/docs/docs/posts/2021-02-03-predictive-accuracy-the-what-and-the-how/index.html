<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #20794d; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #20794d; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

  <!--radix_placeholder_meta_tags-->
<title>Econ 712: Predictive Accuracy: The What and the How</title>

<meta property="description" itemprop="description" content="measuring and managing the performance of an algorithmic model"/>


<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2021-02-03"/>
<meta property="article:created" itemprop="dateCreated" content="2021-02-03"/>
<meta name="article:author" content="Amit Gandhi"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Econ 712: Predictive Accuracy: The What and the How"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="measuring and managing the performance of an algorithmic model"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Econ 712"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary"/>
<meta property="twitter:title" content="Econ 712: Predictive Accuracy: The What and the How"/>
<meta property="twitter:description" content="measuring and managing the performance of an algorithmic model"/>

<!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output","preview"]}},"value":[{"type":"character","attributes":{},"value":["Predictive Accuracy: The What and the How"]},{"type":"character","attributes":{},"value":["measuring and managing the performance of an algorithmic model"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Amit Gandhi"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":[]}},"value":[]}]}]},{"type":"character","attributes":{},"value":["02-03-2021"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","css"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["styles.css"]}]}]},{"type":"character","attributes":{},"value":["https://i0.wp.com/blog.rankone.io/wp-content/uploads/2018/11/accuracy1.png?fit=1801%2C901&ssl=1"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["images/3D-PCA.png","images/approx-shapley-idea.png","images/Autoencoder_structure.png","images/autoencoder-symmetry.png","images/basic-neural-net.png","images/boosted-trees-process.png","images/bootstrap-scheme.png","images/bv.png","images/confusion-matrix.png","images/confusion-matrix2.png","images/cv.png","images/data_split.png","images/decision-tree-terminology.png","images/deep_neural-net.png","images/dendrogram.png","images/dendrogram2.png","images/dendrogram3.png","images/digits.png","images/exemplar-decision-tree.png","images/glrm-example.png","images/minimize-leakage.png","images/mlp_network.png","images/modeling_process.png","images/ohe-vs-dummy.png","images/pcr-steps.png","images/pdp-illustration.png","images/perceptron_node.png","images/pls-vs-pcr.png","images/quadratic-huber-loss.png","images/validatetest.png","predictive-accuracy-the-what-and-the-how_files/anchor-4.2.2/anchor.min.js","predictive-accuracy-the-what-and-the-how_files/bowser-1.9.3/bowser.min.js","predictive-accuracy-the-what-and-the-how_files/distill-2.2.21/template.v2.js","predictive-accuracy-the-what-and-the-how_files/header-attrs-2.5/header-attrs.js","predictive-accuracy-the-what-and-the-how_files/jquery-1.11.3/jquery.min.js","predictive-accuracy-the-what-and-the-how_files/webcomponents-2.0.0/webcomponents.js","styles.css"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

</style>

<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
            .filter(function(item) { return !!item.description; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description}
                </div>
                <div class="search-item-preview">
                  <img src="${suggestion.preview ? offsetURL(suggestion.preview) : ''}"</img>
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.5/header-attrs.js"></script>
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<!--/radix_placeholder_site_in_header-->

  <link rel="stylesheet" href="styles.css" type="text/css"/>

</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Predictive Accuracy: The What and the How","description":"measuring and managing the performance of an algorithmic model","authors":[{"author":"Amit Gandhi","authorURL":{},"affiliation":"&nbsp;","affiliationURL":"#","orcidID":""}],"publishedDate":"2021-02-03T00:00:00.000+00:00","citationText":"Gandhi, 2021"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/pennlogo.png"/>
</span>
<a href="../../index.html" class="title">Econ 712</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../about.html">About</a>
<a href="https://twitter.com/AmitEcon">
<i class="fa fa-twitter" aria-hidden="true"></i>
</a>
<a href="mailto:akgandhi@upenn.edu">
<i class="fa fa-envelope" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Predictive Accuracy: The What and the How</h1>
<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->
<p><p>measuring and managing the performance of an algorithmic model</p></p>
</div>

<div class="d-byline">
  Amit Gandhi true 
  
<br/>02-03-2021
</div>

<div class="d-article">
<h1 id="introduction">Introduction</h1>
<p>In the last post, we examined decision tree as an algorithmic model to understand the behavior of data. As we saw, the optimal tree is one where we grew a large tree, and pruned it to avoid an overfitting problem as measured by the <em>cost complexity criterion</em>. But what is the over-fitting problem with algorithmic models, and why did the cost complexity criterion allow us to manage it?</p>
<p>Trees are formed via an algorithm - <strong>CART</strong> - which is a predictive structure for predicting an outcome variable <span class="math inline">\(Y\)</span> from explanatory variables <span class="math inline">\(X\)</span>. The particular tree that was formed depended on two key inputs</p>
<ol type="1">
<li><p>The training sample <span class="math inline">\(D = \{(y_1, x_1),\dots, (y_n, x_n)\}\)</span></p></li>
<li><p>The tuning parameters (also called <em>hyperparameters</em>) <span class="math inline">\(\eta\)</span> which governs the behavior of the algorithm.</p></li>
</ol>
<p>The predictive structure is connected to the conditional distribution of the outcome variable <span class="math inline">\(Y\)</span> given the explanatory variables <span class="math inline">\(X\)</span>, e.g., a feature <span class="math inline">\(F_{Y\mid X}(y \mid X = x)\)</span>.</p>
<p>Given the training sample <span class="math inline">\(D\)</span> and hyperparameters, the CART algorithm generates a <em>fitted predictor</em> <span class="math inline">\(\hat{m}\)</span>. Although we do not have that much choice over the training sample <span class="math inline">\(D\)</span> (although as we will see below, we have some choice), we do have more discretion over the tuning parameters. Thus a very practical problem we face in algorithmic model is that we must se tthe value of <span class="math inline">\(\eta\)</span>, e.g., <span class="math inline">\(\hat{\eta}\)</span>. This process is called (rather simply) <strong>tuning</strong>. A more elaborate description would be <em>hyperparameter optimization</em></p>
<p>In this post we examine the more general principles around tuning with an eye towards its practical implementation in the case of the CART algorithm.</p>
<h1 id="the-tuning-problem">The tuning problem</h1>
<p>What are the tuning parameters in CART? Lets take a look a look at the help file?</p>
<div class="layout-chunk" data-layout="l-body">
<table width="100%" summary="page for rpart">
<tr>
<td>
rpart
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Recursive Partitioning and Regression Trees
</h2>
<h3>
Description
</h3>
<p>
Fit a <code>rpart</code> model
</p>
<h3>
Usage
</h3>
<pre>
rpart(formula, data, weights, subset, na.action = na.rpart, method,
      model = FALSE, x = FALSE, y = TRUE, parms, control, cost, ...)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>formula</code>
</td>
<td>
<p>
a formula, with a response but no interaction terms. If this a a data frame, that is taken as the model frame (see <code>model.frame).</code>
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>data</code>
</td>
<td>
<p>
an optional data frame in which to interpret the variables named in the formula.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>weights</code>
</td>
<td>
<p>
optional case weights.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>subset</code>
</td>
<td>
<p>
optional expression saying that only a subset of the rows of the data should be used in the fit.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>na.action</code>
</td>
<td>
<p>
the default action deletes all observations for which <code>y</code> is missing, but keeps those in which one or more predictors are missing.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>method</code>
</td>
<td>
<p>
one of <code>anova</code>, <code>poisson</code>, <code>class</code> or <code>exp</code>. If <code>method</code> is missing then the routine tries to make an intelligent guess. If <code>y</code> is a survival object, then <code>method = exp</code> is assumed, if <code>y</code> has 2 columns then <code>method = poisson</code> is assumed, if <code>y</code> is a factor then <code>method = class</code> is assumed, otherwise <code>method = anova</code> is assumed. It is wisest to specify the method directly, especially as more criteria may added to the function in future.
</p>
<p>
Alternatively, <code>method</code> can be a list of functions named <code>init</code>, <code>split</code> and <code>eval</code>. Examples are given in the file <span class="file">tests/usersplits.R</span> in the sources, and in the vignettes User Written Split Functions.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>model</code>
</td>
<td>
<p>
if logical: keep a copy of the model frame in the result? If the input value for <code>model</code> is a model frame (likely from an earlier call to the <code>rpart</code> function), then this frame is used rather than constructing new data.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>x</code>
</td>
<td>
<p>
keep a copy of the <code>x</code> matrix in the result.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>y</code>
</td>
<td>
<p>
keep a copy of the dependent variable in the result. If missing and <code>model</code> is supplied this defaults to <code>FALSE</code>.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>parms</code>
</td>
<td>
<p>
optional parameters for the splitting function.<br /> Anova splitting has no parameters.<br /> Poisson splitting has a single parameter, the coefficient of variation of the prior distribution on the rates. The default value is 1.<br /> Exponential splitting has the same parameter as Poisson.<br /> For classification splitting, the list can contain any of: the vector of prior probabilities (component <code>prior</code>), the loss matrix (component <code>loss</code>) or the splitting index (component <code>split</code>). The priors must be positive and sum to 1. The loss matrix must have zeros on the diagonal and positive off-diagonal elements. The splitting index can be <code>gini</code> or <code>information</code>. The default priors are proportional to the data counts, the losses default to 1, and the split defaults to <code>gini</code>.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>control</code>
</td>
<td>
<p>
a list of options that control details of the <code>rpart</code> algorithm. See <code>rpart.control</code>.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>cost</code>
</td>
<td>
<p>
a vector of non-negative costs, one for each variable in the model. Defaults to one for all variables. These are scalings to be applied when considering splits, so the improvement on splitting on a variable is divided by its cost in deciding which split to choose.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code></code>
</td>
<td>
<p>
arguments to <code>rpart.control</code> may also be specified in the call to <code>rpart</code>. They are checked against the list of valid arguments.
</p>
</td>
</tr>
</table>
<h3>
Details
</h3>
<p>
This differs from the <code>tree</code> function in S mainly in its handling of surrogate variables. In most details it follows Breiman <em>et. al</em> (1984) quite closely. <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> package <span class="pkg">tree</span> provides a re-implementation of <code>tree</code>.
</p>
<h3>
Value
</h3>
<p>
An object of class <code>rpart</code>. See <code>rpart.object</code>.
</p>
<h3>
References
</h3>
<p>
Breiman L., Friedman J. H., Olshen R. A., and Stone, C. J. (1984) <em>Classification and Regression Trees.</em> Wadsworth.
</p>
<h3>
See Also
</h3>
<p>
<code>rpart.control</code>, <code>rpart.object</code>, <code>summary.rpart</code>, <code>print.rpart</code>
</p>
<h3>
Examples
</h3>
<pre>
fit &lt;- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis)
fit2 &lt;- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis,
              parms = list(prior = c(.65,.35), split = "information"))
fit3 &lt;- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis,
              control = rpart.control(cp = 0.05))
par(mfrow = c(1,2), xpd = NA) # otherwise on some devices the text is clipped
plot(fit)
text(fit, use.n = TRUE)
plot(fit2)
text(fit2, use.n = TRUE)
</pre>
</div>
<p>The help file reveals several places where the algorithm can be tuned. Among them is a reference to an argument <code>control</code>, which is a list of options that control the detail of the algorithm. We can examine the parameters of the list:</p>
<div class="layout-chunk" data-layout="l-body">
<table width="100%" summary="page for rpart.control">
<tr>
<td>
rpart.control
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr>
</table>
<h2>
Control for Rpart Fits
</h2>
<h3>
Description
</h3>
<p>
Various parameters that control aspects of the <code>rpart</code> fit.
</p>
<h3>
Usage
</h3>
<pre>
rpart.control(minsplit = 20, minbucket = round(minsplit/3), cp = 0.01, 
              maxcompete = 4, maxsurrogate = 5, usesurrogate = 2, xval = 10,
              surrogatestyle = 0, maxdepth = 30, ...)
</pre>
<h3>
Arguments
</h3>
<table summary="R argblock">
<tr valign="top">
<td>
<code>minsplit</code>
</td>
<td>
<p>
the minimum number of observations that must exist in a node in order for a split to be attempted.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>minbucket</code>
</td>
<td>
<p>
the minimum number of observations in any terminal <code>&lt;leaf&gt;</code> node. If only one of <code>minbucket</code> or <code>minsplit</code> is specified, the code either sets <code>minsplit</code> to <code>minbucket*3</code> or <code>minbucket</code> to <code>minsplit/3</code>, as appropriate.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>cp</code>
</td>
<td>
<p>
complexity parameter. Any split that does not decrease the overall lack of fit by a factor of <code>cp</code> is not attempted. For instance, with <code>anova</code> splitting, this means that the overall R-squared must increase by <code>cp</code> at each step. The main role of this parameter is to save computing time by pruning off splits that are obviously not worthwhile. Essentially,the user informs the program that any split which does not improve the fit by <code>cp</code> will likely be pruned off by cross-validation, and that hence the program need not pursue it.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>maxcompete</code>
</td>
<td>
<p>
the number of competitor splits retained in the output. It is useful to know not just which split was chosen, but which variable came in second, third, etc.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>maxsurrogate</code>
</td>
<td>
<p>
the number of surrogate splits retained in the output. If this is set to zero the compute time will be reduced, since approximately half of the computational time (other than setup) is used in the search for surrogate splits.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>usesurrogate</code>
</td>
<td>
<p>
how to use surrogates in the splitting process. <code>0</code> means display only; an observation with a missing value for the primary split rule is not sent further down the tree. <code>1</code> means use surrogates, in order, to split subjects missing the primary variable; if all surrogates are missing the observation is not split. For value <code>2</code> ,if all surrogates are missing, then send the observation in the majority direction. A value of <code>0</code> corresponds to the action of <code>tree</code>, and <code>2</code> to the recommendations of Breiman <em>et.al</em> (1984).
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>xval</code>
</td>
<td>
<p>
number of cross-validations.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>surrogatestyle</code>
</td>
<td>
<p>
controls the selection of a best surrogate. If set to <code>0</code> (default) the program uses the total number of correct classification for a potential surrogate variable, if set to <code>1</code> it uses the percent correct, calculated over the non-missing values of the surrogate. The first option more severely penalizes covariates with a large number of missing values.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>maxdepth</code>
</td>
<td>
<p>
Set the maximum depth of any node of the final tree, with the root node counted as depth 0. Values greater than 30 <code>rpart</code> will give nonsense results on 32-bit machines.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code></code>
</td>
<td>
<p>
mop up other arguments.
</p>
</td>
</tr>
</table>
<h3>
Value
</h3>
<p>
A list containing the options.
</p>
<h3>
See Also
</h3>
<p>
<code>rpart</code>
</p>
</div>
<p>We can see a few tuning parameters that stand out - <code>minsplit</code>, <code>minbucket</code>, <code>cp</code>, and <code>xval</code>, which are initiatlized to specific values. The user has control of the algorithm by setting these values.</p>
<h1 id="prediction-error">Prediction Error</h1>
<p>The tuning parameters in general should be set to maximize the performance of the model. But what is performance?</p>
<p>Suppose we make a prediction <span class="math inline">\(\hat{Y}\)</span> and the realized outcome is <span class="math inline">\(Y\)</span>, where in general we should not expect perfect prediction and hence <span class="math inline">\(\hat{Y} \neq Y\)</span>. There is a loss <span class="math inline">\(L(Y,\hat{Y})\)</span> incurred from missing the target. Common loss functions are</p>
<p><span class="math display">\[
L(\hat{Y}, Y) = 
\begin{cases}
(Y-\hat{Y})^2 \mbox{ for regression}\\
\mathbf{1}(Y \neq \hat{Y}) \mbox{ for classification}
\end{cases}
\]</span></p>
<p>Given the loss function, what is the predictive performance of the predictor <span class="math inline">\(\hat{m}\)</span>.</p>
<p>If the goal is to use the predictor to predict in the population that has yet to be observed, then the natural performance criterion is the average loss in the population</p>
<p><span class="math display">\[
Err_{D} = E_{Y^{0}, X^{0}} \left[L(Y^{0}, \hat{m}(X^{0})) \mid D \right]
\]</span> where the expectation is taken with respect to the randomness in <span class="math inline">\((Y^{0}, X^{0}) \sim F_{Y,X}\)</span>. This is the <em>test error</em> or <em>generalization error</em>, e.g., the average error we would expect in an independent test sample. Notice that the training sample <span class="math inline">\(D\)</span> is conditioned out in the assesment of performance under <span class="math inline">\(Err_{D}\)</span></p>
<p>Although <span class="math inline">\(Err_{D}\)</span> is the ideal performance measure, it is challenging to analyze or forecast. However if we could measure it, then this provides a path to tuning. Notice that <span class="math inline">\(Err_{D} = Err_{D}(\eta)\)</span>, and hence optimal tuning would amount to</p>
<p><span class="math display">\[
\hat{\eta} = \arg \max_{\eta} Err_{D}(\eta)
\]</span> Thus <span class="math inline">\(Err_{D}(\eta)\)</span> would serve two distinct purposes (ESL p 222)</p>
<ol type="1">
<li><p><font color = "blue"> Model tuning </font>: estimating the performance of different algorithmic models indexed by <span class="math inline">\(\eta\)</span> in order to choose the best one.</p></li>
<li><p><font color = "blue"> Model assessment </font>: having chosen a final model, estimating its prediction error (generalization error) on new data.</p></li>
</ol>
<p>In an ideal circumstance to carry out these calculations we would have a sample of data broken into three parts.</p>
<ol type="1">
<li>Training Set</li>
<li>Validation Set</li>
<li>Test Set</li>
</ol>
<div class="layout-chunk" data-layout="l-body">
<p><img src="images/validatetest.png" width="858" /></p>
</div>
<p>The training set would be used to fit the data <span class="math inline">\(\hat{f}(\eta)\)</span>. The validation set could be used to tune the algorithms <span class="math inline">\(\eta\)</span> based on average loss in the validation set. And then the test set would provide a clean assesment of the test error of the tuned model at $.</p>
<p>We typically will not have enough data for this rather clean experiment without seriously compromising the size of the training sample (which detracts from the algorithms performance).</p>
<p>Instead we will need to live in a <em>second best</em> world and consider a slightly augmented measure of performance, the <em>average test error</em>, where we also account for randomness in the training sample itself</p>
<p><span class="math display">\[
Err(\eta) = E_D\left[Err_{D}\right(\eta)]
\]</span> If we imagine ordering <span class="math inline">\(\eta\)</span> such that lower values of <span class="math inline">\(eta\)</span> generate simpler fitted models, and higher values of <span class="math inline">\(\eta\)</span> generate more complex fitted models, then the behavior of <span class="math inline">\(Err(\eta)\)</span> creates the canonical picture of <em>Bias Variance Tradeoff</em> (ESL p.220)</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="images/bv.png" width="730" /></p>
</div>
<h2 id="optimism">Optimism</h2>
<ul>
<li><p>Let the training sample be $ D = {(y_i,x_i)}_{i=1}^{n}$</p></li>
<li><p>Consider a fitted model <span class="math inline">\(\hat{y}_{i}=\hat{m}\left(x_{i}\right)\)</span>, which can come from any algorithmic model <span class="math inline">\(m\)</span>, and implicitly depends on the tuning parameter <span class="math inline">\(\eta\)</span>.</p></li>
<li><p>For simplicity consider a regression problem with squared error loss (the analysis below generalizes to many loss functions)</p></li>
<li><p>The in-sample training error is <span class="math display">\[
\overline{err}=\frac{1}{n}\sum\left(y_{i}-\hat{y}_{i}\right)^{2}
\]</span></p></li>
<li><p>We have a general understanding that the <span class="math inline">\(\overline{err}\)</span> is an optimistic assessment of the object of interest, namely the test error <span class="math inline">\(Err_{D}\)</span>. Can we formalize the relationship to gauge just how optimistic?</p></li>
<li><p>One source of the discrepancy is that the test experiment is evaluated at potentially different points of the explanatory variables as compared to the training simple. To eliminate this additional variability, it is useful to consider the <em>in-sample</em> test error <span class="math display">\[
Err_{\mbox{in}} = \frac{1}{n} \sum E_{Y^{0}}\left[L(Y_{i}^{0}, \hat{m}(x_{i}) \mid D \right]
\]</span></p></li>
<li><p>Optimism can be defined as</p></li>
</ul>
<p><span class="math display">\[
\mbox{opp} \equiv Err_{\mbox{in}} - \overline{err}
\]</span></p>
<p>It turns out there is a natural characterization of the expected optimism, or <span class="math display">\[
\omega = E_{\mathbf{y}}[\mbox{opp}]
\]</span> Where the expectation is taken with respect to the training points <span class="math inline">\(\mathbf{y} = (y_i)_{i=1}^{n}\)</span></p>
<div class="theorem" data-text="CLT">
<p><span class="math inline">\(\omega = \frac{2}{n}\sum_{i}\mbox{Cov}(y_{i}, \hat{y}_i)\)</span></p>
</div>
<p><br></p>
<p>The interpretation, to quote ESL</p>
<blockquote>
<p>Thus the amount by which <span class="math inline">\(\overline{err}\)</span> underestimates the true error depends on how strongly <span class="math inline">\(y_{i}\)</span> affects its own prediction. The harder we fit the data, the greater <span class="math inline">\(Cov(\hat{y}_i, y_i)\)</span> will be, thereby increasing the optimism.</p>
</blockquote>
<ul>
<li><p>The proof of this result is remarkably straightforward.</p></li>
<li><p>For ease of notation, let the new test data generated from the same points for the explanatory variables as the training set be denoted simply as <span class="math inline">\(y_{i}^{\prime} = Y_{i}^{0}\)</span></p></li>
<li><p>The prediction error is then <span class="math display">\[
\frac{1}{n}\sum\left(y_{i}^{\prime}-\hat{y}_{i}\right)^{2}
\]</span></p></li>
<li><p>Observe that the <span class="math inline">\(\hat{y}_{i}&#39;s\)</span> are functions of all the <span class="math inline">\(y_{i}&#39;s\)</span> and so are dependent random variables.</p></li>
<li><p>However <span class="math inline">\(y_{i}^{\prime}\)</span> is independent of <span class="math inline">\(\hat{y}_{i}\)</span>.</p></li>
<li><p>Recall the formula</p></li>
</ul>
<p><span class="math display">\[V\left(Z\right)=E\left[Z^{2}\right]-E\left[Z\right]^{2}\implies E\left[Z^{2}\right]=V\left[Z\right]+E\left[Z\right]^{2}\]</span></p>
<ul>
<li><p>Then <span class="math display">\[\begin{align*}
E\left[\left(y_{i}-\hat{y}_{i}\right)^{2}\right] &amp; =V\left[y_{i}-\hat{y}_{i}\right]+E\left[y_{i}-\hat{y}_{i}\right]^{2}\\
 &amp; =V\left[y_{i}\right]+V\left[\hat{y}_{i}\right]-2Cov\left[y_{i},\hat{y}_{i}\right]+\left(E\left[y_{i}\right]-E\left[\hat{y}_{i}\right]\right)^{2}
\end{align*}\]</span></p></li>
<li><p>Observe on the other hand that using the fact <span class="math inline">\(E\left[y_{i}\right]=E\left[y_{i}^{\prime}\right]\)</span> and <span class="math inline">\(V\left[y_{i}^{\prime}\right]=V\left[y_{i}\right]\)</span></p></li>
</ul>
<p><span class="math display">\[\begin{align*}
E\left[\left(y_{i}^{\prime}-\hat{y}_{i}\right)^{2}\right] &amp; =V\left[y_{i}^{\prime}\right]+V\left[\hat{y}_{i}\right]-2Cov\left[y_{i}^{\prime},\hat{y}_{i}\right]+\left(E\left[y_{i}^{\prime}\right]-E\left[\hat{y}_{i}\right]\right)^{2}\\
 &amp; =V\left[y_{i}\right]+V\left[\hat{y}_{i}\right]+\left(E\left[y_{i}\right]-E\left[\hat{y}_{i}\right]\right)^{2}
\end{align*}\]</span></p>
<ul>
<li><p>Hence we have the relationship that <span class="math display">\[
E\left[\left(y_{i}^{\prime}-\hat{y}_{i}\right)^{2}\right]=E\left[\left(y_{i}-\hat{y}_{i}\right)^{2}\right]+2Cov\left[y_{i},\hat{y}_{i}\right].
\]</span></p></li>
<li><p>Averaging over data points <span class="math display">\[
E\left[\frac{1}{n}\sum_{i=1}^{n}\left(y_{i}^{\prime}-\hat{y}_{i}\right)^{2}\right]=E\left[\frac{1}{n}\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}\right]+\frac{2}{n}\sum_{i}Cov\left(y_{i},\hat{y}_{i}\right).
\]</span></p></li>
<li><p>We can frame the result in a slightly different way for the specialized case where the true DGP is</p></li>
</ul>
<p><span class="math display">\[
y_{i} = m(x_i)+\epsilon_i
\]</span> For a homoskedastic <span class="math inline">\(\epsilon_i\)</span> with variance <span class="math inline">\(\sigma^2\)</span>.</p>
<ul>
<li><p>Let us define the degrees of freedom <span class="math inline">\(df\left(\hat{y}\right)\)</span> of the fitted model <span class="math inline">\(\hat{y}\)</span> as <span class="math display">\[
df\left(\hat{y}\right)=\frac{1}{\sigma^{2}}\sum Cov\left(y_{i},\hat{y}_{i}\right),
\]</span></p></li>
<li><p>Then the relationship becomes <span class="math display">\[
E\left[\left(y_{i}^{\prime}-\hat{y}_{i}\right)^{2}\right]=E\left[\left(y_{i}-\hat{y}_{i}\right)^{2}\right]+\frac{2\sigma^{2}}{n}df\left(\hat{y}\right)
\]</span> which is words says that the expected test error is exactly the expected training error plus a constant factor <span class="math inline">\(\left(\frac{2\sigma^{2}}{n}\right)\)</span> times the degree of freedom.</p></li>
<li><p>This gives us an approach to model selection. Suppose we have a family of fitted values <span class="math inline">\(\hat{y}_{\eta}\)</span> which depends on a tuning parameter.</p></li>
<li><p>Then we can estimate <span class="math display">\[
Err_{\mbox{in}}(\eta) =\frac{1}{n}\sum_{i=1}^{n}\left(y_{i}-\left(\hat{y}_{\eta}\right)_{i}\right)^{2}+\frac{2\sigma^{2}}{n}df\left(\hat{y}_{\eta}\right)
\]</span> replacing <span class="math inline">\(\sigma^{2}\)</span> and <span class="math inline">\(df\)</span> with estimates if needed.</p>
<p>Then we can select <span class="math display">\[
\hat{\eta}=\arg\min_{\eta\in\Theta}\frac{1}{n}\left(y_{i}-\left(\hat{y}_{\eta}\right)_{i}\right)^{2}+\frac{2\sigma^{2}}{n}df\left(\hat{y}_{\eta}\right)
\]</span></p></li>
<li><p>Observe that for a linear regression model this becomes <span class="math display">\[\begin{align*}
df\left(\hat{y}^{linreg}\right) &amp; =\\
\frac{1}{\sigma^{2}}Tr\left(Cov\left(X\left(X^{\prime}X\right)^{-1}X^{\prime}Y\right),Y\right) &amp; =\\
\frac{1}{\sigma^{2}}Tr\left(X\left(X^{\prime}X\right)^{-1}X^{\prime}V\left[Y\right]\right) &amp; =\\
Tr\left(X\left(X^{\prime}X\right)^{-1}X^{\prime}\right) &amp; =\\
Tr\left(X^{\prime}X\left(X^{\prime}X\right)^{-1}\right) &amp; =p
\end{align*}\]</span></p></li>
<li><p>The optimism term <span class="math inline">\(\frac{2}{n}\sigma^{2}\left(p\right)\)</span> depends on 3 key factors</p>
<ol type="1">
<li><p>Grows with <span class="math inline">\(\sigma^{2}\)</span>: more noise gives the model more opportunities to seem to fit well by capitalizing on chance.</p></li>
<li><p>Shrinks with <span class="math inline">\(n\)</span>: more data at any noise level makes it harder to pretend the fit is better than it is in reality.</p></li>
<li><p>Grows with <span class="math inline">\(p\)</span>: every extra parameter is another control which can adjust to fit the noise.</p></li>
</ol></li>
<li><p>Hence model selection on the number of predictors becomes <span class="math display">\[
\hat{k}=\arg\min_{k\in\left\{ 1,\dots,p\right\} }\frac{1}{n}\sum\left(y_{i}-\left(\hat{y}_{k}\right)_{i}\right)^{2}+\frac{2\sigma^{2}}{n}k
\]</span> which gives Mallows <span class="math inline">\(C_{p}\)</span> criterion for choice among linear models.</p></li>
</ul>
<h2 id="cross-validation">Cross-Validation</h2>
<ul>
<li><p>An alternative approach to estimating the expected test error <span class="math inline">\(Err\)</span> associated with an ML technique <span class="math inline">\(\hat{m}\)</span> is cross validation.</p></li>
<li><p>Let the fitted value under a given ML technique class be <span class="math inline">\(\hat{y}_{\eta}\)</span> for model tuning parameter <span class="math inline">\(\eta\in\Theta\)</span></p></li>
<li><p>Generally <span class="math inline">\(\eta\)</span> is ordered such that larger or smaller values are associated with a higher degree of regularization in the method. We wish to select the value <span class="math inline">\(\eta^{\ast}\)</span> that minimizes <span class="math inline">\(Err\)</span>.</p></li>
<li><p>Cross validation is a resampling technique that allows us to statistically approximate <span class="math inline">\(Err\)</span></p></li>
<li><p>Split the training set randomly into <span class="math inline">\(K\)</span> divisions or <em>folds</em> for some number <span class="math inline">\(K\)</span>. Express the folds as <span class="math inline">\(F_{1},\dots,F_{K}\)</span> where <span class="math display">\[F_{1}\cup \dots \cup F_{K}= \{ 1,\dots,n\} \]</span> with <span class="math inline">\(n_{k}=\left|F_{k}\right|\)</span> points in fold <span class="math inline">\(k\)</span>.</p></li>
<li><p>For each <span class="math inline">\(k=1,\dots,K\)</span>, we fit our model to all points besides the <span class="math inline">\(k^{th}\)</span> fold, and let the <span class="math inline">\(i^{th}\)</span> fitted values be denotes <span class="math inline">\(\hat{m}_{\eta}^{-k}\left(x_{i}\right)\)</span>.</p></li>
<li><p>We then evaluate the error on the points in the <span class="math inline">\(k^{th}\)</span> fold <span class="math display">\[
CV_{k}\left(\eta\right)=\frac{1}{n_{k}}\sum_{i\in F_{k}}\left(y_{i}-\hat{m}_{\eta}^{-k}\left(x_{i}\right)\right)^{2}
\]</span></p></li>
<li><p>We then average over the folds to estimate prediction error <span class="math display">\[
CV\left(\eta\right)=\frac{1}{K}CV_{k}\left(\eta\right)
\]</span></p></li>
<li><p>The process can be depicted as</p></li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<p><img src="images/cv.png" width="716" /></p>
</div>
<ul>
<li><p>This is <span class="math inline">\(K\)</span>-fold cross validation, and the tuning procedure becomes <span class="math display">\[
\hat{\eta}=\arg\min_{\eta\in\left\{ \eta_{1},\dots,\eta_{m}\right\} }CV\left(\eta\right)
\]</span></p></li>
<li><p>This leaves open the choice of <span class="math inline">\(K\)</span>.</p></li>
<li><p>For <span class="math inline">\(K=2\)</span> we have split sample cross-validation. The problem is that the CV error estimate will be biased upwards.</p></li>
<li><p>For <span class="math inline">\(K=n\)</span> we have leave-one-out cross validation. The problem is that the CV error estimate will have high variance.</p></li>
<li><p>A standard to balance this bias-variance tradeoff is setting <span class="math inline">\(K=5\)</span> or <span class="math inline">\(K=10\)</span>, where each iteration we train on a fraction of about <span class="math inline">\(\frac{K-1}{K}\)</span> of the total training set so we reduce bias, and there is less overlap among training set, thus reducing bias.</p></li>
<li><p>Recognizing there is some variance in the CV error estimate, the one standard error rule is an alternative to choice of <span class="math inline">\(\eta\)</span>. Let <span class="math display">\[
SD\left(\eta\right)=\sqrt{var\left(CV_{1}\left(\eta\right),\dots,CV_{K}\left(\eta\right)\right)}
\]</span> and <span class="math display">\[
SE\left(\eta\right)=\frac{SD\left(\eta\right)}{\sqrt{K}}
\]</span> is standard error estimate of <span class="math inline">\(CV\left(\eta\right).\)</span></p></li>
<li><p>The one standard error rule is to move <span class="math inline">\(\eta\)</span> in the direction of increasing regularization until it ceases to be true that <span class="math display">\[
CV\left(\eta\right)\leq CV\left(\hat{\eta}\right)+SE\left(\hat{\eta}\right)
\]</span> e.g., we take the most simplest model whose error is within one standard error of the minimal error.</p></li>
<li><p>See the interesting discussion on the proper application of CV at the top of page 245.</p></li>
<li><p>Let us now revisit the Ames, Iowa data to see if multidimensional tuning would play a role.</p></li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://rsample.tidymodels.org'>rsample</a></span><span class='op'>)</span>     <span class='co'># data splitting </span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://dplyr.tidyverse.org'>dplyr</a></span><span class='op'>)</span>       <span class='co'># data wrangling</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/bethatkinson/rpart'>rpart</a></span><span class='op'>)</span>       <span class='co'># performing regression trees</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='http://www.milbo.org/rpart-plot/index.html'>rpart.plot</a></span><span class='op'>)</span>  <span class='co'># plotting regression trees</span>
</code></pre>
</div>
</div>
<p>Create training and test samples.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='co'># Create training (70%) and test (30%) sets for the AmesHousing::make_ames() data.</span>
<span class='co'># Use set.seed for reproducibility</span>

<span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>123</span><span class='op'>)</span>
<span class='va'>ames_split</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rsample.tidymodels.org/reference/initial_split.html'>initial_split</a></span><span class='op'>(</span><span class='fu'>AmesHousing</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/AmesHousing/man/make_ames.html'>make_ames</a></span><span class='op'>(</span><span class='op'>)</span>, prop <span class='op'>=</span> <span class='fl'>.7</span><span class='op'>)</span>
<span class='va'>ames_train</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rsample.tidymodels.org/reference/initial_split.html'>training</a></span><span class='op'>(</span><span class='va'>ames_split</span><span class='op'>)</span>
<span class='va'>ames_test</span>  <span class='op'>&lt;-</span> <span class='fu'><a href='https://rsample.tidymodels.org/reference/initial_split.html'>testing</a></span><span class='op'>(</span><span class='va'>ames_split</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Setup a grid for the tuning parameters</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>hyper_grid</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/expand.grid.html'>expand.grid</a></span><span class='op'>(</span>
  minsplit <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq</a></span><span class='op'>(</span><span class='fl'>5</span>, <span class='fl'>20</span>, <span class='fl'>1</span><span class='op'>)</span>,
  maxdepth <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq</a></span><span class='op'>(</span><span class='fl'>8</span>, <span class='fl'>15</span>, <span class='fl'>1</span><span class='op'>)</span>
<span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/utils/head.html'>head</a></span><span class='op'>(</span><span class='va'>hyper_grid</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>  minsplit maxdepth
1        5        8
2        6        8
3        7        8
4        8        8
5        9        8
6       10        8</code></pre>
</div>
<p>Use CART for each tuning parameter value in the grid.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>models</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='op'>)</span>

<span class='kw'>for</span> <span class='op'>(</span><span class='va'>i</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>hyper_grid</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span>
  
  <span class='co'># get minsplit, maxdepth values at row i</span>
  <span class='va'>minsplit</span> <span class='op'>&lt;-</span> <span class='va'>hyper_grid</span><span class='op'>$</span><span class='va'>minsplit</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span>
  <span class='va'>maxdepth</span> <span class='op'>&lt;-</span> <span class='va'>hyper_grid</span><span class='op'>$</span><span class='va'>maxdepth</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span>

  <span class='co'># train a model and store in the list</span>
  <span class='va'>models</span><span class='op'>[[</span><span class='va'>i</span><span class='op'>]</span><span class='op'>]</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/rpart/man/rpart.html'>rpart</a></span><span class='op'>(</span>
    formula <span class='op'>=</span> <span class='va'>Sale_Price</span> <span class='op'>~</span> <span class='va'>.</span>,
    data    <span class='op'>=</span> <span class='va'>ames_train</span>,
    method  <span class='op'>=</span> <span class='st'>"anova"</span>,
    control <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>minsplit <span class='op'>=</span> <span class='va'>minsplit</span>, maxdepth <span class='op'>=</span> <span class='va'>maxdepth</span><span class='op'>)</span>
    <span class='op'>)</span>
<span class='op'>}</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='co'># function to get optimal cp</span>
<span class='va'>get_cp</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>{</span>
  <span class='va'>min</span>    <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/which.min.html'>which.min</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>$</span><span class='va'>cptable</span><span class='op'>[</span>, <span class='st'>"xerror"</span><span class='op'>]</span><span class='op'>)</span>
  <span class='va'>cp</span> <span class='op'>&lt;-</span> <span class='va'>x</span><span class='op'>$</span><span class='va'>cptable</span><span class='op'>[</span><span class='va'>min</span>, <span class='st'>"CP"</span><span class='op'>]</span> 
<span class='op'>}</span>

<span class='co'># function to get minimum error</span>
<span class='va'>get_min_error</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>{</span>
  <span class='va'>min</span>    <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/which.min.html'>which.min</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>$</span><span class='va'>cptable</span><span class='op'>[</span>, <span class='st'>"xerror"</span><span class='op'>]</span><span class='op'>)</span>
  <span class='va'>xerror</span> <span class='op'>&lt;-</span> <span class='va'>x</span><span class='op'>$</span><span class='va'>cptable</span><span class='op'>[</span><span class='va'>min</span>, <span class='st'>"xerror"</span><span class='op'>]</span> 
<span class='op'>}</span>

<span class='va'>hyper_grid</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate</a></span><span class='op'>(</span>
    cp    <span class='op'>=</span> <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/map.html'>map_dbl</a></span><span class='op'>(</span><span class='va'>models</span>, <span class='va'>get_cp</span><span class='op'>)</span>,
    error <span class='op'>=</span> <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/map.html'>map_dbl</a></span><span class='op'>(</span><span class='va'>models</span>, <span class='va'>get_min_error</span><span class='op'>)</span>
    <span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/arrange.html'>arrange</a></span><span class='op'>(</span><span class='va'>error</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/top_n.html'>top_n</a></span><span class='op'>(</span><span class='op'>-</span><span class='fl'>5</span>, wt <span class='op'>=</span> <span class='va'>error</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>  minsplit maxdepth         cp     error
1       19       12 0.01060346 0.2628987
2        5        8 0.01000000 0.2635207
3        9       11 0.01000000 0.2645615
4       14       11 0.01000000 0.2650862
5       13       10 0.01000000 0.2655860</code></pre>
</div>
<p>Extract the tree for the optimal value of the tuning parameters.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>optimal_tree</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/rpart/man/rpart.html'>rpart</a></span><span class='op'>(</span>
    formula <span class='op'>=</span> <span class='va'>Sale_Price</span> <span class='op'>~</span> <span class='va'>.</span>,
    data    <span class='op'>=</span> <span class='va'>ames_train</span>,
    method  <span class='op'>=</span> <span class='st'>"anova"</span>,
    control <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>minsplit <span class='op'>=</span> <span class='fl'>17</span>, maxdepth <span class='op'>=</span> <span class='fl'>12</span>, cp <span class='op'>=</span> <span class='fl'>0.01</span><span class='op'>)</span>
    <span class='op'>)</span>
</code></pre>
</div>
</div>
<p>The new test error</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>pred</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>optimal_tree</span>, newdata <span class='op'>=</span> <span class='va'>ames_test</span><span class='op'>)</span>
<span class='va'>p_error</span> <span class='op'>&lt;-</span> <span class='fu'>Metrics</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/Metrics/man/rmse.html'>rmse</a></span><span class='op'>(</span>actual <span class='op'>=</span> <span class='va'>ames_test</span><span class='op'>$</span><span class='va'>Sale_Price</span>, predicted <span class='op'>=</span> <span class='va'>pred</span><span class='op'>)</span>
<span class='va'>p_error</span>
</code></pre>
</div>
<pre><code>[1] 39852.01</code></pre>
</div>
<div class="sourceCode" id="cb4"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
