<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #20794d; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #20794d; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

  <!--radix_placeholder_meta_tags-->
<title>Econ 712: Clustering</title>

<meta property="description" itemprop="description" content="Organizing the rows of your data"/>


<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2021-03-24"/>
<meta property="article:created" itemprop="dateCreated" content="2021-03-24"/>
<meta name="article:author" content="Amit Gandhi"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Econ 712: Clustering"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="Organizing the rows of your data"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Econ 712"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary"/>
<meta property="twitter:title" content="Econ 712: Clustering"/>
<meta property="twitter:description" content="Organizing the rows of your data"/>

<!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output","preview"]}},"value":[{"type":"character","attributes":{},"value":["Clustering"]},{"type":"character","attributes":{},"value":["Organizing the rows of your data"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Amit Gandhi"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":[]}},"value":[]}]}]},{"type":"character","attributes":{},"value":["03-24-2021"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["https://new.pharmacelera.com/wp-content/uploads/2019/08/clusters-1024x530.png"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["average.png","complete.png","dendogram.png","exavg.png","excomp.png","exsing.png","faces.png","figures/agclustex.jpg","figures/agclustex.pdf","figures/agclustex2.pdf","figures/average.pdf","figures/bien1.png","figures/bien2.png","figures/breastcancer.png","figures/bw.pdf","figures/cassella1.png","figures/cassella2.png","figures/centroid.pdf","figures/chooseex1a.pdf","figures/chooseex1b.pdf","figures/chooseex2a.pdf","figures/chooseex2b.pdf","figures/chooseex2c.pdf","figures/chooseex3.pdf","figures/chooseex4.pdf","figures/chooseex5.pdf","figures/chooseex5a.pdf","figures/chooseex5b.pdf","figures/choosek 2.pdf","figures/choosek.pdf","figures/city.jpg","figures/class.png","figures/clus1.png","figures/clus2.png","figures/complete.pdf","figures/exavg.pdf","figures/excent.pdf","figures/excomp.pdf","figures/exdata.pdf","figures/exmm.pdf","figures/exsing.pdf","figures/kmeans_sim.pdf","figures/kmeans_sim2.pdf","figures/mono.pdf","figures/mono1.pdf","figures/mono2.pdf","figures/noinv.pdf","figures/props1.pdf","figures/props2.pdf","figures/props3.pdf","figures/simple2.jpg","figures/single.pdf","figures/zito.pdf","hcpic.png","k-means_files/anchor-4.2.2/anchor.min.js","k-means_files/bowser-1.9.3/bowser.min.js","k-means_files/distill-2.2.21/template.v2.js","k-means_files/figure-html5/unnamed-chunk-12-1.png","k-means_files/figure-html5/unnamed-chunk-13-1.png","k-means_files/figure-html5/unnamed-chunk-14-1.png","k-means_files/figure-html5/unnamed-chunk-16-1.png","k-means_files/figure-html5/unnamed-chunk-7-1.png","k-means_files/header-attrs-2.7/header-attrs.js","k-means_files/jquery-1.11.3/jquery.min.js","k-means_files/popper-2.6.0/popper.min.js","k-means_files/tippy-6.2.7/tippy-bundle.umd.min.js","k-means_files/tippy-6.2.7/tippy-light-border.css","k-means_files/tippy-6.2.7/tippy.css","k-means_files/tippy-6.2.7/tippy.umd.min.js","k-means_files/webcomponents-2.0.0/webcomponents.js","medioid.png","pics/140102_weiss_syria_ap.jpg","pics/abstract_duke_2013.pdf","pics/acf_ucla_bayes2.pdf","pics/asad.jpg","pics/band_one.png","pics/bands.png","pics/biplot_fmri.png","pics/brain_plot.png","pics/cartoon.png","pics/census.jpeg","pics/census.png","pics/clustering_2.png","pics/clustering_3.png","pics/clustering.png","pics/clusters.png","pics/data.png","pics/data10.png","pics/data11.png","pics/data12.png","pics/data13.png","pics/data14.png","pics/data15.png","pics/data16.png","pics/data17.png","pics/data18.png","pics/data19.png","pics/data2.png","pics/data20.png","pics/data21.png","pics/data22.png","pics/data23.png","pics/data24.png","pics/data3.png","pics/data4.png","pics/data5.png","pics/data6.png","pics/data7.png","pics/data8.png","pics/data9.png","pics/davidson.jpg","pics/distortion_rates_all.pdf","pics/distortion_six.pdf","pics/elnet.png","pics/exchangeability.png","pics/fienberg.jpeg","pics/group_clusters.png","pics/hashfunction.png","pics/heatmap.pdf","pics/histogram_100blocks.pdf","pics/images.jpg","pics/jaccard.png","pics/job_talk_spring_14_v2.png","pics/KLSH_1_2_gram.pdf","pics/kmeans_k3.pdf","pics/kmeans.png","pics/kmeans1.png","pics/kmeans2.png","pics/kmeans3.png","pics/latents_firstex.png","pics/latents_secondex.png","pics/link_names.jpg","pics/link_names.png","pics/lsh_mapping_33000b20.pdf","pics/lsh.png","pics/lum_page1.pdf","pics/many_bands.png","pics/map.jpeg","pics/minhash_ex.png","pics/MMS_ex.png","pics/MMS_trans_violation.png","pics/MMS_transitivity_violation.png","pics/network_curves_center.pdf","pics/network_curves.pdf","pics/NSAParody.swf","pics/ny.jpg","pics/obama.jpg","pics/p1_jw_bins1.pdf","pics/p1_jw_overlap_bins1.pdf","pics/penndot.jpg","pics/pittpatt.jpg","pics/plot_bin_10000_new.pdf","pics/plot_bin_10000.pdf","pics/plot_bin.pdf","pics/posterior_full_run_nostates_heatmaprun2_new.pdf","pics/posterior_full_run_nostates_heatmaprun2.pdf","pics/posterior_full_run_nostates_heatmaprun2.pdf_new","pics/posterior_full_run_nostates_heatmaprun2.pdf_new2","pics/posterior_n.pdf","pics/posterior_n2.pdf","pics/recall_KLSH_nodod.pdf","pics/recall_nodod_p20.pdf","pics/recall_p20_40_100.pdf","pics/recall_p20_40.pdf","pics/roc_both.pdf","pics/roc_partition1_cv.pdf","pics/roc_partition1.pdf","pics/roc_partition2_cv_overlaplongest.pdf","pics/roc_partition2_cv.pdf","pics/roc_partition2.pdf","pics/roc_partition3_cv_longestoverlap.pdf","pics/roc_partition3_cv_overlaplongest.pdf","pics/roc_partition3_cv.pdf","pics/roc_partition3.pdf","pics/roc_partition4_cv_overlaplongest.pdf","pics/roc_partition4_cv.pdf","pics/roc_partition4.pdf","pics/scurve.png","pics/sharedMPMMS.png","pics/signatures.png","pics/simple-example.png","pics/small_names.png","pics/smextra.png","pics/smfive.png","pics/smfourh.png","pics/smone.png","pics/smoneh.png","pics/smthree.png","pics/smthreeh.png","pics/smtwo.png","pics/smtwoh.png","pics/states.jpg","pics/steve_fienberg2.jpg","pics/steve_ohio.jpg","pics/steve_speedball.jpg","pics/steven_fienberg_mosaic.jpg","pics/syria_dead.jpg","pics/tlsh_klsh_comparison_100.pdf","pics/trace_ucla_bayes2.pdf","pics/transitive_one.png","pics/transitive_three.png","pics/transitive_two.png","pics/UDDR-wordcloud-300x200.png","pics/xian1.jpg","pics/xian2.jpg","pics/xian3.jpg","simple.png","single.png","table.png","zito.png"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      var refHtml = $('#ref-' + $(this).attr('data-cites')).html();
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<style type="text/css">
/* base variables */

/* Edit the CSS properties in this file to create a custom
   Distill theme. Only edit values in the right column
   for each row; values shown are the CSS defaults.
   To return any property to the default,
   you may set its value to: unset
   All rows must end with a semi-colon.                      */

/* Optional: embed custom fonts here with `@import`          */
/* This must remain at the top of this file.                 */



html {
  /*-- Main font sizes --*/
  --title-size:      50px;
  --body-size:       1.06rem;
  --code-size:       14px;
  --aside-size:      12px;
  --fig-cap-size:    13px;
  /*-- Main font colors --*/
  --title-color:     #000000;
  --header-color:    rgba(0, 0, 0, 0.8);
  --body-color:      rgba(0, 0, 0, 0.8);
  --aside-color:     rgba(0, 0, 0, 0.6);
  --fig-cap-color:   rgba(0, 0, 0, 0.6);
  /*-- Specify custom fonts ~~~ must be imported above   --*/
  --heading-font:    sans-serif;
  --mono-font:       monospace;
  --body-font:       sans-serif;
  --navbar-font:     sans-serif;  /* websites + blogs only */
}

/*-- ARTICLE METADATA --*/
d-byline {
  --heading-size:    0.6rem;
  --heading-color:   rgba(0, 0, 0, 0.5);
  --body-size:       0.8rem;
  --body-color:      rgba(0, 0, 0, 0.8);
}

/*-- ARTICLE TABLE OF CONTENTS --*/
.d-contents {
  --heading-size:    18px;
  --contents-size:   13px;
}

/*-- ARTICLE APPENDIX --*/
d-appendix {
  --heading-size:    15px;
  --heading-color:   rgba(0, 0, 0, 0.65);
  --text-size:       0.8em;
  --text-color:      rgba(0, 0, 0, 0.5);
}

/*-- WEBSITE HEADER + FOOTER --*/
/* These properties only apply to Distill sites and blogs  */

.distill-site-header {
  --title-size:       18px;
  --text-color:       rgba(255, 255, 255, 0.8);
  --text-size:        15px;
  --hover-color:      white;
  --bkgd-color:       #0F2E3D;
}

.distill-site-footer {
  --text-color:       rgba(255, 255, 255, 0.8);
  --text-size:        15px;
  --hover-color:      white;
  --bkgd-color:       #0F2E3D;
}

/*-- Additional custom styles --*/
/* Add any additional CSS rules below                      */
</style>
<style type="text/css">/* base variables */

/* Edit the CSS properties in this file to create a custom
   Distill theme. Only edit values in the right column
   for each row; values shown are the CSS defaults.
   To return any property to the default,
   you may set its value to: unset
   All rows must end with a semi-colon.                      */

/* Optional: embed custom fonts here with `@import`          */
/* This must remain at the top of this file.                 */
@import url('https://fonts.googleapis.com/css2?family=Lato');
@import url('https://fonts.googleapis.com/css2?family=Fira+Mono');
@import url('https://fonts.googleapis.com/css2?family=Montserrat');

html {
  /*-- Main font sizes --*/
  --title-size:      50px;
  --body-size:       1.0rem;                     /* edited */
  --code-size:       0.9rem;                     /* edited */
  --aside-size:      12px;
  --fig-cap-size:    13px;
  /*-- Main font colors --*/
  --title-color:     #000000;
  --heading-color:   rgba(0, 0, 0, 0.8);
  --body-color:      #383838;                    /* edited */
  --aside-color:     rgba(0, 0, 0, 0.6);
  --fig-cap-color:   rgba(0, 0, 0, 0.6);
  /*-- Specify custom fonts ~~~ must be imported above   --*/
  --heading-font:    'Lato', sans-serif;         /* edited */
  --mono-font:       'Fira Mono', monospace;     /* edited */
  --body-font:       'Lato', sans-serif;         /* edited */
  --navbar-font:     'Montserrat', sans-serif;   /* edited */
}

/*-- ARTICLE METADATA --*/
d-byline {
  --heading-size:    0.6rem;
  --heading-color:   rgba(0, 0, 0, 0.5);
  --body-size:       0.8rem;
  --body-color:      rgba(0, 0, 0, 0.8);
}

/*-- ARTICLE TABLE OF CONTENTS --*/
.d-contents {
  --heading-size:    18px;
  --contents-size:   13px;
}

/*-- ARTICLE APPENDIX --*/
d-appendix {
  --heading-size:    15px;
  --heading-color:   rgba(0, 0, 0, 0.65);
  --text-size:       0.8em;
  --text-color:      rgba(0, 0, 0, 0.5);
}

/*-- WEBSITE HEADER + FOOTER --*/
/* These properties only apply to Distill sites and blogs  */

.distill-site-header {
  --title-size:       20px;                      /* edited */
  --text-color:       #FFFFFF;                   /* edited */
  --text-size:        20px;                      /* edited */
  --hover-color:      #383838;                   /* edited */
  --bkgd-color:       rgb(249, 83, 85);          /* edited */
}

.distill-site-footer {
  --text-color:       rgba(255, 255, 255, 0.8);
  --text-size:        15px;
  --hover-color:      white;
  --bkgd-color:       #0F2E3D;
}


/*-- Additional custom styles --*/

.posts-list .metadata .publishedDate {
    color: rgb(249, 83, 85);
}

d-article p code {
  color: #383838;
  background: rgba(249, 83, 85, 0.1);
  font-weight: 400;
  font-size: 0.9em;
}

d-article a {
    border-bottom: 2px solid rgba(249, 83, 85, 0.4);
    text-decoration: none;
}

.distill-site-header .title {
    font-weight: 600; 
}

ul > li::marker {
  color: rgb(249, 83, 85);
}</style>
<style type="text/css">
/* base style */

/* FONT FAMILIES */

:root {
  --heading-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  --mono-default: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  --body-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

body,
.posts-list .post-preview p,
.posts-list .description p {
  font-family: var(--body-font), var(--body-default);
}

h1, h2, h3, h4, h5, h6,
.posts-list .post-preview h2,
.posts-list .description h2 {
  font-family: var(--heading-font), var(--heading-default);
}

d-article div.sourceCode code,
d-article pre code {
  font-family: var(--mono-font), var(--mono-default);
}


/*-- TITLE --*/
d-title h1,
.posts-list > h1 {
  color: var(--title-color, black);
}

d-title h1 {
  font-size: var(--title-size, 50px);
}

/*-- HEADERS --*/
d-article h1,
d-article h2,
d-article h3,
d-article h4,
d-article h5,
d-article h6 {
  color: var(--header-color, rgba(0, 0, 0, 0.8));
}

/*-- BODY --*/
d-article > p,  /* only text inside of <p> tags */
d-article > ul, /* lists */
d-article > ol {
  color: var(--body-color, rgba(0, 0, 0, 0.8));
  font-size: var(--body-size, 1.06rem);
}


/*-- CODE --*/
d-article div.sourceCode code,
d-article pre code {
  font-size: var(--code-size, 14px);
}

/*-- ASIDE --*/
d-article aside {
  font-size: var(--aside-size, 12px);
  color: var(--aside-color, rgba(0, 0, 0, 0.6));
}

/*-- FIGURE CAPTIONS --*/
figure .caption,
figure figcaption,
.figure .caption {
  font-size: var(--fig-cap-size, 13px);
  color: var(--fig-cap-color, rgba(0, 0, 0, 0.6));
}

/*-- METADATA --*/
d-byline h3 {
  font-size: var(--heading-size, 0.6rem);
  color: var(--heading-color, rgba(0, 0, 0, 0.5));
}

d-byline {
  font-size: var(--body-size, 0.8rem);
  color: var(--body-color, rgba(0, 0, 0, 0.8));
}

d-byline a,
d-article d-byline a {
  color: var(--body-color, rgba(0, 0, 0, 0.8));
}

/*-- TABLE OF CONTENTS --*/
.d-contents nav h3 {
  font-size: var(--heading-size, 18px);
}

.d-contents nav a {
  font-size: var(--contents-size, 13px);
}

/*-- APPENDIX --*/
d-appendix h3 {
  font-size: var(--heading-size, 15px);
  color: var(--heading-color, rgba(0, 0, 0, 0.65));
}

d-appendix {
  font-size: var(--text-size, 0.8em);
  color: var(--text-color, rgba(0, 0, 0, 0.5));
}

d-appendix d-footnote-list a.footnote-backlink {
  color: var(--text-color, rgba(0, 0, 0, 0.5));
}

/*-- WEBSITE HEADER + FOOTER --*/
.distill-site-header .title {
  font-size: var(--title-size, 18px);
  font-family: var(--navbar-font), var(--heading-default);
}

.distill-site-header a,
.nav-dropdown .nav-dropbtn {
  font-family: var(--navbar-font), var(--heading-default);
}

.nav-dropdown .nav-dropbtn {
  color: var(--text-color, rgba(255, 255, 255, 0.8));
  font-size: var(--text-size, 15px);
}

.distill-site-header a:hover,
.nav-dropdown:hover .nav-dropbtn {
  color: var(--hover-color, white);
}

.distill-site-header {
  font-size: var(--text-size, 15px);
  color: var(--text-color, rgba(255, 255, 255, 0.8));
  background-color: var(--bkgd-color, #0F2E3D);
}

.distill-site-footer {
  font-size: var(--text-size, 15px);
  color: var(--text-color, rgba(255, 255, 255, 0.8));
  background-color: var(--bkgd-color, #0F2E3D);
}

.distill-site-footer a:hover {
  color: var(--hover-color, white);
}</style>
<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.7/header-attrs.js"></script>
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Clustering","description":"Organizing the rows of your data","authors":[{"author":"Amit Gandhi","authorURL":{},"affiliation":"&nbsp;","affiliationURL":"#","orcidID":""}],"publishedDate":"2021-03-24T00:00:00.000+00:00","citationText":"Gandhi, 2021"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/pennlogo.png"/>
</span>
<a href="../../index.html" class="title">Econ 712</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../about.html">About</a>
<a href="https://twitter.com/AmitEcon">
<i class="fa fa-twitter" aria-hidden="true"></i>
</a>
<a href="mailto:akgandhi@upenn.edu">
<i class="fa fa-envelope" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Clustering</h1>
<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->
<p><p>Organizing the rows of your data</p></p>
</div>

<div class="d-byline">
  Amit Gandhi true 
  
<br/>03-24-2021
</div>

<div class="d-article">
<h1 id="what-is-clustering-why-do-we-use-it">What is clustering? Why do we use it?</h1>
<p><img src="pics/clustering.png" /></p>
<p><img src="pics/clustering_2.png" /></p>
<p><img src="pics/clustering_3.png" /></p>
<h2 id="purpose">Purpose</h2>
<ul>
<li>In clustering, we look at data, where groups are unknown and undefined,</li>
<li>Try to learn the groups themselves, as well as what differentiates them</li>
</ul>
<p><img src="figures/clus1.png" /></p>
<p><img src="figures/clus2.png" /></p>
<h1 id="clustering-algorithms">Clustering algorithms</h1>
<p>We will cover two clustering algorithms that are very simple to understand, visualize, and use.</p>
<p>The first is the k-means algorithm.</p>
<p>The second is hierarchical clustering.</p>
<h2 id="k-means-clustering-algorithm">K-means clustering algorithm</h2>
<ul>
<li><p>K-means clustering: simple approach for partitioning a dataset into K distinct, non-overlapping clusters.</p></li>
<li><p>To perform K-means clustering: specify the desired number of clusters K.</p></li>
<li><p>Then the K-means algorithm will assign each observation to exactly one of the K clusters.</p></li>
<li><p>Observations <span class="math inline">\(X_1,\ldots X_n\)</span></p></li>
<li><p>dissimilarites <span class="math inline">\(d(X_i,X_j)\)</span> (E.g., think of <span class="math inline">\(X_i \in \R^p\)</span> and <span class="math inline">\(d(X_i,X_j)=\|X_i-X_j\|_2^2\)</span>)</p></li>
<li><p>Let <span class="math inline">\(K\)</span> be the number of clusters (fixed).</p></li>
<li><p>A clustering of points <span class="math inline">\(X_1,\ldots X_n\)</span> is a function <span class="math inline">\(C\)</span> that assigns each observation <span class="math inline">\(X_i\)</span> to a group <span class="math inline">\(k \in \{1,\ldots K\}\)</span></p></li>
</ul>
<p><img src="zito.png" /></p>
<h3 id="within-cluster-variation">Within-cluster variation</h3>
<ul>
<li><span class="math inline">\(C(i)=k\)</span> means that observation <span class="math inline">\(X_i\)</span> is assigned to group <span class="math inline">\(k\)</span></li>
<li><span class="math inline">\(|C_k|\)</span> is the number of points in group <span class="math inline">\(k\)</span></li>
<li>Let <span class="math inline">\(d_{ij} = d(X_i,X_j),\)</span> for some distance function <span class="math inline">\(d.\)</span></li>
</ul>
<p>The within-cluster variation is defined as <span class="math display">\[W =  \sum_{k=1}^K 
\frac{1}{|C_k|} \sum_{C(i)=k, \, C(j)=k} d_{ij}\]</span></p>
<p>Smaller <span class="math inline">\(W\)</span> is better</p>
<h3 id="example">Example</h3>
<p>Here <span class="math inline">\(n=5\)</span> and <span class="math inline">\(K=2\)</span></p>
<p><span class="math inline">\(X_i \in \mathbb{R}^2\)</span> and</p>
<p><span class="math inline">\(d_{ij}=\|X_i-X_j\|_2^2\)</span></p>
<p><img src="table.png" /></p>
<p><img src="simple.png" /></p>
<ul>
<li>Red clustering: <span class="math inline">\(W_{\text{red}}=(0.25+0.53+0.52)/3 + 0.25/2 = 0.56\)</span></li>
<li>Blue clustering: <span class="math inline">\(W_{\text{blue}}=0.25/2 + (0.10+0.17+0.25)/3 = 0.30\)</span></li>
</ul>
<p>(Tip: dist function in R)</p>
<h3 id="finding-the-best-group-assignments">Finding the best group assignments</h3>
<p>Smaller <span class="math inline">\(W\)</span> is better, so why dont we just directly find the clustering <span class="math inline">\(C\)</span> that minimizes <span class="math inline">\(W\)</span>?</p>
<p>Problem: doing so requires trying all possible assignments of the <span class="math inline">\(n\)</span> points into <span class="math inline">\(K\)</span> groups. The number of possible assignments is</p>
<p><span class="math display">\[A(n,K) = \frac{1}{K!}\sum_{k=1}^K (-1)^{K-k} 
{K \choose k} k^n
\]</span></p>
<p>Note that <span class="math inline">\(A(10,4)=34,105\)</span>, and <span class="math inline">\(A(25,4) \approx 5 \times 10^{13}\)</span></p>
<p>See, Jain and Dubes (1998), Algorithms for Clustering Data</p>
<p>Most problems we look at are going to have way more than <span class="math inline">\(n=25\)</span> observations, and potentially more than <span class="math inline">\(K=4\)</span> clusters too (but <span class="math inline">\(K=4\)</span> is not unrealistic)</p>
<h3 id="finding-the-best-group-assignments-1">Finding the best group assignments</h3>
<p>How do we get around this?</p>
<p><br></p>
<p>We will end up making an approximation. Lets walk through all the details now of K-means clustering.</p>
<h3 id="k-means-clustering">K-means clustering</h3>
<ul>
<li><p>K-means is a simple way to paritition a data set into <span class="math inline">\(K\)</span> distinct, non-overlapping clusters.</p></li>
<li><p>To perform K-means clustering, we must</p></li>
</ul>
<ol type="1">
<li>first specify the desired number of clusters K</li>
<li>then the K-means algorithm will assign each observation to exactly one of the K clusters.</li>
</ol>
<p>How does this work?</p>
<h3 id="notation">Notation</h3>
<p>Let <span class="math inline">\(n\)</span> denote the number of data points in our data set.</p>
<p>Let <span class="math display">\[C_1, C_2,
\ldots C_k\]</span> denoting sets containing the indices of the observations in each cluster. (This means that each data point is in only one cluster <span class="math inline">\(C_j\)</span>).</p>
<p>This means that these sets satisfy two properties:</p>
<ol type="1">
<li><p><span class="math display">\[C_1 \cup C_2 \cup \cdots C_K = \{1,\ldots,n\}.\]</span> This means that each observations belongs to at least one of the <span class="math inline">\(K\)</span> clusters.</p></li>
<li><p><span class="math display">\[C_k \cap C_{k^{\prime}} = \emptyset\]</span> for all <span class="math inline">\(k \neq k^{\prime}.\)</span> This means the clusters are non-overlapping and so no observation belongs to more than one cluster.</p></li>
</ol>
<h3 id="intuition">Intuition</h3>
<p>As an example, if the <span class="math inline">\(i\)</span>th observation is in cluster <span class="math inline">\(k\)</span> then data point <span class="math inline">\(i \in C_k.\)</span></p>
<p>We think of k-means being a good clustering algorithm when the within-cluster variation is as small as possible.</p>
<p>What is this?</p>
<h3 id="the-within-cluster-variation">The within cluster variation</h3>
<p>The within cluster variation of cluster <span class="math inline">\(C_k\)</span> is a measure of <span class="math inline">\(W(C_k)\)</span> of the amount by which the observations within a cluster differ from each other.</p>
<p>Mathematically, we want to solve the following optimization problem:</p>
<p><span class="math display">\[\min_{C_1,\ldots,C_K} \sum_{k=1}^K W(C_k)\]</span></p>
<p>In words, this means that we want to partition the data points into clusters such that the total within-cluster variation summed over all <span class="math inline">\(K\)</span> clusters is as small as possible.</p>
<p>This seems reasonable, but how do we define the within-cluster variation <span class="math inline">\(W(C_k)\)</span>? Thoughts?</p>
<p>There are many possible ways to define this concept, but by far the most common choice involves squared Euclidean distance.</p>
<p>Thus, we define</p>
<p><span class="math display">\[W(C_k) = \frac{1}{|C_k|} \sum_{i,i^{\prime}} \sum_{j=1}^p(x_{ij} - x_{i^{\prime}j})^2\]</span></p>
<p>where <span class="math inline">\(|C_k|\)</span> denotes the number of observations in the kth cluster.</p>
<p>In words, the within-cluster variation for the <span class="math inline">\(k\)</span>th cluster is the sum of all of the pairwise squared Euclidean distances between the observations in the <span class="math inline">\(k\)</span>th cluster, divided by the total number of observations in the <span class="math inline">\(k\)</span>th cluster.</p>
<h3 id="back-to-the-optimization-problem">Back to the optimization problem</h3>
<p>We return now to the optimization problem that defines <span class="math inline">\(K\)</span>-means clustering (under the Euclidean norm):</p>
<p><span class="math display">\[\begin{align}
\min_{C_1,\ldots,C_K} \sum_{k=1}^K W(C_k)
&amp;=
\min_{C_1,\ldots,C_K} \{ \sum_{k=1}^K
\frac{1}{|C_k|} \sum_{i,i^{\prime}} \sum_{j=1}^p(x_{ij} - x_{i^{\prime}j})^2
\}
\end{align}\]</span></p>
<p>Now, we would like to find an algorithm to solve the above equation.</p>
<p>That is, we want a method to partition the observations into K clusters such that the objective is minimized.</p>
<p>This is in fact a very difficult problem to solve precisely, since there are almost <span class="math inline">\(K^n\)</span> ways to partition <span class="math inline">\(n\)</span> data points into <span class="math inline">\(K\)</span> clusters.</p>
<p>This is a very large number unless <span class="math inline">\(K\)</span> and <span class="math inline">\(n\)</span> are both small. (In practice, they are not)!</p>
<p>Fortunately, a very simple algorithm can be shown to provide a local optimum  a pretty good solution  to the K-means optimization problem.</p>
<h3 id="k-means-clustering-algorithm-1">K-means clustering algorithm</h3>
<ol type="1">
<li>Randomly assign a number, from 1 to <span class="math inline">\(K\)</span>, to each of the observations. These serve as initial cluster assignments for the observations.</li>
<li>Iterate until the clustering algorithm stops changing:</li>
</ol>
<ul>
<li><p>For each of the <span class="math inline">\(K\)</span> clusters, compute the centroid. The <span class="math inline">\(k\)</span>th cluster centriod is the vector of the <span class="math inline">\(p\)</span> feature averages for the observations in the cluster <span class="math inline">\(k\)</span>.</p></li>
<li><p>Assign each observation to the cluster whose centroid is closest (where closest is defined using Euclidean distance).</p></li>
</ul>
<p>Note: <span class="math inline">\(\bar{x}_{kj} = \frac{1}{|C_k|} \sum_{i\in C_k} x_{ij}\)</span> is the average for feature <span class="math inline">\(j\)</span> in cluster <span class="math inline">\(C_k.\)</span></p>
<h3 id="k-means-clustering-algorithm-2">K-means clustering algorithm</h3>
<p>The above algorithm is guaranteed to decrease the value of the objective function at each step.</p>
<p>Why is this true?</p>
<p><span class="math display">\[\begin{align}
\frac{1}{|C_k|} \sum_{i,i^{\prime} \in C_k} \sum_{j=1}^p(x_{ij} - x_{i^{\prime}j})^2
&amp;= 2 \sum_{i \in C_k} \sum_{j=1}^p (x_{ij} - \bar{x}_{kj})^2,
\end{align}\]</span> where <span class="math inline">\(\bar{x}_{kj} = \frac{1}{|C_k|} \sum_{i\in C_k} x_{ij}\)</span> is the mean for data point (feature) <span class="math inline">\(j\)</span> in cluster <span class="math inline">\(C_k.\)</span></p>
<ul>
<li><p>In Step 2(a), the cluster means for each data point are the constants that minimize the sum of squared deviations</p></li>
<li><p>In Step 2(b), reallocating the data points can only improve the the within sum of squares.</p></li>
<li><p>This means that as the algorithm is run, the clustering obtained will continually improve until the result no longer changes and the objective of equation  will never increase!</p></li>
<li><p>When the result no longer changes, we reach a local optimum.</p></li>
</ul>
<p>Since the algorithm reaches a local optimum and not a global optimum, the results obtained will depend on the initial (random) cluster assignment of each observation in Step 1.</p>
<ul>
<li><p>Due to this, its crucial to run the algorithm many times and from multiple (random) starting points.</p></li>
<li><p>One should select the best solution, namely, the one where the objective function is the smallest.</p></li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>knitr</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/knitr/man/include_graphics.html'>include_graphics</a></span><span class='op'>(</span><span class='st'>"pics/kmeans1.png"</span><span class='op'>)</span>
</code></pre>
</div>
<div class="figure"><span id="fig:unnamed-chunk-1"></span>
<img src="pics/kmeans1.png" alt="Top left: the data is shown. Top center: in Step 1 of the algorithm, each observation is randomly assigned to a cluster. Top right: in Step 2(a), the cluster centroids are computed. These are shown as large colored disks. Initially the centroids are almost completely overlapping because the initial cluster assignments were chosen at random." width="314" />
<p class="caption">
Figure 1: Top left: the data is shown. Top center: in Step 1 of the algorithm, each observation is randomly assigned to a cluster. Top right: in Step 2(a), the cluster centroids are computed. These are shown as large colored disks. Initially the centroids are almost completely overlapping because the initial cluster assignments were chosen at random.
</p>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>knitr</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/knitr/man/include_graphics.html'>include_graphics</a></span><span class='op'>(</span><span class='st'>"pics/kmeans2.png"</span><span class='op'>)</span>
</code></pre>
</div>
<div class="figure"><span id="fig:unnamed-chunk-2"></span>
<img src="pics/kmeans2.png" alt="Bottom left: in Step 2(b), each observation is assigned to the nearest centroid. Bottom center: Step 2(a) is once again performed, leading to new cluster centroids. Bottom right: the results obtained after ten iterations." width="310" />
<p class="caption">
Figure 2: Bottom left: in Step 2(b), each observation is assigned to the nearest centroid. Bottom center: Step 2(a) is once again performed, leading to new cluster centroids. Bottom right: the results obtained after ten iterations.
</p>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>knitr</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/knitr/man/include_graphics.html'>include_graphics</a></span><span class='op'>(</span><span class='st'>"pics/kmeans3.png"</span><span class='op'>)</span>
</code></pre>
</div>
<div class="figure"><span id="fig:unnamed-chunk-3"></span>
<img src="pics/kmeans3.png" alt="K-means clustering performed six times; K = 3, each time with a different random assignment of the observations in Step 1 of the K-means algorithm. Above each plot is the value of the objective. Those labeled in red all achieved the same best solution, with an objective value of 235.8." width="308" />
<p class="caption">
Figure 3: K-means clustering performed six times; K = 3, each time with a different random assignment of the observations in Step 1 of the K-means algorithm. Above each plot is the value of the objective. Those labeled in red all achieved the same best solution, with an objective value of 235.8.
</p>
</div>
</div>
<h3 id="application">Application</h3>
<p>We begin with a simple simulated example in which there truly are two clusters in the data: the first 25 observations have a mean shift relative to the next 25 observations.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># simulated some data</span>
<span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>
<span class='va'>x</span><span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>matrix</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/Normal.html'>rnorm</a></span><span class='op'>(</span><span class='fl'>50</span><span class='op'>*</span><span class='fl'>2</span><span class='op'>)</span>, ncol<span class='op'>=</span><span class='fl'>2</span><span class='op'>)</span>
<span class='va'>x</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>25</span>,<span class='fl'>1</span><span class='op'>]</span><span class='op'>=</span><span class='va'>x</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>25</span>,<span class='fl'>1</span><span class='op'>]</span><span class='op'>+</span><span class='fl'>3</span>
<span class='va'>x</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>25</span>,<span class='fl'>2</span><span class='op'>]</span><span class='op'>=</span><span class='va'>x</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>25</span>,<span class='fl'>2</span><span class='op'>]</span><span class='op'>-</span><span class='fl'>4</span>
</code></pre>
</div>
</div>
<h3 id="perform-k-means-clustering-k2">Perform K-means clustering, <span class="math inline">\(K=2\)</span></h3>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>km.out</span><span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/stats/kmeans.html'>kmeans</a></span><span class='op'>(</span><span class='va'>x</span>,centers<span class='op'>=</span> <span class='fl'>2</span>,nstart<span class='op'>=</span><span class='fl'>20</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<ul>
<li>centers is the number of clusters <span class="math inline">\(K\)</span>.</li>
<li>nstart tells us how many sets should be chosen.</li>
</ul>
<h3 id="perform-k-means-clustering-k2-1">Perform K-means clustering, <span class="math inline">\(K=2\)</span></h3>
<p>The cluster assignments of the 50 observations can be found by the following:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>km.out</span><span class='op'>$</span><span class='va'>cluster</span>
</code></pre>
</div>
<pre><code> [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2
[34] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2</code></pre>
</div>
<p>The K-means clustering perfectly separated the observations into two clusters even though we did not supply any group information to kmeans</p>
<h3 id="plotting-with-cluster-assignment">Plotting with cluster assignment</h3>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>x</span>, col<span class='op'>=</span><span class='op'>(</span><span class='va'>km.out</span><span class='op'>$</span><span class='va'>cluster</span> <span class='op'>+</span><span class='fl'>1</span><span class='op'>)</span>, main<span class='op'>=</span><span class='st'>""</span>, xlab<span class='op'>=</span><span class='st'>""</span>, ylab<span class='op'>=</span><span class='st'>""</span>, pch<span class='op'>=</span><span class='fl'>20</span>, cex<span class='op'>=</span><span class='fl'>2</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="k-means_files/figure-html5/unnamed-chunk-7-1.png" width="624" /></p>
</div>
<p>Here the observations can be easily plotted because they are two-dimensional. If there were more than two variables then we could instead perform PCA and plot the first two principal components score vectors.</p>
<h3 id="other-values-of-k">Other values of <span class="math inline">\(K\)</span></h3>
<p>Here, we alread knew the value of <span class="math inline">\(K\)</span> because we simulated the data and in general we dont know <span class="math inline">\(K\)</span>, so we need to play around with this value.</p>
<p>What happens if we look at <span class="math inline">\(K=3.\)</span></p>
<p><span class="math inline">\(K=3\)</span> for simulated example</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>4</span><span class='op'>)</span>
<span class='va'>km.out</span><span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/stats/kmeans.html'>kmeans</a></span><span class='op'>(</span><span class='va'>x</span>,<span class='fl'>3</span>,nstart<span class='op'>=</span><span class='fl'>20</span><span class='op'>)</span>
<span class='va'>km.out</span>
</code></pre>
</div>
<pre><code>K-means clustering with 3 clusters of sizes 17, 23, 10

Cluster means:
        [,1]        [,2]
1  3.7789567 -4.56200798
2 -0.3820397 -0.08740753
3  2.3001545 -2.69622023

Clustering vector:
 [1] 1 3 1 3 1 1 1 3 1 3 1 3 1 3 1 3 1 1 1 1 1 3 1 1 1 2 2 2 2 2 2 2 2
[34] 2 2 2 2 2 2 2 2 2 2 3 2 3 2 2 2 2

Within cluster sum of squares by cluster:
[1] 25.74089 52.67700 19.56137
 (between_SS / total_SS =  79.3 %)

Available components:

[1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;    
[5] &quot;tot.withinss&quot; &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;        
[9] &quot;ifault&quot;      </code></pre>
</div>
<h3 id="more-about-k-means">More about k-means</h3>
<ul>
<li><p>To run the kmeans() function in R with multiple initial cluster assignments, we use the nstart argument.</p></li>
<li><p>If a value of nstart greater than one is used, then K-means clustering will be performed using multiple random assignments in Step 1 of Algorithm 10.1, and the kmeans() function will report only the best results.</p></li>
</ul>
<p>Here we compare using nstart<span class="math inline">\(=1\)</span> to nstart<span class="math inline">\(=20.\)</span></p>
<h3 id="varying-the-nstart-value">Varying the nstart value</h3>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>3</span><span class='op'>)</span>
<span class='va'>km.out</span><span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/stats/kmeans.html'>kmeans</a></span><span class='op'>(</span><span class='va'>x</span>,<span class='fl'>3</span>,nstart<span class='op'>=</span><span class='fl'>1</span><span class='op'>)</span>
<span class='va'>km.out</span><span class='op'>$</span><span class='va'>tot.withinss</span>
</code></pre>
</div>
<pre><code>[1] 97.97927</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>km.out</span><span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/stats/kmeans.html'>kmeans</a></span><span class='op'>(</span><span class='va'>x</span>,<span class='fl'>3</span>,nstart<span class='op'>=</span><span class='fl'>20</span><span class='op'>)</span>
<span class='va'>km.out</span><span class='op'>$</span><span class='va'>tot.withinss</span>
</code></pre>
</div>
<pre><code>[1] 97.97927</code></pre>
</div>
<ul>
<li><p>km.out$tot.withinss is the total within-cluster sum of squares, which we seek to minimize by performing K-means clustering</p></li>
<li><p>The individual within-cluster sum-of-squares are contained in the vector km.out$withinss.</p></li>
</ul>
<h3 id="recommended-settings">Recommended settings</h3>
<ul>
<li><p>Recommend always running K-means clustering with a large value of nstart, such as 20 or 50, since otherwise an undesirable local optimum may be obtained.</p></li>
<li><p>Make sure you always set a random seed as well so that you can reproduce your results.</p></li>
</ul>
<h3 id="difficult-questions-posed-by-k-means">Difficult questions posed by K-means</h3>
<ul>
<li><p>The main question that is posed by k-means is how many clusters <span class="math inline">\(K\)</span> should we choose?</p></li>
<li><p>Anytime we make such a choice regarding <span class="math inline">\(K\)</span>, this can have a strong impact on the results obtained.</p></li>
<li><p>In practice, we try several different choices, and look for the one with the most useful or interpretable solution.</p></li>
<li><p>With these methods, there is no single right answerany solution that exposes some interesting aspects of the data should be considered.</p></li>
</ul>
<h3 id="validating-the-clusters-obtained">Validating the Clusters Obtained</h3>
<ul>
<li><p>Any time clustering is performed on a data set we will find clusters.</p></li>
<li><p>But we really want to know whether the clusters that have been found represent true subgroups in the data, or whether they are simply a result of clustering the noise.</p></li>
<li><p>For instance, if we were to obtain an independent set of observations, then would those observations also display the same set of clusters?</p></li>
<li><p>There exist a number of techniques for assigning a p-value to a cluster in order to assess whether there is more evidence for the cluster than one would expect due to chance.</p></li>
<li><p>However, there has been no consensus on a single best approach. More details can be found in Hastie et al.(2009).</p></li>
</ul>
<h3 id="other-considerations-in-clustering">Other Considerations in Clustering</h3>
<ul>
<li><p>Both K-means and hierarchical clustering will assign each observation to a cluster.</p></li>
<li><p>However, sometimes this might not be appropriate.</p></li>
<li><p>For instance, suppose that most of the observations truly belong to a small number of (unknown) subgroups, and a small subset of the observations are quite different from each other and from all other observations.</p></li>
<li><p>Then since K-means and hierarchical clustering force every observation into a cluster, the clusters found may be heavily distorted due to the presence of outliers that do not belong to any cluster.</p></li>
<li><p>Mixture models are an attractive approach for accommodating the presence of such outliers.</p></li>
<li><p>These amount to a soft version of K-means clustering, and are described in Hastie et al.(2009).</p></li>
</ul>
<h2 id="k-medioids">K-Medioids</h2>
<p>In <span class="math inline">\(K\)</span>-means, cluster centers are averages</p>
<p>A cluster center is representative for all points in a cluster, also called a <font color = "red"> prototype </font></p>
<p>In <span class="math inline">\(K\)</span>-means, we simply take a cluster center to be the <font color = "red"> average </font> of points in the cluster. Great for computational purposesbut how does it lend to <font color = "red"> interpretation </font></p>
<p><br></p>
<p>This would be fine if we were clustering, e.g., houses based on features like price, square footage, number of bedrooms, distance to nearest bus stop, etc.</p>
<p><br></p>
<p>Not so if we were clustering faces</p>
<p><img src="faces.png" /></p>
<h3 id="k-medoids-algorithm"><span class="math inline">\(K\)</span>-medoids algorithm}</h3>
<ul>
<li><p>In some applications we want each center to be <strong>one of the points</strong>* itself.</p></li>
<li><p>This is where <span class="math inline">\(K\)</span>-medoids comes in</p></li>
<li><p>An algorithm similar to the <span class="math inline">\(K\)</span>-means algorithm but when fitting the centers <span class="math inline">\(c_1,\ldots c_K\)</span>, we restrict our attention to the points themselves</p></li>
</ul>
<p>Select initial guess for centers <span class="math inline">\(c_1,\ldots c_K\)</span> (e.g., randomly select <span class="math inline">\(K\)</span> of the points <span class="math inline">\(X_1,\ldots X_n\)</span>), then repeat:</p>
<ol type="1">
<li><p><strong>Minimize</strong> over <span class="math inline">\(C\)</span>: for each<br />
<span class="math inline">\(i=1,\ldots n\)</span>, find the cluster center <span class="math inline">\(c_k\)</span> closest to <span class="math inline">\(X_i\)</span>, and let <span class="math inline">\(C(i)=k\)</span></p></li>
<li><p><strong>Minimize</strong> over <span class="math inline">\(c_1,\ldots c_K\)</span>}: for each <span class="math inline">\(k=1,\ldots K\)</span>, let <span class="math inline">\(c_k = X^*_k\)</span>, the <font color = "red"> medoid </font> of points in cluster <span class="math inline">\(k\)</span>, i.e., the point <span class="math inline">\(X_i\)</span> in cluster <span class="math inline">\(k\)</span> that minimizes <span class="math inline">\(\sum_{C(j)=k} \|X_j-X_i\|_2^2\)</span></p></li>
</ol>
<p>Stop when within-cluster variation doesnt change</p>
<p><br> In words: 1. Cluster (label) each point based on the closest center 2. Replace each center by the medoid of points in its cluster</p>
<h3 id="example-1">Example</h3>
<p><img src="medioid.png" /> Note: only 3 points had different labels under <span class="math inline">\(K\)</span>-means</p>
<h3 id="properties-of-k-medoids">Properties of <span class="math inline">\(K\)</span>-medoids</h3>
<p>The <span class="math inline">\(K\)</span>-medoids algorithm shares the properties of <span class="math inline">\(K\)</span>-means that we discussed (each iteration decreases the criterion; the algorithm always converges; different starts gives different final answers; it does not achieve the global minimum)</p>
<p><br></p>
<p><span class="math inline">\(K\)</span>-medoids generally returns a <strong>higher value</strong> of <span class="math display">\[\sum_{k=1}^K \sum_{C(i)=k} \|X_i-c_k\|_2^2\]</span> than does <span class="math inline">\(K\)</span>-means (why?).</p>
<p><br></p>
<p>Also, <span class="math inline">\(K\)</span>-medoids is <strong>computationally harder</strong> than <span class="math inline">\(K\)</span>-means (because of step 2: computing the medoid is harder than computing the average)</p>
<p><br></p>
<p>Remember, <span class="math inline">\(K\)</span>-medoids has the (potentially important) property that the centers are located among the data points themselves</p>
<p>The K-medoids algorithm is implemented by the function <code>pam</code> (stands for partitioning around medoids) in the package cluster</p>
<h1 id="from-k-means-to-hierarchical-clustering">From K-means to Hierarchical clustering</h1>
<p>Recall two properties of K-means clustering: - It fits exactly <span class="math inline">\(K\)</span> clusters (as specified)</p>
<ul>
<li>Final clustering assignment depends on the chosen initial cluster centers</li>
</ul>
<p><br></p>
<ul>
<li><p>Assume pairwise dissimilarites <span class="math inline">\(d_{ij}\)</span> between data points.</p></li>
<li><p><strong>Hierarchical clustering</strong> produces a consistent result, without the need to choose initial starting positions (number of clusters).</p></li>
</ul>
<p>&lt;<font color= "red"> Catch </font>: choose a way to measure the dissimilarity between groups, called the linkage</p>
<ul>
<li><p>Given the linkage, hierarchical clustering produces a sequence of clustering assignments.</p></li>
<li><p>At one end, all points are in their own cluster, at the other end, all points are in one cluster</p></li>
</ul>
<h2 id="agglomerative-vs-divisive-clustering">Agglomerative vs divisive clustering</h2>
<p><strong>Agglomerative</strong> (i.e., bottom-up): - Start with all points in their own group - Until there is only one cluster, repeatedly: merge the two groups that have the smallest dissimilarity</p>
<p><strong>Divisive</strong> (i.e., top-down): - Start with all points in one cluster - Until all points are in their own cluster, repeatedly: split the group into two resulting in the biggest dissimilarity</p>
<p>Agglomerative strategies are simpler, well focus on them. Divisive methods are still important.</p>
<h2 id="simple-example">Simple example</h2>
<p>Given these data points, an agglomerative algorithm might decide on a clustering sequence as follows:</p>
<p><img src="hcpic.png" /></p>
<h2 id="example-2">Example</h2>
<p><img src="pics/data.png" /></p>
<p><img src="pics/data2.png" /></p>
<p><img src="pics/data3.png" /></p>
<p><img src="pics/data4.png" /></p>
<p><img src="pics/data5.png" /></p>
<p><img src="pics/data6.png" /></p>
<p><img src="pics/data7.png" /></p>
<p><img src="pics/data8.png" /></p>
<p><img src="pics/data9.png" /></p>
<p><img src="pics/data10.png" /></p>
<p><img src="pics/data11.png" /></p>
<p><img src="pics/data12.png" /></p>
<p><img src="pics/data13.png" /></p>
<p><img src="pics/data14.png" /></p>
<p><img src="pics/data15.png" /></p>
<p><img src="pics/data16.png" /></p>
<p><img src="pics/data17.png" /></p>
<p><img src="pics/data18.png" /></p>
<p><img src="pics/data19.png" /></p>
<p><img src="pics/data20.png" /></p>
<p><img src="pics/data21.png" /></p>
<p><img src="pics/data22.png" /></p>
<p><img src="pics/data23.png" /></p>
<p><img src="pics/data24.png" /></p>
<h2 id="when-to-stop">When to stop?</h2>
<p>Suppose you are using the above algorithm to cluster the data points in groups.</p>
<ul>
<li><p>How do you know when to stop?</p></li>
<li><p>How should we compare the data points?</p></li>
<li><p>Each level of the resulting tree is a segmentation of the data</p></li>
<li><p>The algorithm results in a sequence of groupings</p></li>
<li><p>It is up to the user to choose a natural clustering from this sequence</p></li>
</ul>
<h2 id="dendogram">Dendogram</h2>
<p>We can also represent the sequence of clustering assignments as a dendrogram:</p>
<p><img src="dendogram.png" /></p>
<p>Note that cutting the dendrogram horizontally partitions the data points into clusters</p>
<ul>
<li><p>Agglomerative clustering is monotonic</p></li>
<li><p>The similarity between merged clusters is monotone decreasing with the level of the merge.</p></li>
<li><p>Dendrogram: Plot each merge at the (negative) similarity between the two merged groups</p></li>
<li><p>Provides an interpretable visualization of the algorithm and data</p></li>
<li><p>Useful summarization tool, part of why hierarchical clustering is popular</p></li>
</ul>
<h2 id="group-similarity">Group similarity</h2>
<p>Given a distance similarity measure (say, Eucliclean) between points, the user has many choices on how to define intergroup similarity.</p>
<ol type="1">
<li><p>Single linkage: the similiarity of the closest pair <span class="math display">\[ d_{SL}(G,H) = \min_{i\in G, j \in H} d_{i,j}\]</span></p></li>
<li><p>Complete linkage: the similarity of the furthest pair <span class="math display">\[d_{CL}(G,H) = \max_{i\in G, j \in H} d_{i,j}\]</span></p></li>
<li><p>Group-average: the average similarity between groups <span class="math display">\[d_{GA} = \frac{1}{N_G N_H}\sum_{i \in G}\sum_{j \in H}d_{i,j}\]</span></p></li>
</ol>
<h3 id="single-linkage">Single Linkage</h3>
<p>In single linkage (i.e., nearest-neighbor linkage), the dissimilarity between <span class="math inline">\(G,H\)</span> is the smallest dissimilarity between two points in opposite groups: <span class="math display">\[d_{\text{single}}(G,H) = 
\min_{i \in G, \, j \in H} d_{ij}\]</span></p>
<p>Example (dissimilarities <span class="math inline">\(d_{ij}\)</span> are distances, groups are marked by colors): single linkage score <span class="math inline">\(d_{\text{single}}(G,H)\)</span> is the distance of the closest pair}</p>
<p><img src="single.png" /></p>
<p>Here <span class="math inline">\(n=60\)</span>, <span class="math inline">\(X_i \in \R^2\)</span>, <span class="math inline">\(d_{ij}=\|X_i-X_j\|_2\)</span>. Cutting the tree at <span class="math inline">\(h=0.9\)</span> gives the clustering assignments marked by colors</p>
<p><img src="exsing.png" /></p>
<p>Cut interpretation: for each point <span class="math inline">\(X_i\)</span>, there is another point <span class="math inline">\(X_j\)</span> in its cluster with <span class="math inline">\(d_{ij} \leq 0.9\)</span></p>
<h3 id="complete-linkage">Complete Linkage</h3>
<p>In complete linkage (i.e., furthest-neighbor linkage), dissimilarity between <span class="math inline">\(G,H\)</span> is the largest dissimilarity between two points in opposite groups: <span class="math display">\[d_{\text{complete}}(G,H) = 
\max_{i \in G, \, j \in H} d_{ij}\]</span></p>
<p>Example (dissimilarities <span class="math inline">\(d_{ij}\)</span> are distances, groups are marked by colors): complete linkage score <span class="math inline">\(d_{\text{complete}}(G,H)\)</span> is the distance of the furthest pair.</p>
<p><img src="complete.png" /></p>
<p>Cutting the tree at <span class="math inline">\(h=5\)</span> gives the clustering assignments marked by colors</p>
<p><img src="excomp.png" /></p>
<p>Cut interpretation: for each point <span class="math inline">\(X_i\)</span>, every other point <span class="math inline">\(X_j\)</span> in its cluster satisfies <span class="math inline">\(d_{ij} \leq 5\)</span></p>
<h3 id="average-linkage">Average Linkage</h3>
<p>In average linkage, the dissimilarity between <span class="math inline">\(G,H\)</span> is the average dissimilarity over all points in opposite groups: <span class="math display">\[d_{\text{average}}(G,H) = 
\frac{1}{n_G \cdot n_H}
\sum_{i \in G, \, j \in H} d_{ij}\]</span></p>
<p>Example (dissimilarities <span class="math inline">\(d_{ij}\)</span> are distances, groups are marked by colors): average linkage score <span class="math inline">\(d_{\text{average}}(G,H)\)</span> is the<br />
average distance across all pairs</p>
<p>(Plot here only shows distances between the blue points and one red point)}</p>
<p><img src="average.png" /></p>
<p>Same data as before. Cutting the tree at <span class="math inline">\(h=2.5\)</span> gives clustering assignments marked by the colors</p>
<p><img src="exavg.png" /></p>
<p>Cut interpretation: there really isnt a good one!</p>
<h2 id="properties-of-intergroup-similarity">Properties of intergroup similarity</h2>
<ul>
<li><p>Single linkage can produce chaining, where a sequence of close observations in different groups cause early merges of those groups</p></li>
<li><p>Complete linkage has the opposite problem. It might not merge close groups because of outlier members that are far apart.</p></li>
<li><p>Group average represents a natural compromise, but depends on the scale of the similarities. Applying a monotone transformation to the similarities can change the results.</p></li>
</ul>
<h2 id="things-to-consider">Things to consider</h2>
<ul>
<li>Hierarchical clustering should be treated with caution.</li>
<li>Different decisions about group similarities can lead to vastly different dendrograms.</li>
<li>The algorithm imposes a hierarchical structure on the data, even data for which such structure is not appropriate.</li>
</ul>
<h2 id="application-on-genomic-data">Application on genomic data</h2>
<ul>
<li><p>Unsupervised methods are often used in the analysis of genomic data.</p></li>
<li><p>PCA and hierarchical clustering are very common tools. We will explore both on a genomic data set.</p></li>
<li><p>We illustrate these methods on the NCI60 cancer cell line microarray data, which consists of 6,830 gene expression measurements on 64 cancer cell lines.</p></li>
</ul>
<h3 id="background-on-gene-expression-levels">Background on gene expression levels</h3>
<p>A gene is a stretch of DNA inside the cell that tells the cell how to make a specific protein.</p>
<p>All cells in the body contain the same genes, but they do not always make the same proteins in the same quantities</p>
<p>The genes have different expression levels in different cell types, and cells can regulate gene expression levels in response to their environment.</p>
<p>Different types of cells thus have different expression profiles.</p>
<p>Many diseases, including cancer, fundamentally involve breakdowns in the regulation of gene expression.</p>
<p>The expression profile of cancer cells becomes abnormal, and different kinds of cancers have different expression profiles. (The exception are red blood cells, which do not contain DNA)</p>
<h3 id="gene-expression-data">Gene expression data</h3>
<p>Our data are gene expression measurements from cells drawn from 64 different tumors (from 64 different patients).</p>
<p>In each case, a device called a microarray (or gene chip) measured the expression of each of 6830 distinct genes.</p>
<h3 id="class-types-of-gene-expression-data">Class types of gene expression data</h3>
<p>The cells mostly come from known cancer types, so there are classes, in addition to the measurements of the expression levels.</p>
<p>The classes are breast, cns (central nervous system), colon, leukemia, melanoma, nsclc (non-small- cell lung cancer), ovarian, prostate, renal, K562A, K562B, MCF7A, MCF7D (those four are laboratory tumor cultures) and unknown.</p>
<h3 id="application-on-gene-expression-data">Application on gene expression data</h3>
<p>Note you will need to install via <code>install.packages(pkgs="ElemStatLearn_2015.6.26.tar.gz", type="source", repos=NULL)</code></p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='http://www-stat.stanford.edu/~tibs/ElemStatLearn/'>ElemStatLearn</a></span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span><span class='op'>(</span><span class='va'>nci</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/utils/head.html'>head</a></span><span class='op'>(</span><span class='va'>nci</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>        CNS      CNS    CNS         RENAL BREAST    CNS    CNS BREAST
[1,]  0.300 0.679961  0.940  2.800000e-01  0.485  0.310 -0.830 -0.190
[2,]  1.180 1.289961 -0.040 -3.100000e-01 -0.465 -0.030  0.000 -0.870
[3,]  0.550 0.169961 -0.170  6.800000e-01  0.395 -0.100  0.130 -0.450
[4,]  1.140 0.379961 -0.040 -8.100000e-01  0.905 -0.460 -1.630  0.080
[5,] -0.265 0.464961 -0.605  6.250000e-01  0.200 -0.205  0.075  0.005
[6,] -0.070 0.579961  0.000 -1.387779e-17 -0.005 -0.540 -0.360  0.350
      NSCLC  NSCLC  RENAL  RENAL  RENAL  RENAL  RENAL  RENAL  RENAL
[1,]  0.460  0.760  0.270 -0.450 -0.030  0.710 -0.360 -0.210 -0.500
[2,]  0.000  1.490  0.630 -0.060 -1.120  0.000 -1.420 -1.950 -0.520
[3,]  1.150  0.280 -0.360  0.150 -0.050  0.160 -0.030 -0.700 -0.660
[4,] -1.400  0.100 -1.040 -0.610  0.000 -0.770 -2.280 -1.650 -2.610
[5,] -0.005 -0.525  0.015 -0.395 -0.285  0.045  0.135 -0.075  0.225
[6,] -0.700  0.360 -0.040  0.150 -0.250 -0.160 -0.320  0.060 -0.050
     BREAST  NSCLC  RENAL UNKNOWN OVARIAN MELANOMA PROSTATE OVARIAN
[1,] -1.060  0.150 -0.290  -0.200   0.430   -0.490   -0.530  -0.010
[2,] -2.190 -0.450  0.000   0.740   0.500    0.330   -0.050  -0.370
[3,] -0.130 -0.320  0.050   0.080  -0.730    0.010   -0.230  -0.160
[4,]  0.000 -1.610  0.730   0.760   0.600   -1.660    0.170   0.930
[5,] -0.485 -0.095  0.385  -0.105  -0.635   -0.185    0.825   0.395
[6,] -0.430 -0.080  0.390  -0.080  -0.430   -0.140    0.010  -0.100
     OVARIAN OVARIAN OVARIAN OVARIAN PROSTATE NSCLC  NSCLC  NSCLC
[1,]   0.640  -0.480   0.140   0.640    0.070 0.130  0.320  0.515
[2,]   0.550   0.970   0.720   0.150    0.290 2.240  0.280  1.045
[3,]  -0.540   0.300  -0.240  -0.170    0.070 0.640  0.360  0.000
[4,]  -1.780   0.470   0.000   0.550    1.310 0.680 -1.880  0.000
[5,]   0.315   0.425   1.715  -0.205    0.085 0.135  0.475  0.330
[6,]   0.810   0.020   0.260   0.290   -0.620 0.300  0.110 -0.155
     LEUKEMIA K562B-repro K562A-repro    LEUKEMIA LEUKEMIA LEUKEMIA
[1,]    0.080       0.410      -0.200 -0.36998050   -0.370   -0.430
[2,]    0.120       0.000       0.000 -1.38998000    0.180   -0.590
[3,]    0.060       0.210       0.060 -0.05998047    0.000   -0.500
[4,]    0.400       0.180      -0.070  0.07001953   -1.320   -1.520
[5,]    0.105      -0.255      -0.415 -0.07498047   -0.825   -0.785
[6,]   -0.190      -0.110       0.020  0.04001953   -0.130    0.520
     LEUKEMIA LEUKEMIA       COLON  COLON         COLON       COLON
[1,]   -0.380   -0.550 -0.32003900 -0.620 -4.900000e-01  0.07001953
[2,]   -0.550    0.000  0.08996101  0.080  4.200000e-01 -0.82998050
[3,]   -1.710    0.100 -0.29003900  0.140 -3.400000e-01 -0.59998050
[4,]   -1.870   -2.390 -1.03003900  0.740  7.000000e-02 -0.90998050
[5,]   -0.585   -0.215  0.09496101  0.205 -2.050000e-01  0.24501950
[6,]    0.120   -0.620  0.05996101  0.000 -1.387779e-17 -0.43998050
      COLON  COLON      COLON MCF7A-repro     BREAST MCF7D-repro
[1,] -0.120 -0.290 -0.8100195       0.200 0.37998050   0.3100195
[2,]  0.000  0.030  0.0000000      -0.230 0.44998050   0.4800195
[3,] -0.010 -0.310  0.2199805       0.360 0.65998050   0.9600195
[4,]  0.130  1.500  0.7399805       0.180 0.76998050   0.9600195
[5,]  0.555  0.005  0.1149805      -0.315 0.05498047  -0.2149805
[6,] -0.550 -0.540  0.1199805       0.410 0.54998050   0.3700195
     BREAST       NSCLC  NSCLC  NSCLC MELANOMA BREAST      BREAST
[1,]  0.030 -0.42998050  0.160  0.010   -0.620 -0.380  0.04998047
[2,]  0.220 -0.38998050 -0.340 -1.280   -0.130  0.000 -0.72001950
[3,]  0.150 -0.17998050 -0.020 -0.770    0.200 -0.060  0.41998050
[4,] -1.240  0.86001950 -1.730  0.940   -1.410  0.800  0.92998050
[5,] -0.305  0.78501950 -0.625 -0.015    1.585 -0.115 -0.09501953
[6,]  0.050  0.04001953 -0.140  0.270    1.160  0.180  0.19998050
     MELANOMA MELANOMA MELANOMA MELANOMA      MELANOMA MELANOMA
[1,]    0.650   -0.030   -0.270    0.210 -5.000000e-02    0.350
[2,]    0.640   -0.480    0.630   -0.620  1.400000e-01   -0.270
[3,]    0.150    0.070   -0.100   -0.150 -9.000000e-02    0.020
[4,]   -1.970   -0.700    1.100   -1.330 -1.260000e+00   -1.230
[5,]   -0.065   -0.195    1.045    0.045  4.500000e-02   -0.715
[6,]    0.130    0.410    0.080   -0.400 -2.710505e-20   -0.340</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># transpose the data for clustering</span>
<span class='va'>nci.t</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/t.html'>t</a></span><span class='op'>(</span><span class='va'>nci</span><span class='op'>)</span>
<span class='co'># columns are cancer types</span>
<span class='co'># rows are the patient </span>
</code></pre>
</div>
</div>
<h3 id="task-1-hierarchical-clustering-to-nci60-data">Task 1: Hierarchical Clustering to NCI60 Data</h3>
<p>Produce dendrograms using single-link clustering and complete-link clustering, and average link clustering. Make sure the figures are legible. (Try the cex=0.5 option to plot.)</p>
<p>Remark: hclust needs a matrix of distances, handily produced by the dist function, so lets make sure to remember to use this.</p>
<h3 id="creating-distances">Creating distances</h3>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># does euc. dist by default </span>
<span class='va'>nci.dist</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/dist.html'>dist</a></span><span class='op'>(</span><span class='va'>nci.t</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/utils/head.html'>head</a></span><span class='op'>(</span><span class='va'>nci.dist</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>[1] 51.43823 65.93815 79.87886 92.65185 80.36544 81.03195</code></pre>
</div>
<h3 id="complete-linkage-1">Complete Linkage</h3>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/hclust.html'>hclust</a></span><span class='op'>(</span><span class='va'>nci.dist</span>, method<span class='op'>=</span><span class='st'>"complete"</span><span class='op'>)</span>, cex<span class='op'>=</span><span class='fl'>0.5</span>, main<span class='op'>=</span><span class='st'>"Complete Linkage"</span>, xlab<span class='op'>=</span><span class='st'>"Cells"</span>, sub<span class='op'>=</span><span class='st'>""</span>,ylab<span class='op'>=</span><span class='st'>""</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="k-means_files/figure-html5/unnamed-chunk-12-1.png" width="624" /></p>
</div>
<h3 id="average-linkage-1">Average Linkage</h3>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/hclust.html'>hclust</a></span><span class='op'>(</span><span class='va'>nci.dist</span>, method<span class='op'>=</span><span class='st'>"average"</span><span class='op'>)</span>, cex<span class='op'>=</span><span class='fl'>0.5</span>,
main<span class='op'>=</span><span class='st'>"Average Linkage"</span>, xlab<span class='op'>=</span><span class='st'>""</span>, sub<span class='op'>=</span><span class='st'>""</span>,ylab<span class='op'>=</span><span class='st'>""</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="k-means_files/figure-html5/unnamed-chunk-13-1.png" width="624" /></p>
</div>
<h3 id="single-linkage-1">Single Linkage</h3>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/stats/hclust.html'>hclust</a></span><span class='op'>(</span><span class='va'>nci.dist</span>, method<span class='op'>=</span><span class='st'>"single"</span><span class='op'>)</span>, cex<span class='op'>=</span><span class='fl'>0.5</span>,
main<span class='op'>=</span><span class='st'>"Single Linkage"</span>, xlab<span class='op'>=</span><span class='st'>""</span>, sub<span class='op'>=</span><span class='st'>""</span>,ylab<span class='op'>=</span><span class='st'>""</span><span class='op'>)</span>
</code></pre>
</div>
<p><img src="k-means_files/figure-html5/unnamed-chunk-14-1.png" width="624" /></p>
</div>
<h3 id="question">Question</h3>
<p>Which cell classes seem are best captured by each clustering method?</p>
<ol type="1">
<li>Complete-linkage has nice sub-trees for COLON, LEUKEMIA, MELANOMA, and RENAL.</li>
<li>Average linkage has similar resuls to complete linkage.</li>
<li>Single-linkage is good with RENAL and decent with MELANOMA (though confused with BREAST). There are little sub-trees of cells of the same time, like COLON or CNS, but mixed together with others.</li>
</ol>
<h3 id="complete-and-average-linkage-versus-single-linkage">Complete and average linkage versus single linkage</h3>
<ul>
<li>Typically, single linkage will tend to yield trailing clusters: very large clusters onto which individual observations attach one-by-one.</li>
<li>On the other hand, complete and average linkage tend to yield more balanced, attractive clusters</li>
<li>For this reason, complete and average linkage are generally preferred to single linkage.</li>
</ul>
<h3 id="height-and-sum-of-the-within-cluster-sums-of-squares-relationship">Height and sum of the within-cluster sums of squares relationship</h3>
<p>The hclust command returns an object whose height attribute is the sum of the within-cluster sums of squares. How many clusters does this suggest we should use, according to complete linkage?</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>nci.complete</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/stats/hclust.html'>hclust</a></span><span class='op'>(</span><span class='va'>nci.dist</span>, method<span class='op'>=</span><span class='st'>"complete"</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>nci.complete</span><span class='op'>$</span><span class='va'>height</span><span class='op'>)</span>
</code></pre>
</div>
<pre><code>[1] 63</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>nci.complete</span><span class='op'>$</span><span class='va'>height</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>]</span>
</code></pre>
</div>
<pre><code>[1] 38.23033</code></pre>
</div>
<p>There are 63 heights, corresponding to the 63 joinings, i.e., not in- cluding the height (sum-of-squares) of zero when we have 64 clusters, one for each data point. Since the merging costs are differences, we want to add an initial 0 to the sequence.</p>
<h3 id="optimal-number-of-clusters">Optimal number of clusters</h3>
<div class="layout-chunk" data-layout="l-body">
<p><img src="k-means_files/figure-html5/unnamed-chunk-16-1.png" width="384" /></p>
</div>
<p>The heuristic is to stop joining clusters when the cost of doing so goes up a lot.</p>
<p>This suggests using only 10 clusters, since going from 10 clusters to 9 is very expensive. (Alternately, use 63 clusters; but that would be silly.)</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
