---
title: "jonathan-sheng-algorithmic-demand-estimation-causal"
description: |
  extra code (do not knit)
author:
  - Jonathan Arnold 
  - Sheng Chao Ho
date: 03-27-2021
output:
  distill::distill_article:
    self_contained: false
categories: "Jonathan and Sheng"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```



```{r draws for observed and unobserved heterogeneities,eval=FALSE}

rc <- c("(Intercept)", "price", "car_size","mpg_combined", "dpm_combined",
        "engine_hp", "hp_to_weight")

df_income <- 
  df %>% 
  distinct(Year, .keep_all = TRUE) %>% 
  select(Year,starts_with("real")) %>% 
  arrange(Year)
nYears <- nrow(df_income)

#This part uses the real income percentiles to find the best fitting lognormal distribution for each year. (BLP used the mean and standard deviation to get the lognormal distributions. But i believe the resulting log normal distributions aren't very different at all)
ofn <- function(x,q) {
  sum(abs(q-qlnorm(c(0.2,0.4,0.6,0.8,0.95),x[1],x[2]))^2) 
}
para = matrix(0,nrow = nYears, ncol = 2)
colnames(para) <- c("mu","sigma")
for (i in 1:nYears) {
  para[i,] <- optim(c(9,0.8),ofn, q = df_income[i,2:6],
                    method = "L-BFGS-B",lower  = c(0,0))$par
} 
df_income <- bind_cols(df_income,as_tibble(para))


#The rest of this code chunk gets the observed and unobserved heterogeneity draws into the format used by BLPestimatoR
#Using the estimated lognormal distributions for each year, generate draws for income
N_draws <- 1000
#Use log(income) as the income variable
obs_draws_income = map2_dfr(pull(df_income,mu),pull(df_income,sigma), 
                        ~ rlnorm(N_draws,meanlog = .x, sdlog = .y) %>% 
                          log %>% matrix(nrow=1) %>% as_tibble) %>%
  bind_cols(select(df_income,Year),.)

obs_draws = list(income = obs_draws_income)


#This part generates the unobserved heterogeneities from a SND 
unobs_draws <- map(rc,
                   ~ rnorm(N_draws*nYears) %>% 
                     matrix(ncol=N_draws) %>% as_tibble %>% 
                     bind_cols(select(df_income,Year),.)
                   )
names(unobs_draws) <- rc


for (i in 1:length(unobs_draws)) {
  unobs_draws[[i]]<- unobs_draws[[i]] %>% gather(key="variable",value="value",-Year) %>% select(Year, value) %>% arrange(Year)
  names(unobs_draws[[i]])[2]<- names(unobs_draws)[i]
}
unobs_draws_all<- reduce(unobs_draws,cbind)
unobs_draws_all<- unobs_draws_all[,c(1:2,seq(4,ncol(unobs_draws_all),by=2))]

obs_draws_income<- obs_draws_income %>% gather(key="variable",value="value",-Year) %>% select(Year, value) %>% arrange(Year)
names(obs_draws_income)[2]<- "income"
```

```{r last step of data prep,eval=FALSE}
blp_data <-  BLP_data(
  model = blp_model,
  market_identifier = "Year",
  par_delta = "delta",
  product_identifier = "Model_id",
  productData = df,
  blp_inner_tol = 1e-9, blp_inner_maxit = 5000,
  demographic_draws = obs_draws,
  integration_draws = unobs_draws,
  integration_weights = rep(1 / N_draws, N_draws)
)
```

```{r estimate blp,eval=FALSE}
#Estimating the BLP model with observed heterogeneities results in a very unstable algorithm for most combinations of variables that i've tried.
starting_guess <- cbind(unobs_sd,-0.001)
colnames(starting_guess) <- c("unobs_sd","income")
rownames(starting_guess) <- rc


blp_est <- estimateBLP(
  blp_data = blp_data,
  par_theta2 = starting_guess,
  solver_method = "BFGS", solver_maxit = 1000, solver_reltol = 1e-6,
  standardError = "heteroskedastic",
  extremumCheck = FALSE,
  printLevel = 1
)
```



