<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #20794d; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #20794d; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

  <!--radix_placeholder_meta_tags-->
  <title>Bandit Problems</title>

  <meta property="description" itemprop="description" content="From Bellman Equations to Reinforcement Learning"/>


  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2021-04-17"/>
  <meta property="article:created" itemprop="dateCreated" content="2021-04-17"/>
  <meta name="article:author" content="Amit Gandhi"/>

  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Bandit Problems"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="From Bellman Equations to Reinforcement Learning"/>
  <meta property="og:locale" content="en_US"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Bandit Problems"/>
  <meta property="twitter:description" content="From Bellman Equations to Reinforcement Learning"/>

  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output","preview"]}},"value":[{"type":"character","attributes":{},"value":["Bandit Problems"]},{"type":"character","attributes":{},"value":["From Bellman Equations to Reinforcement Learning\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Amit Gandhi"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":[]}},"value":[]}]}]},{"type":"character","attributes":{},"value":["04-17-2021"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["https://www.kdnuggets.com/images/reinforcement-learning-fig1-700.jpg"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["3.dmu.log","3.dmu.tex","bandit-problems_files/anchor-4.2.2/anchor.min.js","bandit-problems_files/bowser-1.9.3/bowser.min.js","bandit-problems_files/distill-2.2.21/template.v2.js","bandit-problems_files/header-attrs-2.7/header-attrs.js","bandit-problems_files/jquery-1.11.3/jquery.min.js","bandit-problems_files/popper-2.6.0/popper.min.js","bandit-problems_files/tippy-6.2.7/tippy-bundle.umd.min.js","bandit-problems_files/tippy-6.2.7/tippy-light-border.css","bandit-problems_files/tippy-6.2.7/tippy.css","bandit-problems_files/tippy-6.2.7/tippy.umd.min.js","bandit-problems_files/webcomponents-2.0.0/webcomponents.js","BanditProblems-Slides.aux","BanditProblems-Slides.bbl","BanditProblems-Slides.blg","BanditProblems-Slides.log","BanditProblems-Slides.nav","BanditProblems-Slides.pdf","BanditProblems-Slides.snm","BanditProblems-Slides.synctex.gz","BanditProblems-Slides.tex","BanditProblems-Slides.toc","betadist.png","eligibilitytrace.png","gw1.png","gw10.png","gw11.png","gw2.png","gw3.png","gw4.png","gw5.png","gw6.png","gw7.png","gw8.png","gw9.png","neuralnetwork.png","perceptron.png"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure img {
    width: 100%;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }

  /* Citation hover box */

  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }

  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme
    $('code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // hoverable references
      $('span.citation[data-cites]').each(function() {
        var refHtml = $('#ref-' + $(this).attr('data-cites')).html();
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <!--/radix_placeholder_distill-->
  <script src="bandit-problems_files/header-attrs-2.7/header-attrs.js"></script>
  <script src="bandit-problems_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="bandit-problems_files/popper-2.6.0/popper.min.js"></script>
  <link href="bandit-problems_files/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="bandit-problems_files/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="bandit-problems_files/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="bandit-problems_files/anchor-4.2.2/anchor.min.js"></script>
  <script src="bandit-problems_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="bandit-problems_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="bandit-problems_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Bandit Problems","description":"From Bellman Equations to Reinforcement Learning","authors":[{"author":"Amit Gandhi","authorURL":{},"affiliation":"&nbsp;","affiliationURL":"#","orcidID":""}],"publishedDate":"2021-04-17T00:00:00.000+00:00","citationText":"Gandhi, 2021"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Bandit Problems</h1>
<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->
<p><p>From Bellman Equations to Reinforcement Learning</p></p>
</div>

<div class="d-byline">
  Amit Gandhi true 
  
<br/>04-17-2021
</div>

<div class="d-article">
<h2 id="introduction">Introduction</h2>
<p>We introduce <em>Bandit Problems</em> as a class of sequential optimization problems which require algorithmic techniques to study and structure solutions.</p>
<ul>
<li><p>Standard dynamic proogram concerns sequential decision making problems where the transition model and reward function were known</p></li>
<li><p>In many problems, the model and reward are <font color = "red"> not known </font> in advance</p></li>
<li><p>Agent must <font color = "red"> learn how to act through experience </font> with the world</p></li>
<li><p>Here we consider <font color = "red"> reinforcement learning </font> where an agent receives a reinforcement signal</p></li>
</ul>
<h3 id="definition-of-intelligence">Definition of intelligence</h3>
<blockquote>
<p>Of a device or machine: able to vary its behaviour in response to differing requirements, varying situations, or past events</p>
</blockquote>
<p>—Oxford English Dictionary</p>
<h2 id="challenges-in-reinforcement-learning">Challenges in reinforcement learning}</h2>
<ul>
<li><p><strong>Exploration</strong> of the world must be balanced with <strong>exploitation</strong> of knowledge gained through experience</p></li>
<li><p>Reward may be received long after the important choices have been made, so <font color = "red"> credit must be assigned to earlier decisions </font></p></li>
<li><p>Must <font color = "red"> generalize </font> from limited experience</p></li>
</ul>
<h2 id="outline">Outline</h2>
<ul>
<li><p>Evaluative feedback</p></li>
<li><p>Model-based methods</p></li>
<li><p>Model-free methods</p></li>
<li><p>Generalization</p></li>
</ul>
<h2 id="markov-decision-problems">Markov Decision Problems</h2>
<ul>
<li><p>Agent chooses action <span class="math inline">\(A_t\)</span> at time <span class="math inline">\(t\)</span> based on observing state <span class="math inline">\(S_t\)</span></p></li>
<li><p>State evolves probabilistically based on current state and action taken by agent (<font color = "red"> Markov assumption </font> )</p></li>
<li><p>Objective is to maximize sum of rewards <span class="math inline">\(R_1, \ldots\)</span></p></li>
<li><p>Problem is known as a <em>Markov decision process</em> (MDPs)</p></li>
<li><p>Defined by <em>transition model</em> <span class="math inline">\(T(s&#39; \mid s, a)\)</span> and <em>reward model</em> <span class="math inline">\(R(s, a)\)</span> (often assumed deterministic)</p></li>
</ul>
<h2 id="optimal-behavior">Optimal Behavior</h2>
<ul>
<li><p>In the <em>finite-horizon model</em> agent should optimize expected reward for the next <span class="math inline">\(H\)</span> steps: <span class="math inline">\(E(\sum_{t = 0}^H r_t)\)</span></p></li>
<li><p>In the <em>infinite-horizon discounted model</em> agent should optimize <span class="math inline">\(E(\sum_{t = 0}^\infty \gamma^t r_t)\)</span></p></li>
<li><p><em>Discount factor</em> <span class="math inline">\(0 \leq \gamma &lt; 1\)</span> can be thought of as an interest rate (reward now is worth more than reward in the future)</p></li>
<li><p>Discounting keeps utility of an infinite sequence finite</p></li>
</ul>
<h2 id="policies-and-utilities-of-states">Policies and utilities of states</h2>
<ul>
<li><p>A <em>policy</em> <span class="math inline">\(\pi\)</span> specifies what action to execute from every possible state</p></li>
<li><p>Action to execute from state <span class="math inline">\(s\)</span> according to <span class="math inline">\(\pi\)</span> is denoted <span class="math inline">\(\pi(s)\)</span></p></li>
<li><p>Expected utility of executing <span class="math inline">\(\pi\)</span> when starting from <span class="math inline">\(s\)</span> is denoted <span class="math inline">\(U^\pi(s)\)</span></p></li>
<li><p>Optimal policy <span class="math inline">\(\pi^*\)</span> is one that maximizes expected utility: <span class="math inline">\(\pi^*(s) = \mathop{\mathrm{arg\,max}}_\pi U^\pi(s)\)</span></p></li>
</ul>
<h2 id="iterative-policy-evaluation">Iterative policy evaluation</h2>
<ul>
<li><p>Incrementally compute expected utility after <span class="math inline">\(k\)</span> steps of executing <span class="math inline">\(\pi\)</span></p></li>
<li><p><span class="math inline">\(U_0^\pi(s) = 0\)</span></p></li>
<li><p><span class="math inline">\(U_1^\pi(s) = R(s, \pi(s))\)</span></p></li>
<li><p>…</p></li>
<li><p><span class="math inline">\(U_k^\pi(s) = R(s, \pi(s)) + \gamma \sum_{s&#39;} T(s&#39; \mid s, \pi(s)) U_{k-1}^\pi(s&#39;)\)</span></p></li>
</ul>
<p>This kind of iterative calculation is called <strong>dynamic programming</strong></p>
<h2 id="policy-evaluation">Policy evaluation</h2>
<ul>
<li><p>For an infinite horizon, <span class="math display">\[U^\pi(s) = R(s, \pi(s)) + \gamma \sum_{s&#39;} T(s&#39; \mid s, \pi(s)) U^\pi(s&#39;)\]</span></p></li>
<li><p>Can compute this arbitrarily well with enough iterations of iterative policy evaluation</p></li>
<li><p>Alternative is to just solve system of <span class="math inline">\(N\)</span> linear equations, where <span class="math inline">\(N\)</span> is the number of states, requiring <span class="math inline">\(O(n^3)\)</span> time</p></li>
<li><p><span class="math inline">\(U^\pi = R^\pi + \gamma T^\pi U^\pi\)</span> (in matrix form)</p></li>
<li><p><span class="math inline">\(U^\pi - \gamma T^\pi U^\pi = R^\pi\)</span></p></li>
<li><p><span class="math inline">\((I - \gamma T^\pi) U^\pi = R^\pi\)</span></p></li>
<li><p><span class="math inline">\(U^\pi = (I - \gamma T^\pi)^{-1}R^\pi\)</span></p></li>
</ul>
<h2 id="policy-iteration">Policy iteration</h2>
<ul>
<li><p>Policy iteration is one way to compute an optimal policy <span class="math inline">\(\pi^*\)</span></p></li>
<li><p>The algorithm starts with any policy <span class="math inline">\(\pi_0\)</span> and iterates the following steps</p></li>
</ul>
<p><em>Policy evaluation</em>: given <span class="math inline">\(\pi_i\)</span> compute <span class="math inline">\(U^{\pi_i}\)</span></p>
<p><br></p>
<p><em>Policy improvement</em>: compute new policy from <span class="math inline">\(U^{\pi_i}\)</span> <span class="math display">\[\pi_{i+1}(s) = \mathop{\mathrm{arg\,max}}_a [ R(s, a) + \gamma \sum_{s&#39;} T(s&#39; \mid s, a) U^{\pi_i}(s&#39;)]\]</span></p>
<ul>
<li><p>Algorithm terminates when there is no more improvement</p></li>
<li><p>Since every step leads to improvement and there are finitely many policies, algorithm terminates at optimal solution</p></li>
</ul>
<h1 id="value-iteration">Value iteration</h1>
<ul>
<li><p>An alternative algorithm is <em>value iteration</em></p></li>
<li><p><strong>Bellman equation</strong> says value of optimal policy is given by <span class="math display">\[U^*(s) = \max_a [R(s, a) + \gamma \sum_{s&#39;} T(s&#39; \mid s, a) U^*(s&#39;)]\]</span></p></li>
<li><p><span class="math inline">\(U^*_0(s) = 0\)</span> (initialization)</p></li>
<li><p><span class="math inline">\(U^*_1(s) = \max_a [R(s, a) + \gamma \sum_{s&#39;} T(s&#39; \mid s, a) U_0^*(s&#39;)]\)</span></p></li>
<li><p>…</p></li>
<li><p><span class="math inline">\(U^*_k(s) = \max_a [R(s, a) + \gamma \sum_{s&#39;} T(s&#39; \mid s, a) U_{k-1}^*(s&#39;)]\)</span></p></li>
<li><p><span class="math inline">\(U^*_k \rightarrow U^*\)</span> as <span class="math inline">\(k \rightarrow \infty\)</span></p></li>
<li><p><span class="math inline">\(\pi(s) = \mathop{\mathrm{arg\,max}}_a [R(s, a) + \gamma \sum_{s&#39;} T(s&#39; \mid s, a) U(s&#39;)]\)</span></p></li>
</ul>
<h2 id="convergence-of-value-iteration">Convergence of value iteration</h2>
<ul>
<li><p>Let <span class="math inline">\(||U||\)</span> denote the , i.e. <span class="math inline">\(||U|| = \max_s |U(s)|\)</span></p></li>
<li><p><span class="math inline">\(||U^*_k - U^*_{k-1}||\)</span> is known as the </p></li>
<li><p>Can be proven that if <span class="math inline">\(||U^*_k - U^*_{k-1}|| &lt; \epsilon(1-\gamma)/\gamma\)</span> then <span class="math inline">\(||U^*_k - U^*|| &lt; \epsilon\)</span></p></li>
<li><p>Hence, slower convergence for <span class="math inline">\(\gamma\)</span> closer to 1</p></li>
<li><p>Can also bound <strong>policy loss</strong>: if <span class="math inline">\(||U^*_k - U^*|| &lt; \epsilon\)</span> then <span class="math inline">\(||U^{\pi_k} - U^*|| &lt; 2\epsilon\gamma/(1-\gamma)\)</span></p></li>
</ul>
<h2 id="example-grid-world">Example: Grid World</h2>
<ul>
<li><p><strong>States</strong>: cells in <span class="math inline">\(10\times10\)</span> grid</p></li>
<li><p><strong>Actions</strong>: up, down, left, and right</p></li>
<li><p><strong>Transition model</strong>: 0.7 chance of moving in intended direction, uniform in other directions</p></li>
<li><p><strong>Reward</strong>: two states have cost (and are not terminal),\ two have reward (and are terminal), <span class="math inline">\(-1\)</span> for wall crash</p></li>
</ul>
<p><img src="gw1.png" /></p>
<p><img src="gw2.png" /></p>
<p><img src="gw3.png" /> <img src="gw4.png" /></p>
<p><img src="gw5.png" /></p>
<p><img src="gw6.png" /></p>
<p><img src="gw7.png" /></p>
<p><img src="gw8.png" /></p>
<p><img src="gw9.png" /></p>
<p><img src="gw10.png" /></p>
<p><img src="gw11.png" /></p>
<h2 id="multi-armed-bandit-problem">Multi-armed bandit problem}</h2>
<ul>
<li><p>Multi-armed bandit problems illustrate challenge with <font color = "red"> exploration and exploitation </font> in a single state environment</p></li>
<li><p>There is a slot machine with <span class="math inline">\(k\)</span> arms</p></li>
<li><p>Arm <span class="math inline">\(i\)</span> pays off 1 or 0 according to unknown parameter <span class="math inline">\(\theta_i\)</span></p></li>
<li><p>No deposit to play, but limited to <span class="math inline">\(h\)</span> pulls</p></li>
<li><p>Many variations on problem, applicable to allocation of clinical trials, adaptive network routing, etc.</p></li>
</ul>
<h2 id="bayesian-estimation-of-payoff-probability">Bayesian estimation of payoff probability</h2>
<ul>
<li><p>Beta distribution can represent posterior over the win probability <span class="math inline">\(\theta_i\)</span> for arm <span class="math inline">\(i\)</span></p></li>
<li><p>Uniform prior distribution is given by <span class="math inline">\(Beta(1,1)\)</span></p></li>
<li><p>Keep track of number of wins <span class="math inline">\(w_i\)</span> and number of losses <span class="math inline">\(\ell_i\)</span> for each arm <span class="math inline">\(i\)</span></p></li>
<li><p>Posterior for <span class="math inline">\(\theta_i\)</span> is given by <span class="math inline">\(Beta(w_i + 1, \ell_i + 1)\)</span></p></li>
</ul>
<h2 id="bayesian-estimation-of-payoff-probability-1">Bayesian estimation of payoff probability</h2>
<p>Red arm has 1 win and 0 loss and blue arm has 4 wins and 1 loss</p>
<p><img src="betadist.png" /></p>
<ul>
<li><p>Posterior probability of winning: <span class="math inline">\(\rho_i = P(\text{win}_i \mid w_i, \ell_i) = \int_0^1 \theta Beta(w_i + 1, \ell_i + 1)(\theta)\,d\theta = \frac{w_i + 1}{w_i + \ell_i + 2}\)</span></p></li>
<li><p><span class="math inline">\(\rho_\text{red} = 2/3 = 0.67\)</span> and <span class="math inline">\(\rho_\text{blue} = 5/7 = 0.83\)</span></p></li>
<li><p>Maximum likelihood estimates: <span class="math inline">\(\hat \theta_\text{red} = 1\)</span> and <span class="math inline">\(\hat \theta_\text{blue} = 0.8\)</span></p></li>
</ul>
<center>
<font size = "6pt"> <em>Should you pull the red arm or blue arm?</em> </font>
</center>
<h2 id="ad-hoc-strategies">Ad-hoc strategies</h2>
<ul>
<li><p><strong><span class="math inline">\(\epsilon\)</span>-greedy</strong>: Choose random arm with probability <span class="math inline">\(\epsilon\)</span>, otherwise choose <span class="math inline">\(\mathop{\mathrm{arg\,max}}_i \rho_i\)</span></p></li>
<li><p><strong>Softmax</strong>: Choose arm <span class="math inline">\(i\)</span> with probability proportional to <span class="math inline">\(e^{\lambda \rho_i}\)</span> (<span class="math inline">\(\lambda \geq 0\)</span> is precision parameter)</p></li>
<li><p><strong>Interval exploration</strong>: Compute <span class="math inline">\(\alpha\%\)</span> confidence interval for <span class="math inline">\(\theta_i\)</span>, choose arm with highest upper bound</p></li>
</ul>
<h2 id="dynamic-programming-approach">Dynamic programming approach</h2>
<ul>
<li><p>Counts <span class="math inline">\(w_1, \ell_1, \ldots, w_k, \ell_k\)</span> represents a , which summarize belief about payoffs</p></li>
<li><p>Use dynamic programming to find optimal policy <span class="math inline">\(\pi^*\)</span> mapping belief states to actions (similar to MDP)</p></li>
<li><p>Expected payoff after pulling <span class="math inline">\(i\)</span> and then acting optimally is denoted <span class="math inline">\(Q^*(w_1, \ell_1, \ldots, w_k, \ell_k, i)\)</span></p></li>
<li><p><span class="math inline">\(U^*(w_1, \ell_1, \ldots, w_k, \ell_k) = \max_i Q^*(w_1, \ell_1, \ldots, w_k, \ell_k, i)\)</span></p></li>
<li><p><span class="math inline">\(\pi^*(w_1, \ell_1, \ldots, w_k, \ell_k) = \mathop{\mathrm{arg\,max}}_i Q^*(w_1, \ell_1, \ldots, w_k, \ell_k, i)\)</span></p></li>
</ul>
<h2 id="computing-optimal-state-action-utility">Computing optimal state-action utility}</h2>
<p><span class="math display">\[\begin{align*}

&amp;Q^*(w_1, \ell_1, \ldots, w_k, \ell_k, i) = \\
&amp;\frac{w_i + 1}{w_i + \ell_i + 2}U^*(\ldots, w_i + 1, \ell_i, \ldots) + \\ 
&amp;\left(1 - \frac{w_i + 1}{w_i + \ell_i + 2}\right)U^*(\ldots, w_i, \ell_i + 1, \ldots)
\end{align*}\]</span></p>
<ul>
<li><p>When <span class="math inline">\(\sum_i (w_i + \ell_i) = h\)</span> (i.e., no pulls left) then <span class="math inline">\(U^*(w_1, \ell_1, \ldots, w_k, \ell_k) = 0\)</span></p></li>
<li><p>Solution is <strong>optimal</strong>, but computation is <strong>exponential</strong> in <span class="math inline">\(h\)</span></p></li>
<li><p><em>Gittins allocation index</em> method can be used to efficiently solve infinite horizon, discounted version</p></li>
</ul>
<center>
Optimal exploration/exploitation difficult in multistate problems
</center>
<h2 id="translating-to-a-learning-problem">Translating to a Learning Problem</h2>
<ul>
<li><p>Rather than <em>compute</em> the optimal policy, treat the policy and the underlying value function as primitives to be learned</p></li>
<li><p>In the multi-arm bandit problem we have an on-line learning problem - we learn from data collected via exploration of the problem space, e.g., the agent’s behavior constructs the data.</p></li>
<li><p>Use exploratory strategies (see above) but applied to the Bellman equation</p></li>
<li><p>This is so called <em>reinforcement learning</em> - these aim to learn the optimal policy directly without use of a model of <span class="math inline">\(T\)</span> and <span class="math inline">\(R\)</span></p></li>
</ul>
<h2 id="incrementally-learning-a-mean">Incrementally Learning a Mean</h2>
<ul>
<li><p>Suppose we have a random variable <span class="math inline">\(X\)</span> and we want to estimate the mean from samples <span class="math inline">\(x_1, \ldots, x_k\)</span></p></li>
<li><p>After <span class="math inline">\(k\)</span> samples <span class="math inline">\(\hat x_k = \frac1k \sum_{i=1}^k x_i\)</span></p></li>
<li><p>Can show that <span class="math inline">\(\hat x_k = \hat x_{k-1} + \frac1k (x_k - \hat x_{k - 1})\)</span></p></li>
<li><p>Can be written <span class="math inline">\(\hat x_k = \hat x_{k-1} + \alpha(k) (x_k - \hat x_{k - 1})\)</span></p></li>
<li><p>Learning rate <span class="math inline">\(\alpha(k)\)</span> can be functions other than <span class="math inline">\(\frac1k\)</span>, loose conditions on learning rate to ensure convergence to mean</p></li>
<li><p>If learning rate is constant, weight of older samples decay exponentially at the rate <span class="math inline">\((1 - \alpha)\)</span></p></li>
</ul>
<p><strong>Update rule: <span class="math inline">\(\hat x \leftarrow \hat x + \alpha(x - \hat x)\)</span></strong></p>
<h2 id="q-learning">Q-learning</h2>
<ul>
<li><p>One algorithm is called <strong>Q-learning</strong></p></li>
<li><p>Idea is to apply <em>incremental estimation</em> to <span class="math inline">\(Q(s, a) = R(s, a) + \gamma \sum_{s&#39;} T(s&#39; \mid s, a) \max_{a&#39;} Q(s&#39;, a&#39;)\)</span></p></li>
<li><p>Interpretation of the Q-function: Choose action <span class="math inline">\(a\)</span> and act optimally thereafter.</p></li>
<li><p>Use sample of next state <span class="math inline">\(s&#39;\)</span> and reward <span class="math inline">\(r\)</span> instead of models</p></li>
<li><p>Q-learning rule: <span class="math inline">\(Q(s, a) \leftarrow Q(s, a) + \alpha(r + \gamma \max_{a&#39;} Q(s&#39;, a&#39;) - Q(s, a))\)</span></p>
<ul>
<li>Recall: <span class="math inline">\(\hat x \leftarrow \hat x + \alpha(x - \hat x)\)</span></li>
</ul></li>
</ul>
<h2 id="q-learning-1">Q-learning</h2>
<ul>
<li><p>Q-learning will converge to the optimal policy</p></li>
<li><p>However, Q-learning typically requires </p></li>
<li><p>Utility is updated one step at a time</p></li>
<li><p><strong>Eligibility traces</strong> allow states along a path to be updated</p></li>
</ul>
<p><img src="eligibilitytrace.png" /></p>
<h2 id="functional-learning-and-generalization">Functional Learning and Generalization</h2>
<ul>
<li><p>Up to this point, we’ve assumed <span class="math inline">\(Q\)</span> can be represented as a table, which is only useful for small discrete problems</p></li>
<li><p>Problem with larger state spaces is <em>not just the size</em> of <span class="math inline">\(Q\)</span> table, but the <em>amount of experience</em> required to accurately estimate the values</p></li>
<li><p>Agent must <font color = "red"> generalize </font> from limited experience to states that have not yet been visited</p></li>
</ul>
<h2 id="functional-approximations">Functional Approximations</h2>
<ul>
<li><p>Many generalization approaches attempt to approximate <span class="math inline">\(Q\)</span> with a function $Q_{}(a,s)</p></li>
<li><p>One way is to use a <strong>perceptron</strong>, one for each action</p></li>
</ul>
<p><img src="perceptron.png" /></p>
<ul>
<li><p>Weights associated with edges</p></li>
<li><p><span class="math inline">\(q = w_1 x_1 + w_2 x_2 + w_3 x_3\)</span></p></li>
<li><p>Given weights in perceptrons, compute <span class="math inline">\(Q\)</span> for each action from current state <span class="math inline">\(\vec x\)</span></p></li>
</ul>
<h2 id="perceptron-q-learning">Perceptron Q-learning</h2>
<ul>
<li><p>Q-learning tells us how to adapt the weights after transitioning to <span class="math inline">\(\vec{x}&#39;\)</span> from <span class="math inline">\(\vec{x}\)</span> by action <span class="math inline">\(a\)</span> and receiving <span class="math inline">\(r\)</span></p></li>
<li><p><span class="math inline">\(q&#39; \leftarrow r + \gamma \max_{a&#39;} Q(\vec{x}&#39;, a&#39;)\)</span></p></li>
<li><p>Compute error: <span class="math inline">\(Q(\vec{x}, a) - q&#39;\)</span></p></li>
<li><p>Update weights in perceptron for <span class="math inline">\(a\)</span> to reduce error using some learning rate</p></li>
</ul>
<h2 id="neural-networks-aka-deep-rl">Neural networks (aka Deep RL)</h2>
<ul>
<li><strong>Neural networks</strong> are networks of perceptrons</li>
</ul>
<p><img src="neuralnetwork.png" /></p>
<ul>
<li><p>Organized into input layer, hidden layer, and output layer</p></li>
<li><p>Perceptrons only represent linear functions, but neural networks represent <strong>non-linear</strong> functions</p></li>
<li><p>Q-learning works the same way as with perceptrons, though the adjustment of weights is tied to the backpropogation algorithms for fitting neural nets.</p></li>
</ul>
<h2 id="other-generalization-approaches">Other generalization approaches</h2>
<ul>
<li><p>Locally weighted regression</p></li>
<li><p>Self-organizing maps</p></li>
<li><p>Decision trees</p></li>
<li><p>Growing neural gas</p></li>
<li><p>Support vector machines</p></li>
<li><p>Gaussian processes</p></li>
<li><p>Tile coding</p></li>
<li><p>Radial basis function networks</p></li>
</ul>
<center>
<font size = "6pt"> Many ideas based on supervised and unsupervised methods </font>
</center>
<h2 id="policy-function-approximation">Policy Function Approximation</h2>
<ul>
<li><p>Rather than functionally approximate the Q function <span class="math inline">\(Q_{\theta}(a,s)\)</span> and then derive a policy <span class="math inline">\(\pi_{\theta}\)</span> from it, it is more efficient to approximate the policy function directly <span class="math inline">\(\pi_{\theta}\)</span> and apply gradient ascent to the policy parameters <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>We need an ability to <em>simulate</em> a Markov Chain of <span class="math inline">\((s_t,a_t)\)</span> from <span class="math inline">\(s_0\)</span> given a policy <span class="math inline">\(\pi_{\theta}\)</span> to approximate the Bellman.</p></li>
<li><p>See the <embed src="https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf" /></p></li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
